Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=1.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=2, dec_num_layer=2, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=2, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.001, enc_lr=0.001, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=True, precompute_norm_stats=False, D=1)
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=2, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69395537  running time 84.99759006500244
====> Epoch: 1 Average loss: 0.69343949  running time 84.29414749145508
====> Epoch: 1 Average loss: 0.69228938  running time 84.82532238960266
====> Epoch: 1 Average loss: 0.69193970  running time 85.82458686828613
====> Epoch: 1 Average loss: 0.69158442  running time 84.57922625541687
====> Epoch: 1 Average loss: 0.69178019  running time 84.18192958831787
====> Test set BCE loss 0.6911077499389648 Custom Loss 0.6911077499389648 with ber  0.47530999779701233 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_1_awgn_lr_0.001_D1_1000_20221202-012805.pt
each epoch training time: 512.5678262710571s
====> Epoch: 2 Average loss: 0.68864471  running time 85.28730726242065
====> Epoch: 2 Average loss: 0.67426096  running time 84.01920199394226
====> Epoch: 2 Average loss: 0.66847274  running time 84.45017409324646
====> Epoch: 2 Average loss: 0.66545861  running time 84.60686182975769
====> Epoch: 2 Average loss: 0.66317065  running time 86.03723120689392
====> Epoch: 2 Average loss: 0.66486398  running time 84.83414673805237
====> Test set BCE loss 0.6578844785690308 Custom Loss 0.6578844785690308 with ber  0.390720009803772 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_2_awgn_lr_0.001_D1_1000_20221202-012805.pt
each epoch training time: 513.2470915317535s
test loss trajectory [0.6911077499389648, 0.6578844785690308]
test ber trajectory [0.47530999779701233, 0.390720009803772]
test bler trajectory [1.0, 1.0]
total epoch 2
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_awgn_lr_0.001_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.41503995656967163 with bler 1.0
Test SNR -1.0 with ber  0.41192999482154846 with bler 1.0
Test SNR -0.5 with ber  0.4057199954986572 with bler 1.0
Test SNR 0.0 with ber  0.40090999007225037 with bler 1.0
Test SNR 0.5 with ber  0.3979699909687042 with bler 1.0
Test SNR 1.0 with ber  0.392270028591156 with bler 1.0
Test SNR 1.5 with ber  0.3896400034427643 with bler 1.0
Test SNR 2.0 with ber  0.37981000542640686 with bler 1.0
Test SNR 2.5 with ber  0.37473997473716736 with bler 1.0
Test SNR 3.0 with ber  0.3712400197982788 with bler 1.0
Test SNR 3.5 with ber  0.36268001794815063 with bler 1.0
Test SNR 4.0 with ber  0.35638999938964844 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.41503995656967163, 0.41192999482154846, 0.4057199954986572, 0.40090999007225037, 0.3979699909687042, 0.392270028591156, 0.3896400034427643, 0.37981000542640686, 0.37473997473716736, 0.3712400197982788, 0.36268001794815063, 0.35638999938964844]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
Training Time: 1071.7008168697357s
