Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=1.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=2, dec_num_layer=2, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=2, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.001, enc_lr=0.001, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=True, precompute_norm_stats=False, D=1)
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=2, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69316236  running time 111.02422738075256
====> Epoch: 1 Average loss: 0.69224551  running time 90.05278635025024
====> Epoch: 1 Average loss: 0.69016101  running time 89.16996502876282
====> Epoch: 1 Average loss: 0.68862431  running time 86.33325600624084
====> Epoch: 1 Average loss: 0.68822811  running time 84.95658254623413
====> Epoch: 1 Average loss: 0.68840142  running time 85.15305590629578
====> Test set BCE loss 0.6865943074226379 Custom Loss 0.6865943074226379 with ber  0.45333996415138245 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_1_awgn_lr_0.001_D1_1000_20221209-121616.pt
each epoch training time: 550.7321538925171s
====> Epoch: 2 Average loss: 0.67725779  running time 85.15105700492859
====> Epoch: 2 Average loss: 0.63211631  running time 87.17649388313293
====> Epoch: 2 Average loss: 0.61394113  running time 86.50090742111206
====> Epoch: 2 Average loss: 0.60948358  running time 86.2273805141449
====> Epoch: 2 Average loss: 0.60814233  running time 85.855233669281
====> Epoch: 2 Average loss: 0.60740378  running time 86.55713534355164
====> Test set BCE loss 0.5962526798248291 Custom Loss 0.5962526798248291 with ber  0.32110998034477234 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_2_awgn_lr_0.001_D1_1000_20221209-121616.pt
each epoch training time: 521.5138761997223s
test loss trajectory [0.6865943074226379, 0.5962526798248291]
test ber trajectory [0.45333996415138245, 0.32110998034477234]
test bler trajectory [1.0, 1.0]
total epoch 2
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_awgn_lr_0.001_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.3569299578666687 with bler 1.0
Test SNR -1.0 with ber  0.3469499945640564 with bler 1.0
Test SNR -0.5 with ber  0.34272998571395874 with bler 1.0
Test SNR 0.0 with ber  0.3317999839782715 with bler 1.0
Test SNR 0.5 with ber  0.3259299695491791 with bler 1.0
Test SNR 1.0 with ber  0.32180002331733704 with bler 1.0
Test SNR 1.5 with ber  0.31147000193595886 with bler 1.0
Test SNR 2.0 with ber  0.3017500042915344 with bler 1.0
Test SNR 2.5 with ber  0.30021998286247253 with bler 1.0
Test SNR 3.0 with ber  0.2892799973487854 with bler 1.0
Test SNR 3.5 with ber  0.2835899889469147 with bler 1.0
Test SNR 4.0 with ber  0.27215999364852905 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.3569299578666687, 0.3469499945640564, 0.34272998571395874, 0.3317999839782715, 0.3259299695491791, 0.32180002331733704, 0.31147000193595886, 0.3017500042915344, 0.30021998286247253, 0.2892799973487854, 0.2835899889469147, 0.27215999364852905]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
