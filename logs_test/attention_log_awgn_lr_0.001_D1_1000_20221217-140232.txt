Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=1.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=2, dec_num_layer=2, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=2, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.001, enc_lr=0.001, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1)
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=2, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69266037  running time 110.68108868598938
====> Epoch: 1 Average loss: 0.66676410  running time 112.38524889945984
====> Epoch: 1 Average loss: 0.58148797  running time 104.73870038986206
====> Epoch: 1 Average loss: 0.48994940  running time 102.99706530570984
====> Epoch: 1 Average loss: 0.45800171  running time 101.94673800468445
====> Epoch: 1 Average loss: 0.45194618  running time 104.52289080619812
====> Test set BCE loss 0.4214874804019928 Custom Loss 0.4214874804019928 with ber  0.19425000250339508 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_1_awgn_lr_0.001_D1_1000_20221217-140232.pt
each epoch training time: 646.0338456630707s
====> Epoch: 2 Average loss: 0.38921121  running time 118.44786405563354
====> Epoch: 2 Average loss: 0.35473891  running time 125.3013482093811
====> Epoch: 2 Average loss: 0.35192246  running time 114.40601205825806
====> Epoch: 2 Average loss: 0.34676712  running time 113.24953651428223
====> Epoch: 2 Average loss: 0.34513440  running time 88.60108661651611
====> Epoch: 2 Average loss: 0.34599523  running time 88.74709582328796
====> Test set BCE loss 0.30906033515930176 Custom Loss 0.30906033515930176 with ber  0.13171999156475067 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_2_awgn_lr_0.001_D1_1000_20221217-140232.pt
each epoch training time: 652.9982762336731s
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_awgn_lr_0.001_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.1845499873161316 with bler 1.0
Test SNR -1.0 with ber  0.17464998364448547 with bler 1.0
Test SNR -0.5 with ber  0.16326001286506653 with bler 1.0
Test SNR 0.0 with ber  0.15314999222755432 with bler 1.0
Test SNR 0.5 with ber  0.14162001013755798 with bler 1.0
Test SNR 1.0 with ber  0.13291999697685242 with bler 1.0
Test SNR 1.5 with ber  0.12211000919342041 with bler 1.0
Test SNR 2.0 with ber  0.11258000135421753 with bler 1.0
Test SNR 2.5 with ber  0.10130999237298965 with bler 0.999
Test SNR 3.0 with ber  0.09611000120639801 with bler 1.0
Test SNR 3.5 with ber  0.08698000013828278 with bler 1.0
Test SNR 4.0 with ber  0.07885000109672546 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.1845499873161316, 0.17464998364448547, 0.16326001286506653, 0.15314999222755432, 0.14162001013755798, 0.13291999697685242, 0.12211000919342041, 0.11258000135421753, 0.10130999237298965, 0.09611000120639801, 0.08698000013828278, 0.07885000109672546]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
Training Time: 3819.4692435264587s
