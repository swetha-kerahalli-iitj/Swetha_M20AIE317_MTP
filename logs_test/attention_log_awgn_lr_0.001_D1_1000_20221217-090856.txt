Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=1.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=2, dec_num_layer=2, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=2, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.001, enc_lr=0.001, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1)
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=2, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69432997  running time 91.61849284172058
====> Epoch: 1 Average loss: 0.69132911  running time 97.38740396499634
====> Epoch: 1 Average loss: 0.68518083  running time 94.35782074928284
====> Epoch: 1 Average loss: 0.67998666  running time 93.79461479187012
====> Epoch: 1 Average loss: 0.67786571  running time 107.2427613735199
====> Epoch: 1 Average loss: 0.67751935  running time 101.4736762046814
====> Test set BCE loss 0.6748343706130981 Custom Loss 0.6748343706130981 with ber  0.41948002576828003 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_1_awgn_lr_0.001_D1_1000_20221217-090856.pt
each epoch training time: 591.0092349052429s
====> Epoch: 2 Average loss: 0.63073783  running time 131.03634023666382
====> Epoch: 2 Average loss: 0.54071698  running time 112.25436806678772
====> Epoch: 2 Average loss: 0.47629618  running time 127.6913628578186
====> Epoch: 2 Average loss: 0.46857956  running time 111.71967625617981
====> Epoch: 2 Average loss: 0.46433724  running time 117.65945196151733
====> Epoch: 2 Average loss: 0.46253285  running time 124.00731611251831
====> Test set BCE loss 0.43214043974876404 Custom Loss 0.43214043974876404 with ber  0.2009900063276291 with bler  1.0
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_2_awgn_lr_0.001_D1_1000_20221217-090856.pt
each epoch training time: 730.1848831176758s
saved model C:\WorkSpace\Swetha_M20AIE317_MTP\model_test\attention_model_awgn_lr_0.001_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.2502099871635437 with bler 1.0
Test SNR -1.0 with ber  0.2403300255537033 with bler 1.0
Test SNR -0.5 with ber  0.23020000755786896 with bler 1.0
Test SNR 0.0 with ber  0.21991999447345734 with bler 1.0
Test SNR 0.5 with ber  0.208979994058609 with bler 1.0
Test SNR 1.0 with ber  0.19846999645233154 with bler 1.0
Test SNR 1.5 with ber  0.18884000182151794 with bler 1.0
Test SNR 2.0 with ber  0.1791199892759323 with bler 1.0
Test SNR 2.5 with ber  0.17293000221252441 with bler 1.0
Test SNR 3.0 with ber  0.16412000358104706 with bler 1.0
Test SNR 3.5 with ber  0.15544000267982483 with bler 1.0
Test SNR 4.0 with ber  0.1454000025987625 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.2502099871635437, 0.2403300255537033, 0.23020000755786896, 0.21991999447345734, 0.208979994058609, 0.19846999645233154, 0.18884000182151794, 0.1791199892759323, 0.17293000221252441, 0.16412000358104706, 0.15544000267982483, 0.1454000025987625]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
