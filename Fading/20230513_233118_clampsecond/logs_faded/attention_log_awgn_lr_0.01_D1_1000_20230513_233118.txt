Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=0.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', enc_rnn='gru', dec_rnn='gru', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=10, test_ratio=1, block_len=(10, 20), code_rate_k=(3, 5, 7), code_rate_n=(4, 6, 8), modtype=('QAM16', 'QAM64'), block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_233118\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_233118\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_233118\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_233118\\plot_faded')
use_cuda:  False

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69312171 loss Rayleigh: 0.69312593 loss Rician: 0.69313831   running time 4.9565277099609375
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70146548 loss Rayleigh: 0.70468746 loss Rician: 0.70079446   running time 4.955242156982422
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70385548 loss Rayleigh: 0.69850513 loss Rician: 0.69785059   running time 5.2353832721710205
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70181617 loss Rayleigh: 0.69806466 loss Rician: 0.69419915   running time 6.8489978313446045
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69582241 loss Rayleigh: 0.69556171 loss Rician: 0.69426394   running time 4.98721981048584
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69358085 loss Rayleigh: 0.69356156 loss Rician: 0.69334556   running time 4.885167837142944
====> Test set BCE loss with SNR 0.0 for AWGN 0.69318026304245 Custom Loss 0.69318026304245 with ber  0.5025 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934033632278442 Custom Loss 0.6934033632278442 with ber  0.5025 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933386921882629 Custom Loss 0.6933386921882629 with ber  0.5025 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 33.513184785842896s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69341402 loss Rayleigh: 0.69336497 loss Rician: 0.69332948   running time 4.768291711807251
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69345312 loss Rayleigh: 0.69334421 loss Rician: 0.69314280   running time 4.926361799240112
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69356836 loss Rayleigh: 0.69342929 loss Rician: 0.69327189   running time 4.933068037033081
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340526 loss Rayleigh: 0.69327880 loss Rician: 0.69304447   running time 5.006984710693359
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69322681 loss Rayleigh: 0.69296704 loss Rician: 0.69253767   running time 4.887488603591919
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69333257 loss Rayleigh: 0.69279329 loss Rician: 0.69183530   running time 4.877871751785278
====> Test set BCE loss with SNR 0.0 for AWGN 0.6867948174476624 Custom Loss 0.6867948174476624 with ber  0.49746666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928104162216187 Custom Loss 0.6928104162216187 with ber  0.49746666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6898688673973083 Custom Loss 0.6898688673973083 with ber  0.49746666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.075085878372192s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69372610 loss Rayleigh: 0.69241589 loss Rician: 0.69143054   running time 4.716327667236328
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69388890 loss Rayleigh: 0.69318123 loss Rician: 0.69192205   running time 4.888653039932251
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69362718 loss Rayleigh: 0.69311873 loss Rician: 0.69237171   running time 4.93993067741394
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69356062 loss Rayleigh: 0.69299905 loss Rician: 0.69171650   running time 4.908038854598999
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333587 loss Rayleigh: 0.69245380 loss Rician: 0.69046800   running time 4.893749952316284
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69350348 loss Rayleigh: 0.69249025 loss Rician: 0.69117415   running time 4.933984041213989
====> Test set BCE loss with SNR 0.0 for AWGN 0.6845302581787109 Custom Loss 0.6845302581787109 with ber  0.4959666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6917677521705627 Custom Loss 0.6917677521705627 with ber  0.4959666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6879786849021912 Custom Loss 0.6879786849021912 with ber  0.4959666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.067458629608154s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69344926 loss Rayleigh: 0.69272120 loss Rician: 0.69083304   running time 4.771208763122559
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69366865 loss Rayleigh: 0.69264551 loss Rician: 0.69152835   running time 4.996488094329834
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69343199 loss Rayleigh: 0.69221971 loss Rician: 0.69068058   running time 4.959888935089111
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69357986 loss Rayleigh: 0.69260378 loss Rician: 0.69076014   running time 4.925396919250488
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69339345 loss Rayleigh: 0.69183345 loss Rician: 0.69043627   running time 4.902456283569336
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69350647 loss Rayleigh: 0.69239333 loss Rician: 0.69040668   running time 4.921514511108398
====> Test set BCE loss with SNR 0.0 for AWGN 0.6841707229614258 Custom Loss 0.6841707229614258 with ber  0.5022 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925116181373596 Custom Loss 0.6925116181373596 with ber  0.5022 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6864232420921326 Custom Loss 0.6864232420921326 with ber  0.5022 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.180898666381836s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69322321 loss Rayleigh: 0.69276010 loss Rician: 0.69021758   running time 4.779913902282715
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69350390 loss Rayleigh: 0.69210975 loss Rician: 0.68998820   running time 4.959386348724365
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69345043 loss Rayleigh: 0.69194041 loss Rician: 0.69011963   running time 4.950335741043091
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69354147 loss Rayleigh: 0.69259281 loss Rician: 0.69032322   running time 4.917935609817505
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69364232 loss Rayleigh: 0.69253696 loss Rician: 0.68996755   running time 4.94884467124939
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69386158 loss Rayleigh: 0.69290357 loss Rician: 0.69085654   running time 4.987403154373169
====> Test set BCE loss with SNR 0.0 for AWGN 0.6909781694412231 Custom Loss 0.6909781694412231 with ber  0.49580000000000013 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6924974918365479 Custom Loss 0.6924974918365479 with ber  0.49580000000000013 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6909748315811157 Custom Loss 0.6909748315811157 with ber  0.49580000000000013 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.159765243530273s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69311068 loss Rayleigh: 0.69236270 loss Rician: 0.69129164   running time 4.856529712677002
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69360198 loss Rayleigh: 0.69221731 loss Rician: 0.69120194   running time 4.99606466293335
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69347945 loss Rayleigh: 0.69220322 loss Rician: 0.69112664   running time 4.946830987930298
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69355689 loss Rayleigh: 0.69215746 loss Rician: 0.68929383   running time 4.919996738433838
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69354573 loss Rayleigh: 0.69257258 loss Rician: 0.69018576   running time 4.933742523193359
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69361947 loss Rayleigh: 0.69267090 loss Rician: 0.69059322   running time 4.958311080932617
====> Test set BCE loss with SNR 0.0 for AWGN 0.6888890266418457 Custom Loss 0.6888890266418457 with ber  0.4975333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6914738416671753 Custom Loss 0.6914738416671753 with ber  0.4975333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6858112215995789 Custom Loss 0.6858112215995789 with ber  0.4975333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.25365138053894s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69366250 loss Rayleigh: 0.69194829 loss Rician: 0.68902552   running time 4.85101580619812
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340351 loss Rayleigh: 0.69227332 loss Rician: 0.68985700   running time 4.976843595504761
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69366519 loss Rayleigh: 0.69231368 loss Rician: 0.68973448   running time 4.996094226837158
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69368516 loss Rayleigh: 0.69260152 loss Rician: 0.69025649   running time 4.962253570556641
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69682955 loss Rayleigh: 0.69436776 loss Rician: 0.69396935   running time 4.949046611785889
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69672220 loss Rayleigh: 0.69569734 loss Rician: 0.69581680   running time 4.943440675735474
====> Test set BCE loss with SNR 0.0 for AWGN 0.6947270631790161 Custom Loss 0.6947270631790161 with ber  0.5001333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6950653195381165 Custom Loss 0.6950653195381165 with ber  0.5001333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6947740316390991 Custom Loss 0.6947740316390991 with ber  0.5001333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.458823919296265s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69505693 loss Rayleigh: 0.69482247 loss Rician: 0.69475175   running time 4.855294704437256
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.70070609 loss Rayleigh: 0.69836238 loss Rician: 0.70035898   running time 5.00824499130249
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.70467779 loss Rayleigh: 0.70120842 loss Rician: 0.70042456   running time 5.01609468460083
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69851894 loss Rayleigh: 0.69890157 loss Rician: 0.69817910   running time 4.94617486000061
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69421692 loss Rayleigh: 0.69414399 loss Rician: 0.69401620   running time 4.915626287460327
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69349135 loss Rayleigh: 0.69344656 loss Rician: 0.69336182   running time 4.943050384521484
====> Test set BCE loss with SNR 0.0 for AWGN 0.693353533744812 Custom Loss 0.693353533744812 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933563947677612 Custom Loss 0.6933563947677612 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933537125587463 Custom Loss 0.6933537125587463 with ber  0.4991 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.419700860977173s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333915 loss Rayleigh: 0.69334156 loss Rician: 0.69333957   running time 4.751875877380371
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69348176 loss Rayleigh: 0.69347580 loss Rician: 0.69344412   running time 4.939777612686157
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69331350 loss Rayleigh: 0.69329646 loss Rician: 0.69326087   running time 4.967666387557983
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69334587 loss Rayleigh: 0.69331642 loss Rician: 0.69326743   running time 4.933986186981201
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69335629 loss Rayleigh: 0.69334581 loss Rician: 0.69331524   running time 4.946480751037598
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325083 loss Rayleigh: 0.69325091 loss Rician: 0.69323444   running time 4.981036424636841
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932882070541382 Custom Loss 0.6932882070541382 with ber  0.4964666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932888031005859 Custom Loss 0.6932888031005859 with ber  0.4964666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932884454727173 Custom Loss 0.6932884454727173 with ber  0.4964666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.20732045173645s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69322182 loss Rayleigh: 0.69322273 loss Rician: 0.69322174   running time 4.877715110778809
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69322801 loss Rayleigh: 0.69321697 loss Rician: 0.69318872   running time 4.944753408432007
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69326357 loss Rayleigh: 0.69324809 loss Rician: 0.69321005   running time 4.958649396896362
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332010 loss Rayleigh: 0.69330204 loss Rician: 0.69326447   running time 4.961551904678345
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69322451 loss Rayleigh: 0.69320737 loss Rician: 0.69317340   running time 5.00537109375
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336636 loss Rayleigh: 0.69335952 loss Rician: 0.69333351   running time 4.946034908294678
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932703256607056 Custom Loss 0.6932703256607056 with ber  0.49716666666666665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932708024978638 Custom Loss 0.6932708024978638 with ber  0.49716666666666665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932705044746399 Custom Loss 0.6932705044746399 with ber  0.49716666666666665 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.355502605438232s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5053000000000001 learn codes ber with rayleigh  0.5053000000000001 learn codes ber with rician  0.5053000000000001 ber with awgn  0.378025 ber with rayleigh  0.39709999999999995 ber with rician  0.39235
Test SNR 5 learn codes ber with awgn  0.49849999999999994 learn codes ber with rayleigh  0.49849999999999994 learn codes ber with rician  0.49849999999999994 ber with awgn  0.28504999999999997 ber with rayleigh  0.30445 ber with rician  0.29667499999999997
Test SNR 10 learn codes ber with awgn  0.49926666666666664 learn codes ber with rayleigh  0.49926666666666664 learn codes ber with rician  0.49926666666666664 ber with awgn  0.15960000000000002 ber with rayleigh  0.18444999999999998 ber with rician  0.16002500000000003
Test SNR 15 learn codes ber with awgn  0.49943333333333334 learn codes ber with rayleigh  0.49943333333333334 learn codes ber with rician  0.49943333333333334 ber with awgn  0.037125 ber with rayleigh  0.083125 ber with rician  0.054674999999999994
Test SNR 20 learn codes ber with awgn  0.4981 learn codes ber with rayleigh  0.4981 learn codes ber with rician  0.4981 ber with awgn  0.0008500000000000001 ber with rayleigh  0.031075 ber with rician  0.015725
Test SNR 25 learn codes ber with awgn  0.5023000000000001 learn codes ber with rayleigh  0.5023000000000001 learn codes ber with rician  0.5023000000000001 ber with awgn  0.0 ber with rayleigh  0.009625000000000002 ber with rician  0.005275
Test SNR 30 learn codes ber with awgn  0.5020333333333333 learn codes ber with rayleigh  0.5020333333333333 learn codes ber with rician  0.5020333333333333 ber with awgn  0.0 ber with rayleigh  0.0035499999999999998 ber with rician  0.001475
Test SNR 35 learn codes ber with awgn  0.5027999999999999 learn codes ber with rayleigh  0.5027999999999999 learn codes ber with rician  0.5027999999999999 ber with awgn  0.0 ber with rayleigh  0.0011 ber with rician  0.0005000000000000001
Test SNR 40 learn codes ber with awgn  0.4989333333333333 learn codes ber with rayleigh  0.4989333333333333 learn codes ber with rician  0.4989333333333333 ber with awgn  0.0 ber with rayleigh  0.00035000000000000005 ber with rician  0.0001
Test SNR 45 learn codes ber with awgn  0.49696666666666667 learn codes ber with rayleigh  0.49696666666666667 learn codes ber with rician  0.49696666666666667 ber with awgn  0.0 ber with rayleigh  0.0001 ber with rician  7.500000000000001e-05
Test SNR 50 learn codes ber with awgn  0.4998 learn codes ber with rayleigh  0.4998 learn codes ber with rician  0.4998 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5029333333333333 learn codes ber with rayleigh  0.5029333333333333 learn codes ber with rician  0.5029333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5010333333333332 learn codes ber with rayleigh  0.5010333333333332 learn codes ber with rician  0.5010333333333332 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4998666666666667 learn codes ber with rayleigh  0.4998666666666667 learn codes ber with rician  0.4998666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5028999999999999 learn codes ber with rayleigh  0.5028999999999999 learn codes ber with rician  0.5028999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5029000000000001 learn codes ber with rayleigh  0.5029000000000001 learn codes ber with rician  0.5029000000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49759999999999993 learn codes ber with rayleigh  0.49759999999999993 learn codes ber with rician  0.49759999999999993 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5034 learn codes ber with rayleigh  0.5034 learn codes ber with rician  0.5034 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5026333333333334 learn codes ber with rayleigh  0.5026333333333334 learn codes ber with rician  0.5026333333333334 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4928 learn codes ber with rayleigh  0.4928 learn codes ber with rician  0.4928 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5053000000000001, 0.49849999999999994, 0.49926666666666664, 0.49943333333333334, 0.4981, 0.5023000000000001, 0.5020333333333333, 0.5027999999999999, 0.4989333333333333, 0.49696666666666667, 0.4998, 0.5029333333333333, 0.5010333333333332, 0.4998666666666667, 0.5028999999999999, 0.5029000000000001, 0.49759999999999993, 0.5034, 0.5026333333333334, 0.4928]
Learn Codes rayleigh [0.5053000000000001, 0.49849999999999994, 0.49926666666666664, 0.49943333333333334, 0.4981, 0.5023000000000001, 0.5020333333333333, 0.5027999999999999, 0.4989333333333333, 0.49696666666666667, 0.4998, 0.5029333333333333, 0.5010333333333332, 0.4998666666666667, 0.5028999999999999, 0.5029000000000001, 0.49759999999999993, 0.5034, 0.5026333333333334, 0.4928]
Learn Codes rician [0.5053000000000001, 0.49849999999999994, 0.49926666666666664, 0.49943333333333334, 0.4981, 0.5023000000000001, 0.5020333333333333, 0.5027999999999999, 0.4989333333333333, 0.49696666666666667, 0.4998, 0.5029333333333333, 0.5010333333333332, 0.4998666666666667, 0.5028999999999999, 0.5029000000000001, 0.49759999999999993, 0.5034, 0.5026333333333334, 0.4928]
AWGN [0.378025, 0.28504999999999997, 0.15960000000000002, 0.037125, 0.0008500000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39709999999999995, 0.30445, 0.18444999999999998, 0.083125, 0.031075, 0.009625000000000002, 0.0035499999999999998, 0.0011, 0.00035000000000000005, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39235, 0.29667499999999997, 0.16002500000000003, 0.054674999999999994, 0.015725, 0.005275, 0.001475, 0.0005000000000000001, 0.0001, 7.500000000000001e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69415196 loss Rayleigh: 0.69414159 loss Rician: 0.69411998   running time 5.117615699768066
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70601611 loss Rayleigh: 0.69923795 loss Rician: 0.70366783   running time 5.20350980758667
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70416027 loss Rayleigh: 0.70053464 loss Rician: 0.69630940   running time 5.189234495162964
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69747812 loss Rayleigh: 0.69666957 loss Rician: 0.69446515   running time 5.083306312561035
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69412003 loss Rayleigh: 0.69409718 loss Rician: 0.69384744   running time 5.196907043457031
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69376615 loss Rayleigh: 0.69367096 loss Rician: 0.69350913   running time 5.2595374584198
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933409571647644 Custom Loss 0.6933409571647644 with ber  0.4999666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693368136882782 Custom Loss 0.693368136882782 with ber  0.4999666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933633685112 Custom Loss 0.6933633685112 with ber  0.4999666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.88319277763367s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69332427 loss Rayleigh: 0.69332525 loss Rician: 0.69332104   running time 5.01962423324585
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69346409 loss Rayleigh: 0.69342241 loss Rician: 0.69334486   running time 5.147445917129517
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69345133 loss Rayleigh: 0.69342864 loss Rician: 0.69335140   running time 5.148760795593262
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69337026 loss Rayleigh: 0.69335138 loss Rician: 0.69329677   running time 5.204986095428467
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69354121 loss Rayleigh: 0.69351433 loss Rician: 0.69344321   running time 5.179815769195557
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69320494 loss Rayleigh: 0.69320983 loss Rician: 0.69318894   running time 5.17138934135437
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931713819503784 Custom Loss 0.6931713819503784 with ber  0.5006666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693173348903656 Custom Loss 0.693173348903656 with ber  0.5006666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931718587875366 Custom Loss 0.6931718587875366 with ber  0.5006666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.83047008514404s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69342562 loss Rayleigh: 0.69342541 loss Rician: 0.69342034   running time 5.010339260101318
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69327926 loss Rayleigh: 0.69326802 loss Rician: 0.69322136   running time 5.235207796096802
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69318728 loss Rayleigh: 0.69316906 loss Rician: 0.69311087   running time 5.2316672801971436
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69361629 loss Rayleigh: 0.69355562 loss Rician: 0.69345448   running time 5.180616855621338
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69339446 loss Rayleigh: 0.69341947 loss Rician: 0.69332796   running time 5.224307060241699
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69364203 loss Rayleigh: 0.69359717 loss Rician: 0.69346054   running time 5.184595346450806
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932076811790466 Custom Loss 0.6932076811790466 with ber  0.4985666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932388544082642 Custom Loss 0.6932388544082642 with ber  0.4985666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693229615688324 Custom Loss 0.693229615688324 with ber  0.4985666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.90469455718994s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69322928 loss Rayleigh: 0.69322299 loss Rician: 0.69321709   running time 5.06135106086731
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69353946 loss Rayleigh: 0.69344383 loss Rician: 0.69322146   running time 5.2613584995269775
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342589 loss Rayleigh: 0.69337531 loss Rician: 0.69324400   running time 5.216608047485352
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329115 loss Rayleigh: 0.69325866 loss Rician: 0.69315256   running time 5.171645879745483
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69410703 loss Rayleigh: 0.69379447 loss Rician: 0.69307683   running time 5.18728494644165
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69357677 loss Rayleigh: 0.69381397 loss Rician: 0.69354287   running time 5.300859451293945
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932634115219116 Custom Loss 0.6932634115219116 with ber  0.5016 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933158040046692 Custom Loss 0.6933158040046692 with ber  0.5016 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933084726333618 Custom Loss 0.6933084726333618 with ber  0.5016 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 33.12856411933899s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319878 loss Rayleigh: 0.69318437 loss Rician: 0.69319579   running time 5.101218938827515
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69397756 loss Rayleigh: 0.69390820 loss Rician: 0.69347951   running time 5.179983854293823
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69368615 loss Rayleigh: 0.69351775 loss Rician: 0.69325074   running time 5.1456193923950195
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69340001 loss Rayleigh: 0.69341784 loss Rician: 0.69331391   running time 5.179685592651367
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69348809 loss Rayleigh: 0.69342650 loss Rician: 0.69327870   running time 5.159042119979858
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332477 loss Rayleigh: 0.69332682 loss Rician: 0.69326057   running time 5.171024799346924
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933701634407043 Custom Loss 0.6933701634407043 with ber  0.5007666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933714747428894 Custom Loss 0.6933714747428894 with ber  0.5007666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693372368812561 Custom Loss 0.693372368812561 with ber  0.5007666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.8096649646759s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69351435 loss Rayleigh: 0.69351363 loss Rician: 0.69350982   running time 5.10758638381958
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69344512 loss Rayleigh: 0.69340181 loss Rician: 0.69330457   running time 5.289653301239014
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69354783 loss Rayleigh: 0.69352365 loss Rician: 0.69341844   running time 5.190572500228882
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320793 loss Rayleigh: 0.69321585 loss Rician: 0.69318357   running time 5.1999921798706055
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69340291 loss Rayleigh: 0.69337447 loss Rician: 0.69328130   running time 5.152866840362549
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69335307 loss Rayleigh: 0.69335334 loss Rician: 0.69327602   running time 5.195097208023071
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935076117515564 Custom Loss 0.6935076117515564 with ber  0.5003333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935291886329651 Custom Loss 0.6935291886329651 with ber  0.5003333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935242414474487 Custom Loss 0.6935242414474487 with ber  0.5003333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 33.073381423950195s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336886 loss Rayleigh: 0.69336734 loss Rician: 0.69336989   running time 5.068514585494995
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69326363 loss Rayleigh: 0.69323593 loss Rician: 0.69316722   running time 5.155841112136841
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69338445 loss Rayleigh: 0.69335831 loss Rician: 0.69328040   running time 5.203137397766113
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327612 loss Rayleigh: 0.69325373 loss Rician: 0.69320725   running time 5.192275762557983
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69335174 loss Rayleigh: 0.69331256 loss Rician: 0.69322988   running time 5.225231647491455
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336324 loss Rayleigh: 0.69337897 loss Rician: 0.69332588   running time 5.132627964019775
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931458115577698 Custom Loss 0.6931458115577698 with ber  0.49916666666666665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931545734405518 Custom Loss 0.6931545734405518 with ber  0.49916666666666665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931533813476562 Custom Loss 0.6931533813476562 with ber  0.49916666666666665 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.96334981918335s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69317083 loss Rayleigh: 0.69316419 loss Rician: 0.69315885   running time 5.090040922164917
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330756 loss Rayleigh: 0.69332058 loss Rician: 0.69326216   running time 5.211832284927368
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69338450 loss Rayleigh: 0.69336805 loss Rician: 0.69330646   running time 5.182220458984375
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69338146 loss Rayleigh: 0.69336429 loss Rician: 0.69326791   running time 5.145645380020142
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69373362 loss Rayleigh: 0.69364426 loss Rician: 0.69335588   running time 5.185165166854858
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69404688 loss Rayleigh: 0.69426419 loss Rician: 0.69377599   running time 5.170322895050049
====> Test set BCE loss with SNR 0.0 for AWGN 0.6944191455841064 Custom Loss 0.6944191455841064 with ber  0.5021333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6945005655288696 Custom Loss 0.6945005655288696 with ber  0.5021333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6944791674613953 Custom Loss 0.6944791674613953 with ber  0.5021333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.85126519203186s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69428961 loss Rayleigh: 0.69427856 loss Rician: 0.69426814   running time 5.030924081802368
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69441041 loss Rayleigh: 0.69450935 loss Rician: 0.69367452   running time 5.2182533740997314
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69473754 loss Rayleigh: 0.69516676 loss Rician: 0.69377798   running time 5.139957427978516
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69373898 loss Rayleigh: 0.69387327 loss Rician: 0.69365060   running time 5.206862926483154
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69352467 loss Rayleigh: 0.69345520 loss Rician: 0.69332764   running time 5.1847076416015625
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69379344 loss Rayleigh: 0.69367910 loss Rician: 0.69342936   running time 5.16155481338501
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935616731643677 Custom Loss 0.6935616731643677 with ber  0.5009 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935757398605347 Custom Loss 0.6935757398605347 with ber  0.5009 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693576455116272 Custom Loss 0.693576455116272 with ber  0.5009 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.99078321456909s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69410219 loss Rayleigh: 0.69409521 loss Rician: 0.69409337   running time 5.032860994338989
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69383551 loss Rayleigh: 0.69386607 loss Rician: 0.69367438   running time 5.254797697067261
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332708 loss Rayleigh: 0.69329259 loss Rician: 0.69320026   running time 5.225637674331665
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69348552 loss Rayleigh: 0.69346127 loss Rician: 0.69339428   running time 5.155940294265747
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69358373 loss Rayleigh: 0.69356477 loss Rician: 0.69349100   running time 5.12951135635376
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69338697 loss Rayleigh: 0.69336143 loss Rician: 0.69330243   running time 5.160845518112183
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934537887573242 Custom Loss 0.6934537887573242 with ber  0.49416666666666664 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934522986412048 Custom Loss 0.6934522986412048 with ber  0.49416666666666664 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934518218040466 Custom Loss 0.6934518218040466 with ber  0.49416666666666664 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 32.78572702407837s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4992 learn codes ber with rayleigh  0.4992 learn codes ber with rician  0.4992 ber with awgn  0.442125 ber with rayleigh  0.45577500000000004 ber with rician  0.45097499999999996
Test SNR 5 learn codes ber with awgn  0.5067666666666667 learn codes ber with rayleigh  0.5067666666666667 learn codes ber with rician  0.5067666666666667 ber with awgn  0.39365 ber with rayleigh  0.41059999999999997 ber with rician  0.41154999999999997
Test SNR 10 learn codes ber with awgn  0.4983000000000001 learn codes ber with rayleigh  0.4983000000000001 learn codes ber with rician  0.4983000000000001 ber with awgn  0.3104 ber with rayleigh  0.32847499999999996 ber with rician  0.3235
Test SNR 15 learn codes ber with awgn  0.502 learn codes ber with rayleigh  0.502 learn codes ber with rician  0.502 ber with awgn  0.19350000000000003 ber with rayleigh  0.21527500000000002 ber with rician  0.1967
Test SNR 20 learn codes ber with awgn  0.5015666666666668 learn codes ber with rayleigh  0.5015666666666668 learn codes ber with rician  0.5015666666666668 ber with awgn  0.060524999999999995 ber with rayleigh  0.104575 ber with rician  0.07644999999999999
Test SNR 25 learn codes ber with awgn  0.4998666666666668 learn codes ber with rayleigh  0.4998666666666668 learn codes ber with rician  0.4998666666666668 ber with awgn  0.002875 ber with rayleigh  0.039875 ber with rician  0.021549999999999993
Test SNR 30 learn codes ber with awgn  0.5014 learn codes ber with rayleigh  0.5014 learn codes ber with rician  0.5014 ber with awgn  0.0 ber with rayleigh  0.013574999999999999 ber with rician  0.0056749999999999995
Test SNR 35 learn codes ber with awgn  0.5014000000000001 learn codes ber with rayleigh  0.5014000000000001 learn codes ber with rician  0.5014000000000001 ber with awgn  0.0 ber with rayleigh  0.004400000000000001 ber with rician  0.0017249999999999998
Test SNR 40 learn codes ber with awgn  0.4964666666666668 learn codes ber with rayleigh  0.4964666666666668 learn codes ber with rician  0.4964666666666668 ber with awgn  0.0 ber with rayleigh  0.001575 ber with rician  0.00047500000000000005
Test SNR 45 learn codes ber with awgn  0.4994666666666667 learn codes ber with rayleigh  0.4994666666666667 learn codes ber with rician  0.4994666666666667 ber with awgn  0.0 ber with rayleigh  0.000325 ber with rician  0.000175
Test SNR 50 learn codes ber with awgn  0.5016666666666667 learn codes ber with rayleigh  0.5016666666666667 learn codes ber with rician  0.5016666666666667 ber with awgn  0.0 ber with rayleigh  7.500000000000001e-05 ber with rician  7.500000000000001e-05
Test SNR 55 learn codes ber with awgn  0.5003333333333333 learn codes ber with rayleigh  0.5003333333333333 learn codes ber with rician  0.5003333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  2.5e-05
Test SNR 60 learn codes ber with awgn  0.4984333333333333 learn codes ber with rayleigh  0.4984333333333333 learn codes ber with rician  0.4984333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5020333333333333 learn codes ber with rayleigh  0.5020333333333333 learn codes ber with rician  0.5020333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.507 learn codes ber with rayleigh  0.507 learn codes ber with rician  0.507 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4999666666666667 learn codes ber with rayleigh  0.4999666666666667 learn codes ber with rician  0.4999666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5014333333333333 learn codes ber with rayleigh  0.5014333333333333 learn codes ber with rician  0.5014333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4996666666666666 learn codes ber with rayleigh  0.4996666666666666 learn codes ber with rician  0.4996666666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.4977666666666667 learn codes ber with rayleigh  0.4977666666666667 learn codes ber with rician  0.4977666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4987666666666666 learn codes ber with rayleigh  0.4987666666666666 learn codes ber with rician  0.4987666666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4992, 0.5067666666666667, 0.4983000000000001, 0.502, 0.5015666666666668, 0.4998666666666668, 0.5014, 0.5014000000000001, 0.4964666666666668, 0.4994666666666667, 0.5016666666666667, 0.5003333333333333, 0.4984333333333333, 0.5020333333333333, 0.507, 0.4999666666666667, 0.5014333333333333, 0.4996666666666666, 0.4977666666666667, 0.4987666666666666]
Learn Codes rayleigh [0.4992, 0.5067666666666667, 0.4983000000000001, 0.502, 0.5015666666666668, 0.4998666666666668, 0.5014, 0.5014000000000001, 0.4964666666666668, 0.4994666666666667, 0.5016666666666667, 0.5003333333333333, 0.4984333333333333, 0.5020333333333333, 0.507, 0.4999666666666667, 0.5014333333333333, 0.4996666666666666, 0.4977666666666667, 0.4987666666666666]
Learn Codes rician [0.4992, 0.5067666666666667, 0.4983000000000001, 0.502, 0.5015666666666668, 0.4998666666666668, 0.5014, 0.5014000000000001, 0.4964666666666668, 0.4994666666666667, 0.5016666666666667, 0.5003333333333333, 0.4984333333333333, 0.5020333333333333, 0.507, 0.4999666666666667, 0.5014333333333333, 0.4996666666666666, 0.4977666666666667, 0.4987666666666666]
AWGN [0.442125, 0.39365, 0.3104, 0.19350000000000003, 0.060524999999999995, 0.002875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45577500000000004, 0.41059999999999997, 0.32847499999999996, 0.21527500000000002, 0.104575, 0.039875, 0.013574999999999999, 0.004400000000000001, 0.001575, 0.000325, 7.500000000000001e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45097499999999996, 0.41154999999999997, 0.3235, 0.1967, 0.07644999999999999, 0.021549999999999993, 0.0056749999999999995, 0.0017249999999999998, 0.00047500000000000005, 0.000175, 7.500000000000001e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69380996 loss Rayleigh: 0.69380499 loss Rician: 0.69380475   running time 4.953359603881836
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69886628 loss Rayleigh: 0.70112184 loss Rician: 0.69893901   running time 5.008344411849976
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69714876 loss Rayleigh: 0.69556892 loss Rician: 0.69378924   running time 5.028982639312744
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69449694 loss Rayleigh: 0.69437125 loss Rician: 0.69363922   running time 5.049162864685059
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69387210 loss Rayleigh: 0.69389971 loss Rician: 0.69359998   running time 5.016347885131836
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69349935 loss Rayleigh: 0.69348922 loss Rician: 0.69336767   running time 5.059193134307861
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934229135513306 Custom Loss 0.6934229135513306 with ber  0.49535999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936379075050354 Custom Loss 0.6936379075050354 with ber  0.49535999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693573534488678 Custom Loss 0.693573534488678 with ber  0.49535999999999997 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.815762281417847s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69357778 loss Rayleigh: 0.69353872 loss Rician: 0.69350218   running time 4.901092052459717
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69345182 loss Rayleigh: 0.69345025 loss Rician: 0.69335797   running time 5.025052309036255
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338360 loss Rayleigh: 0.69338763 loss Rician: 0.69330441   running time 5.021207094192505
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69332747 loss Rayleigh: 0.69330974 loss Rician: 0.69323136   running time 5.027815341949463
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69330519 loss Rayleigh: 0.69329624 loss Rician: 0.69323403   running time 5.030210494995117
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328362 loss Rayleigh: 0.69325019 loss Rician: 0.69315389   running time 5.06182336807251
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931632161140442 Custom Loss 0.6931632161140442 with ber  0.50064 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933282613754272 Custom Loss 0.6933282613754272 with ber  0.50064 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693245530128479 Custom Loss 0.693245530128479 with ber  0.50064 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 31.968989849090576s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69322931 loss Rayleigh: 0.69321249 loss Rician: 0.69318734   running time 6.536532640457153
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69338238 loss Rayleigh: 0.69336752 loss Rician: 0.69328829   running time 5.892699480056763
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330561 loss Rayleigh: 0.69327812 loss Rician: 0.69320102   running time 5.110586404800415
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69346361 loss Rayleigh: 0.69342339 loss Rician: 0.69320889   running time 5.0143866539001465
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69339641 loss Rayleigh: 0.69337408 loss Rician: 0.69326446   running time 5.094783544540405
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69347108 loss Rayleigh: 0.69347181 loss Rician: 0.69333975   running time 5.100280284881592
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930964589118958 Custom Loss 0.6930964589118958 with ber  0.5021199999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931380033493042 Custom Loss 0.6931380033493042 with ber  0.5021199999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931243538856506 Custom Loss 0.6931243538856506 with ber  0.5021199999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 34.577208280563354s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69316920 loss Rayleigh: 0.69315628 loss Rician: 0.69315585   running time 4.983935594558716
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69367900 loss Rayleigh: 0.69354607 loss Rician: 0.69324293   running time 5.06878662109375
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69385716 loss Rayleigh: 0.69379147 loss Rician: 0.69326122   running time 5.58232569694519
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69370216 loss Rayleigh: 0.69372216 loss Rician: 0.69336664   running time 5.144591808319092
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69375657 loss Rayleigh: 0.69367273 loss Rician: 0.69337476   running time 5.04648494720459
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69360607 loss Rayleigh: 0.69367019 loss Rician: 0.69340884   running time 5.052285432815552
====> Test set BCE loss with SNR 0.0 for AWGN 0.6949440240859985 Custom Loss 0.6949440240859985 with ber  0.50212 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6949723958969116 Custom Loss 0.6949723958969116 with ber  0.50212 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6949520707130432 Custom Loss 0.6949520707130432 with ber  0.50212 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.600146532058716s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69465991 loss Rayleigh: 0.69466060 loss Rician: 0.69465724   running time 4.876082897186279
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69369622 loss Rayleigh: 0.69364710 loss Rician: 0.69341711   running time 5.02152681350708
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69360179 loss Rayleigh: 0.69367663 loss Rician: 0.69350434   running time 5.030699014663696
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69360653 loss Rayleigh: 0.69354797 loss Rician: 0.69336568   running time 5.091259479522705
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69363254 loss Rayleigh: 0.69351392 loss Rician: 0.69307846   running time 5.082090377807617
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69419782 loss Rayleigh: 0.69398810 loss Rician: 0.69328071   running time 5.0906078815460205
====> Test set BCE loss with SNR 0.0 for AWGN 0.6971436738967896 Custom Loss 0.6971436738967896 with ber  0.50102 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6976349353790283 Custom Loss 0.6976349353790283 with ber  0.50102 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6975730657577515 Custom Loss 0.6975730657577515 with ber  0.50102 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.06061887741089s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69725025 loss Rayleigh: 0.69709932 loss Rician: 0.69695970   running time 4.8567564487457275
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69536523 loss Rayleigh: 0.69405546 loss Rician: 0.69429957   running time 5.01108717918396
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69564947 loss Rayleigh: 0.69550795 loss Rician: 0.69387193   running time 5.06143593788147
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69374081 loss Rayleigh: 0.69383205 loss Rician: 0.69370782   running time 5.041210174560547
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69367406 loss Rayleigh: 0.69364012 loss Rician: 0.69350903   running time 5.117782831192017
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331965 loss Rayleigh: 0.69331360 loss Rician: 0.69326940   running time 5.067605495452881
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934611797332764 Custom Loss 0.6934611797332764 with ber  0.50236 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934559345245361 Custom Loss 0.6934559345245361 with ber  0.50236 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934557557106018 Custom Loss 0.6934557557106018 with ber  0.50236 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.058374881744385s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69339448 loss Rayleigh: 0.69339483 loss Rician: 0.69339573   running time 4.91772723197937
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69326723 loss Rayleigh: 0.69326190 loss Rician: 0.69321857   running time 5.048713207244873
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69341568 loss Rayleigh: 0.69341114 loss Rician: 0.69335048   running time 5.036453008651733
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69334372 loss Rayleigh: 0.69333711 loss Rician: 0.69329089   running time 5.069531202316284
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69326933 loss Rayleigh: 0.69325523 loss Rician: 0.69322081   running time 5.068971157073975
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69338269 loss Rayleigh: 0.69336771 loss Rician: 0.69332260   running time 5.080261468887329
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931646466255188 Custom Loss 0.6931646466255188 with ber  0.49788 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931673884391785 Custom Loss 0.6931673884391785 with ber  0.49788 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931661367416382 Custom Loss 0.6931661367416382 with ber  0.49788 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.060404777526855s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335242 loss Rayleigh: 0.69335256 loss Rician: 0.69335266   running time 4.944420099258423
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343484 loss Rayleigh: 0.69339055 loss Rician: 0.69329473   running time 5.079418182373047
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339328 loss Rayleigh: 0.69337696 loss Rician: 0.69330452   running time 5.033873558044434
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323446 loss Rayleigh: 0.69324404 loss Rician: 0.69321640   running time 5.161728143692017
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69341189 loss Rayleigh: 0.69335107 loss Rician: 0.69325516   running time 5.063298940658569
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335853 loss Rayleigh: 0.69333320 loss Rician: 0.69325482   running time 5.135230541229248
====> Test set BCE loss with SNR 0.0 for AWGN 0.693482518196106 Custom Loss 0.693482518196106 with ber  0.50158 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934846043586731 Custom Loss 0.6934846043586731 with ber  0.50158 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934847235679626 Custom Loss 0.6934847235679626 with ber  0.50158 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.2077739238739s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69334378 loss Rayleigh: 0.69334431 loss Rician: 0.69334370   running time 4.981500864028931
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69341702 loss Rayleigh: 0.69341510 loss Rician: 0.69337189   running time 5.08003830909729
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69335201 loss Rayleigh: 0.69334648 loss Rician: 0.69330618   running time 5.066366910934448
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69342009 loss Rayleigh: 0.69339336 loss Rician: 0.69332232   running time 5.068201541900635
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69320034 loss Rayleigh: 0.69320226 loss Rician: 0.69317449   running time 5.07422137260437
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322295 loss Rayleigh: 0.69322214 loss Rician: 0.69319980   running time 5.031472444534302
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932582855224609 Custom Loss 0.6932582855224609 with ber  0.50092 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932581663131714 Custom Loss 0.6932581663131714 with ber  0.50092 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693257749080658 Custom Loss 0.693257749080658 with ber  0.50092 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.01626229286194s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69320448 loss Rayleigh: 0.69320449 loss Rician: 0.69320487   running time 4.909233331680298
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331407 loss Rayleigh: 0.69330622 loss Rician: 0.69327350   running time 5.064327001571655
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329405 loss Rayleigh: 0.69327728 loss Rician: 0.69323710   running time 5.048113107681274
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331883 loss Rayleigh: 0.69332408 loss Rician: 0.69328557   running time 5.046115398406982
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69330608 loss Rayleigh: 0.69329694 loss Rician: 0.69325559   running time 5.095001935958862
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69327613 loss Rayleigh: 0.69328104 loss Rician: 0.69324548   running time 5.052300453186035
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933924555778503 Custom Loss 0.6933924555778503 with ber  0.49882 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933935880661011 Custom Loss 0.6933935880661011 with ber  0.49882 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933934688568115 Custom Loss 0.6933934688568115 with ber  0.49882 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.04644465446472s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5022199999999999 learn codes ber with rayleigh  0.5022199999999999 learn codes ber with rician  0.5022199999999999 ber with awgn  0.3802333333333333 ber with rayleigh  0.39780000000000004 ber with rician  0.39049999999999996
Test SNR 5 learn codes ber with awgn  0.5017 learn codes ber with rayleigh  0.5017 learn codes ber with rician  0.5017 ber with awgn  0.2870666666666667 ber with rayleigh  0.3105666666666667 ber with rician  0.2922333333333333
Test SNR 10 learn codes ber with awgn  0.49912 learn codes ber with rayleigh  0.49912 learn codes ber with rician  0.49912 ber with awgn  0.15941666666666665 ber with rayleigh  0.18405 ber with rician  0.15041666666666667
Test SNR 15 learn codes ber with awgn  0.5025199999999999 learn codes ber with rayleigh  0.5025199999999999 learn codes ber with rician  0.5025199999999999 ber with awgn  0.03796666666666666 ber with rayleigh  0.08263333333333335 ber with rician  0.04438333333333334
Test SNR 20 learn codes ber with awgn  0.50444 learn codes ber with rayleigh  0.50444 learn codes ber with rician  0.50444 ber with awgn  0.0006833333333333333 ber with rayleigh  0.030933333333333334 ber with rician  0.010766666666666666
Test SNR 25 learn codes ber with awgn  0.49876000000000004 learn codes ber with rayleigh  0.49876000000000004 learn codes ber with rician  0.49876000000000004 ber with awgn  0.0 ber with rayleigh  0.009399999999999999 ber with rician  0.0019333333333333333
Test SNR 30 learn codes ber with awgn  0.49673999999999996 learn codes ber with rayleigh  0.49673999999999996 learn codes ber with rician  0.49673999999999996 ber with awgn  0.0 ber with rayleigh  0.0033666666666666662 ber with rician  0.0005833333333333334
Test SNR 35 learn codes ber with awgn  0.5038400000000001 learn codes ber with rayleigh  0.5038400000000001 learn codes ber with rician  0.5038400000000001 ber with awgn  0.0 ber with rayleigh  0.0008333333333333333 ber with rician  0.00023333333333333336
Test SNR 40 learn codes ber with awgn  0.50064 learn codes ber with rayleigh  0.50064 learn codes ber with rician  0.50064 ber with awgn  0.0 ber with rayleigh  0.00038333333333333334 ber with rician  6.666666666666667e-05
Test SNR 45 learn codes ber with awgn  0.49912 learn codes ber with rayleigh  0.49912 learn codes ber with rician  0.49912 ber with awgn  0.0 ber with rayleigh  0.00011666666666666668 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.49594000000000005 learn codes ber with rayleigh  0.49594000000000005 learn codes ber with rician  0.49594000000000005 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.49688 learn codes ber with rayleigh  0.49688 learn codes ber with rician  0.49688 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49895999999999996 learn codes ber with rayleigh  0.49895999999999996 learn codes ber with rician  0.49895999999999996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4989 learn codes ber with rayleigh  0.4989 learn codes ber with rician  0.4989 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.50134 learn codes ber with rayleigh  0.50134 learn codes ber with rician  0.50134 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4990200000000001 learn codes ber with rayleigh  0.4990200000000001 learn codes ber with rician  0.4990200000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.50022 learn codes ber with rayleigh  0.50022 learn codes ber with rician  0.50022 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.50126 learn codes ber with rayleigh  0.50126 learn codes ber with rician  0.50126 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5041 learn codes ber with rayleigh  0.5041 learn codes ber with rician  0.5041 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5034200000000001 learn codes ber with rayleigh  0.5034200000000001 learn codes ber with rician  0.5034200000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5022199999999999, 0.5017, 0.49912, 0.5025199999999999, 0.50444, 0.49876000000000004, 0.49673999999999996, 0.5038400000000001, 0.50064, 0.49912, 0.49594000000000005, 0.49688, 0.49895999999999996, 0.4989, 0.50134, 0.4990200000000001, 0.50022, 0.50126, 0.5041, 0.5034200000000001]
Learn Codes rayleigh [0.5022199999999999, 0.5017, 0.49912, 0.5025199999999999, 0.50444, 0.49876000000000004, 0.49673999999999996, 0.5038400000000001, 0.50064, 0.49912, 0.49594000000000005, 0.49688, 0.49895999999999996, 0.4989, 0.50134, 0.4990200000000001, 0.50022, 0.50126, 0.5041, 0.5034200000000001]
Learn Codes rician [0.5022199999999999, 0.5017, 0.49912, 0.5025199999999999, 0.50444, 0.49876000000000004, 0.49673999999999996, 0.5038400000000001, 0.50064, 0.49912, 0.49594000000000005, 0.49688, 0.49895999999999996, 0.4989, 0.50134, 0.4990200000000001, 0.50022, 0.50126, 0.5041, 0.5034200000000001]
AWGN [0.3802333333333333, 0.2870666666666667, 0.15941666666666665, 0.03796666666666666, 0.0006833333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39780000000000004, 0.3105666666666667, 0.18405, 0.08263333333333335, 0.030933333333333334, 0.009399999999999999, 0.0033666666666666662, 0.0008333333333333333, 0.00038333333333333334, 0.00011666666666666668, 0.0, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39049999999999996, 0.2922333333333333, 0.15041666666666667, 0.04438333333333334, 0.010766666666666666, 0.0019333333333333333, 0.0005833333333333334, 0.00023333333333333336, 6.666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69376962 loss Rayleigh: 0.69375523 loss Rician: 0.69374127   running time 5.227128982543945
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70035123 loss Rayleigh: 0.69937817 loss Rician: 0.70004201   running time 5.3322930335998535
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70618741 loss Rayleigh: 0.69703186 loss Rician: 0.70231353   running time 5.37658166885376
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70041426 loss Rayleigh: 0.69789289 loss Rician: 0.69665226   running time 5.31471061706543
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69449694 loss Rayleigh: 0.69482220 loss Rician: 0.69454128   running time 5.563171625137329
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69354777 loss Rayleigh: 0.69358749 loss Rician: 0.69349400   running time 5.362432241439819
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933891177177429 Custom Loss 0.6933891177177429 with ber  0.49964000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934106945991516 Custom Loss 0.6934106945991516 with ber  0.49964000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693399965763092 Custom Loss 0.693399965763092 with ber  0.49964000000000003 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.26621389389038s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338790 loss Rayleigh: 0.69338314 loss Rician: 0.69337685   running time 5.223870038986206
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69349580 loss Rayleigh: 0.69346026 loss Rician: 0.69337119   running time 5.370803356170654
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69349828 loss Rayleigh: 0.69348661 loss Rician: 0.69341530   running time 5.335821866989136
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328156 loss Rayleigh: 0.69326311 loss Rician: 0.69320019   running time 5.396331787109375
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331955 loss Rayleigh: 0.69330611 loss Rician: 0.69325255   running time 5.416738748550415
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69335448 loss Rayleigh: 0.69331908 loss Rician: 0.69321290   running time 5.35395622253418
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931961178779602 Custom Loss 0.6931961178779602 with ber  0.49774 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932390332221985 Custom Loss 0.6932390332221985 with ber  0.49774 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932405233383179 Custom Loss 0.6932405233383179 with ber  0.49774 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.2692654132843s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69317508 loss Rayleigh: 0.69317259 loss Rician: 0.69316078   running time 5.221844673156738
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69346693 loss Rayleigh: 0.69344693 loss Rician: 0.69336910   running time 5.408390045166016
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329706 loss Rayleigh: 0.69329119 loss Rician: 0.69325383   running time 5.361981630325317
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329113 loss Rayleigh: 0.69326029 loss Rician: 0.69318209   running time 5.365275144577026
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69320623 loss Rayleigh: 0.69321408 loss Rician: 0.69316588   running time 5.400953769683838
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69342973 loss Rayleigh: 0.69339551 loss Rician: 0.69333052   running time 5.326692342758179
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930161714553833 Custom Loss 0.6930161714553833 with ber  0.49788000000000004 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931161284446716 Custom Loss 0.6931161284446716 with ber  0.49788000000000004 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930878758430481 Custom Loss 0.6930878758430481 with ber  0.49788000000000004 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.291417598724365s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69313483 loss Rayleigh: 0.69312295 loss Rician: 0.69309782   running time 5.186761140823364
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69334444 loss Rayleigh: 0.69330906 loss Rician: 0.69321479   running time 5.37371301651001
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329963 loss Rayleigh: 0.69326542 loss Rician: 0.69317093   running time 5.366427183151245
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69344487 loss Rayleigh: 0.69339579 loss Rician: 0.69324721   running time 5.346506595611572
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69358884 loss Rayleigh: 0.69352628 loss Rician: 0.69337154   running time 5.3204216957092285
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329292 loss Rayleigh: 0.69327468 loss Rician: 0.69318032   running time 5.406627655029297
====> Test set BCE loss with SNR 0.0 for AWGN 0.692915141582489 Custom Loss 0.692915141582489 with ber  0.49748000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930919289588928 Custom Loss 0.6930919289588928 with ber  0.49748000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693048357963562 Custom Loss 0.693048357963562 with ber  0.49748000000000003 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.13326930999756s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69328964 loss Rayleigh: 0.69326615 loss Rician: 0.69323059   running time 5.225309371948242
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332903 loss Rayleigh: 0.69329888 loss Rician: 0.69318569   running time 5.328130006790161
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330582 loss Rayleigh: 0.69323190 loss Rician: 0.69311019   running time 5.476996898651123
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69328139 loss Rayleigh: 0.69324724 loss Rician: 0.69315278   running time 5.365057945251465
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69339319 loss Rayleigh: 0.69329845 loss Rician: 0.69312580   running time 5.354649305343628
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332210 loss Rayleigh: 0.69325089 loss Rician: 0.69298329   running time 5.621572017669678
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925171613693237 Custom Loss 0.6925171613693237 with ber  0.5069400000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932066679000854 Custom Loss 0.6932066679000854 with ber  0.5069400000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6929905414581299 Custom Loss 0.6929905414581299 with ber  0.5069400000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.37159061431885s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69341820 loss Rayleigh: 0.69332147 loss Rician: 0.69311630   running time 5.340207099914551
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69342312 loss Rayleigh: 0.69331258 loss Rician: 0.69302698   running time 5.352429628372192
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69339076 loss Rayleigh: 0.69327826 loss Rician: 0.69295543   running time 5.371069669723511
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69332377 loss Rayleigh: 0.69322357 loss Rician: 0.69280574   running time 5.43788480758667
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69342191 loss Rayleigh: 0.69335108 loss Rician: 0.69306779   running time 5.363509893417358
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69337441 loss Rayleigh: 0.69320034 loss Rician: 0.69293524   running time 5.38248348236084
====> Test set BCE loss with SNR 0.0 for AWGN 0.690997838973999 Custom Loss 0.690997838973999 with ber  0.4968 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931620240211487 Custom Loss 0.6931620240211487 with ber  0.4968 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.69237220287323 Custom Loss 0.69237220287323 with ber  0.4968 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.2358558177948s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69322467 loss Rayleigh: 0.69306334 loss Rician: 0.69232711   running time 5.211235523223877
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69351463 loss Rayleigh: 0.69330476 loss Rician: 0.69258299   running time 5.337466716766357
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69330439 loss Rayleigh: 0.69324493 loss Rician: 0.69285220   running time 5.465682506561279
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69368625 loss Rayleigh: 0.69357203 loss Rician: 0.69290639   running time 5.379204988479614
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69357921 loss Rayleigh: 0.69354219 loss Rician: 0.69277866   running time 5.3228936195373535
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69352307 loss Rayleigh: 0.69339935 loss Rician: 0.69266569   running time 5.344692945480347
====> Test set BCE loss with SNR 0.0 for AWGN 0.6916700601577759 Custom Loss 0.6916700601577759 with ber  0.49892000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931191682815552 Custom Loss 0.6931191682815552 with ber  0.49892000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6928048133850098 Custom Loss 0.6928048133850098 with ber  0.49892000000000003 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.14057636260986s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69378595 loss Rayleigh: 0.69370567 loss Rician: 0.69322532   running time 5.244773626327515
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69367038 loss Rayleigh: 0.69344702 loss Rician: 0.69299228   running time 5.355556964874268
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69396688 loss Rayleigh: 0.69382117 loss Rician: 0.69264161   running time 5.373567819595337
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69379497 loss Rayleigh: 0.69372752 loss Rician: 0.69300517   running time 5.392582178115845
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69356974 loss Rayleigh: 0.69341602 loss Rician: 0.69278728   running time 5.550799131393433
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69357771 loss Rayleigh: 0.69353082 loss Rician: 0.69215907   running time 5.399875640869141
====> Test set BCE loss with SNR 0.0 for AWGN 0.6896389722824097 Custom Loss 0.6896389722824097 with ber  0.50244 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929672956466675 Custom Loss 0.6929672956466675 with ber  0.50244 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6921641230583191 Custom Loss 0.6921641230583191 with ber  0.50244 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.41050410270691s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69367769 loss Rayleigh: 0.69345316 loss Rician: 0.69252325   running time 5.220629930496216
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69406893 loss Rayleigh: 0.69401581 loss Rician: 0.69297793   running time 5.370643138885498
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69374771 loss Rayleigh: 0.69345605 loss Rician: 0.69235916   running time 5.385629415512085
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69347354 loss Rayleigh: 0.69334766 loss Rician: 0.69255836   running time 5.387080192565918
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69346913 loss Rayleigh: 0.69333423 loss Rician: 0.69226323   running time 5.357165575027466
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336954 loss Rayleigh: 0.69333737 loss Rician: 0.69231179   running time 5.337787866592407
====> Test set BCE loss with SNR 0.0 for AWGN 0.6912237405776978 Custom Loss 0.6912237405776978 with ber  0.49728000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692883312702179 Custom Loss 0.692883312702179 with ber  0.49728000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6926213502883911 Custom Loss 0.6926213502883911 with ber  0.49728000000000006 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.27279615402222s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69319481 loss Rayleigh: 0.69317188 loss Rician: 0.69260805   running time 5.256858825683594
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69343401 loss Rayleigh: 0.69335409 loss Rician: 0.69265091   running time 5.301318883895874
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69349730 loss Rayleigh: 0.69334665 loss Rician: 0.69233388   running time 5.378053665161133
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69346407 loss Rayleigh: 0.69323738 loss Rician: 0.69222035   running time 5.385264873504639
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328791 loss Rayleigh: 0.69325348 loss Rician: 0.69168379   running time 5.3392579555511475
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69343079 loss Rayleigh: 0.69325412 loss Rician: 0.69224530   running time 5.377593755722046
====> Test set BCE loss with SNR 0.0 for AWGN 0.6919447183609009 Custom Loss 0.6919447183609009 with ber  0.5029 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930360198020935 Custom Loss 0.6930360198020935 with ber  0.5029 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6915582418441772 Custom Loss 0.6915582418441772 with ber  0.5029 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 34.18748331069946s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.50026 learn codes ber with rayleigh  0.50026 learn codes ber with rician  0.50026 ber with awgn  0.4383333333333333 ber with rayleigh  0.4557666666666667 ber with rician  0.4488666666666667
Test SNR 5 learn codes ber with awgn  0.5035800000000001 learn codes ber with rayleigh  0.5035800000000001 learn codes ber with rician  0.5035800000000001 ber with awgn  0.3938 ber with rayleigh  0.41596666666666665 ber with rician  0.4072
Test SNR 10 learn codes ber with awgn  0.50302 learn codes ber with rayleigh  0.50302 learn codes ber with rician  0.50302 ber with awgn  0.31165 ber with rayleigh  0.3320666666666666 ber with rician  0.31975000000000003
Test SNR 15 learn codes ber with awgn  0.5016400000000001 learn codes ber with rayleigh  0.5016400000000001 learn codes ber with rician  0.5016400000000001 ber with awgn  0.19678333333333334 ber with rayleigh  0.21395000000000003 ber with rician  0.1852
Test SNR 20 learn codes ber with awgn  0.50168 learn codes ber with rayleigh  0.50168 learn codes ber with rician  0.50168 ber with awgn  0.062083333333333345 ber with rayleigh  0.10461666666666666 ber with rician  0.06356666666666666
Test SNR 25 learn codes ber with awgn  0.5001800000000001 learn codes ber with rayleigh  0.5001800000000001 learn codes ber with rician  0.5001800000000001 ber with awgn  0.003 ber with rayleigh  0.04033333333333333 ber with rician  0.013733333333333334
Test SNR 30 learn codes ber with awgn  0.50194 learn codes ber with rayleigh  0.50194 learn codes ber with rician  0.50194 ber with awgn  0.0 ber with rayleigh  0.013516666666666666 ber with rician  0.0028666666666666667
Test SNR 35 learn codes ber with awgn  0.50088 learn codes ber with rayleigh  0.50088 learn codes ber with rician  0.50088 ber with awgn  0.0 ber with rayleigh  0.004216666666666667 ber with rician  0.0007833333333333333
Test SNR 40 learn codes ber with awgn  0.5001399999999999 learn codes ber with rayleigh  0.5001399999999999 learn codes ber with rician  0.5001399999999999 ber with awgn  0.0 ber with rayleigh  0.0014000000000000002 ber with rician  0.0003
Test SNR 45 learn codes ber with awgn  0.4976999999999999 learn codes ber with rayleigh  0.4976999999999999 learn codes ber with rician  0.4976999999999999 ber with awgn  0.0 ber with rayleigh  0.00045 ber with rician  0.00013333333333333334
Test SNR 50 learn codes ber with awgn  0.5036800000000001 learn codes ber with rayleigh  0.5036800000000001 learn codes ber with rician  0.5036800000000001 ber with awgn  0.0 ber with rayleigh  0.0001 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.4950799999999999 learn codes ber with rayleigh  0.4950799999999999 learn codes ber with rician  0.4950799999999999 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  1.6666666666666667e-05
Test SNR 60 learn codes ber with awgn  0.49824 learn codes ber with rayleigh  0.49824 learn codes ber with rician  0.49824 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.50276 learn codes ber with rayleigh  0.50276 learn codes ber with rician  0.50276 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49736 learn codes ber with rayleigh  0.49736 learn codes ber with rician  0.49736 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4981 learn codes ber with rayleigh  0.4981 learn codes ber with rician  0.4981 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4990799999999999 learn codes ber with rayleigh  0.4990799999999999 learn codes ber with rician  0.4990799999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49695999999999996 learn codes ber with rayleigh  0.49695999999999996 learn codes ber with rician  0.49695999999999996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49756 learn codes ber with rayleigh  0.49756 learn codes ber with rician  0.49756 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4963 learn codes ber with rayleigh  0.4963 learn codes ber with rician  0.4963 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.50026, 0.5035800000000001, 0.50302, 0.5016400000000001, 0.50168, 0.5001800000000001, 0.50194, 0.50088, 0.5001399999999999, 0.4976999999999999, 0.5036800000000001, 0.4950799999999999, 0.49824, 0.50276, 0.49736, 0.4981, 0.4990799999999999, 0.49695999999999996, 0.49756, 0.4963]
Learn Codes rayleigh [0.50026, 0.5035800000000001, 0.50302, 0.5016400000000001, 0.50168, 0.5001800000000001, 0.50194, 0.50088, 0.5001399999999999, 0.4976999999999999, 0.5036800000000001, 0.4950799999999999, 0.49824, 0.50276, 0.49736, 0.4981, 0.4990799999999999, 0.49695999999999996, 0.49756, 0.4963]
Learn Codes rician [0.50026, 0.5035800000000001, 0.50302, 0.5016400000000001, 0.50168, 0.5001800000000001, 0.50194, 0.50088, 0.5001399999999999, 0.4976999999999999, 0.5036800000000001, 0.4950799999999999, 0.49824, 0.50276, 0.49736, 0.4981, 0.4990799999999999, 0.49695999999999996, 0.49756, 0.4963]
AWGN [0.4383333333333333, 0.3938, 0.31165, 0.19678333333333334, 0.062083333333333345, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.4557666666666667, 0.41596666666666665, 0.3320666666666666, 0.21395000000000003, 0.10461666666666666, 0.04033333333333333, 0.013516666666666666, 0.004216666666666667, 0.0014000000000000002, 0.00045, 0.0001, 3.3333333333333335e-05, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4488666666666667, 0.4072, 0.31975000000000003, 0.1852, 0.06356666666666666, 0.013733333333333334, 0.0028666666666666667, 0.0007833333333333333, 0.0003, 0.00013333333333333334, 0.0, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69340472 loss Rayleigh: 0.69339512 loss Rician: 0.69337834   running time 5.014970779418945
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69924501 loss Rayleigh: 0.69859369 loss Rician: 0.69984010   running time 5.093248605728149
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69885652 loss Rayleigh: 0.69748642 loss Rician: 0.69668546   running time 5.108416557312012
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70129718 loss Rayleigh: 0.69719656 loss Rician: 0.69699707   running time 5.142822742462158
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69530188 loss Rayleigh: 0.69585482 loss Rician: 0.69453691   running time 5.093592882156372
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69447156 loss Rayleigh: 0.69447290 loss Rician: 0.69403669   running time 5.118364572525024
====> Test set BCE loss with SNR 0.0 for AWGN 0.693742573261261 Custom Loss 0.693742573261261 with ber  0.4992285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6937884092330933 Custom Loss 0.6937884092330933 with ber  0.4992285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6937652826309204 Custom Loss 0.6937652826309204 with ber  0.4992285714285714 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.42418551445007s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69397715 loss Rayleigh: 0.69397745 loss Rician: 0.69395936   running time 4.999922037124634
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69376153 loss Rayleigh: 0.69370767 loss Rician: 0.69353005   running time 5.169032573699951
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69348840 loss Rayleigh: 0.69348803 loss Rician: 0.69340063   running time 5.151386737823486
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69334036 loss Rayleigh: 0.69334132 loss Rician: 0.69328492   running time 5.156741380691528
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69335729 loss Rayleigh: 0.69333501 loss Rician: 0.69326239   running time 5.160841703414917
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331971 loss Rayleigh: 0.69329569 loss Rician: 0.69322031   running time 5.1516571044921875
====> Test set BCE loss with SNR 0.0 for AWGN 0.693304717540741 Custom Loss 0.693304717540741 with ber  0.4982285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933119893074036 Custom Loss 0.6933119893074036 with ber  0.4982285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693312406539917 Custom Loss 0.693312406539917 with ber  0.4982285714285714 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.69947385787964s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69337900 loss Rayleigh: 0.69337797 loss Rician: 0.69337634   running time 5.023962020874023
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332313 loss Rayleigh: 0.69330852 loss Rician: 0.69325388   running time 5.2178425788879395
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336681 loss Rayleigh: 0.69334239 loss Rician: 0.69328062   running time 5.3919641971588135
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329441 loss Rayleigh: 0.69328581 loss Rician: 0.69324153   running time 5.201845169067383
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329397 loss Rayleigh: 0.69328284 loss Rician: 0.69323031   running time 5.195809841156006
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69345317 loss Rayleigh: 0.69343259 loss Rician: 0.69334740   running time 5.153553009033203
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935276389122009 Custom Loss 0.6935276389122009 with ber  0.5006714285714285 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935456991195679 Custom Loss 0.6935456991195679 with ber  0.5006714285714285 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935442686080933 Custom Loss 0.6935442686080933 with ber  0.5006714285714285 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.95480227470398s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69345841 loss Rayleigh: 0.69345717 loss Rician: 0.69345198   running time 4.995701789855957
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69327404 loss Rayleigh: 0.69326258 loss Rician: 0.69321348   running time 5.226821660995483
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342973 loss Rayleigh: 0.69340854 loss Rician: 0.69334957   running time 5.1823890209198
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69332567 loss Rayleigh: 0.69331791 loss Rician: 0.69326754   running time 5.368528366088867
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69322687 loss Rayleigh: 0.69319507 loss Rician: 0.69312873   running time 7.45253324508667
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69340793 loss Rayleigh: 0.69336738 loss Rician: 0.69326630   running time 5.262058973312378
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935010552406311 Custom Loss 0.6935010552406311 with ber  0.4970714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934953927993774 Custom Loss 0.6934953927993774 with ber  0.4970714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934956908226013 Custom Loss 0.6934956908226013 with ber  0.4970714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 35.264384269714355s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69345682 loss Rayleigh: 0.69345756 loss Rician: 0.69345816   running time 4.994061231613159
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69342013 loss Rayleigh: 0.69341205 loss Rician: 0.69333729   running time 5.178506135940552
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69335734 loss Rayleigh: 0.69333879 loss Rician: 0.69325234   running time 5.0977795124053955
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69348105 loss Rayleigh: 0.69343013 loss Rician: 0.69331809   running time 5.184631824493408
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69337905 loss Rayleigh: 0.69336450 loss Rician: 0.69329551   running time 5.144792795181274
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69338307 loss Rayleigh: 0.69336039 loss Rician: 0.69328863   running time 5.205463409423828
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933943033218384 Custom Loss 0.6933943033218384 with ber  0.5004857142857142 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933897733688354 Custom Loss 0.6933897733688354 with ber  0.5004857142857142 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693390965461731 Custom Loss 0.693390965461731 with ber  0.5004857142857142 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.71143460273743s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69353847 loss Rayleigh: 0.69353900 loss Rician: 0.69353799   running time 5.07806921005249
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330911 loss Rayleigh: 0.69330072 loss Rician: 0.69325265   running time 5.1934814453125
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331797 loss Rayleigh: 0.69331330 loss Rician: 0.69326060   running time 5.208688020706177
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69340571 loss Rayleigh: 0.69337866 loss Rician: 0.69331176   running time 5.2321014404296875
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328142 loss Rayleigh: 0.69327023 loss Rician: 0.69321414   running time 5.17527174949646
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69338074 loss Rayleigh: 0.69336351 loss Rician: 0.69330601   running time 5.168096542358398
====> Test set BCE loss with SNR 0.0 for AWGN 0.693222165107727 Custom Loss 0.693222165107727 with ber  0.49902857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932234764099121 Custom Loss 0.6932234764099121 with ber  0.49902857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932224035263062 Custom Loss 0.6932224035263062 with ber  0.49902857142857143 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.811742544174194s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69319032 loss Rayleigh: 0.69318982 loss Rician: 0.69318777   running time 5.091224431991577
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331116 loss Rayleigh: 0.69329422 loss Rician: 0.69323507   running time 5.175154209136963
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69348665 loss Rayleigh: 0.69342666 loss Rician: 0.69330380   running time 5.163913249969482
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340646 loss Rayleigh: 0.69336799 loss Rician: 0.69325280   running time 5.160842418670654
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69355463 loss Rayleigh: 0.69355348 loss Rician: 0.69338102   running time 5.164491415023804
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69353952 loss Rayleigh: 0.69355678 loss Rician: 0.69343310   running time 5.286549806594849
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933649778366089 Custom Loss 0.6933649778366089 with ber  0.5013142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933648586273193 Custom Loss 0.6933648586273193 with ber  0.5013142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933648586273193 Custom Loss 0.6933648586273193 with ber  0.5013142857142857 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.9068386554718s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69340524 loss Rayleigh: 0.69340724 loss Rician: 0.69340951   running time 5.051717042922974
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343579 loss Rayleigh: 0.69341800 loss Rician: 0.69334493   running time 5.207727670669556
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337073 loss Rayleigh: 0.69335647 loss Rician: 0.69329994   running time 5.195123195648193
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323838 loss Rayleigh: 0.69321296 loss Rician: 0.69315519   running time 5.145034313201904
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337168 loss Rayleigh: 0.69336756 loss Rician: 0.69325151   running time 5.17572283744812
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69346308 loss Rayleigh: 0.69345037 loss Rician: 0.69336518   running time 5.1870338916778564
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933985948562622 Custom Loss 0.6933985948562622 with ber  0.4966857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934099793434143 Custom Loss 0.6934099793434143 with ber  0.4966857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934087872505188 Custom Loss 0.6934087872505188 with ber  0.4966857142857143 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.76246762275696s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69377924 loss Rayleigh: 0.69377919 loss Rician: 0.69378021   running time 5.031238079071045
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69353004 loss Rayleigh: 0.69347388 loss Rician: 0.69335906   running time 5.2900707721710205
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336573 loss Rayleigh: 0.69334193 loss Rician: 0.69324836   running time 5.2553746700286865
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330839 loss Rayleigh: 0.69329957 loss Rician: 0.69324631   running time 5.196584224700928
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69351828 loss Rayleigh: 0.69347601 loss Rician: 0.69331255   running time 5.208820819854736
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69345341 loss Rayleigh: 0.69342668 loss Rician: 0.69331931   running time 5.160833120346069
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935447454452515 Custom Loss 0.6935447454452515 with ber  0.4989571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935466527938843 Custom Loss 0.6935466527938843 with ber  0.4989571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935456991195679 Custom Loss 0.6935456991195679 with ber  0.4989571428571429 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.97140121459961s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69364982 loss Rayleigh: 0.69364877 loss Rician: 0.69364864   running time 5.0460779666900635
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332224 loss Rayleigh: 0.69331458 loss Rician: 0.69326346   running time 5.165247678756714
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337246 loss Rayleigh: 0.69335346 loss Rician: 0.69327980   running time 5.12639594078064
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69344502 loss Rayleigh: 0.69342583 loss Rician: 0.69334729   running time 5.170666933059692
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69343191 loss Rayleigh: 0.69342315 loss Rician: 0.69336049   running time 5.174285173416138
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69346616 loss Rayleigh: 0.69343708 loss Rician: 0.69336271   running time 5.187742471694946
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932286620140076 Custom Loss 0.6932286620140076 with ber  0.49408571428571424 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932292580604553 Custom Loss 0.6932292580604553 with ber  0.49408571428571424 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693229079246521 Custom Loss 0.693229079246521 with ber  0.49408571428571424 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 32.79059553146362s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49888571428571415 learn codes ber with rayleigh  0.49888571428571415 learn codes ber with rician  0.49888571428571415 ber with awgn  0.374625 ber with rayleigh  0.39325 ber with rician  0.38923749999999996
Test SNR 5 learn codes ber with awgn  0.5006428571428572 learn codes ber with rayleigh  0.5006428571428572 learn codes ber with rician  0.5006428571428572 ber with awgn  0.2853125 ber with rayleigh  0.30567500000000003 ber with rician  0.28937500000000005
Test SNR 10 learn codes ber with awgn  0.4990571428571428 learn codes ber with rayleigh  0.4990571428571428 learn codes ber with rician  0.4990571428571428 ber with awgn  0.15889999999999999 ber with rayleigh  0.185225 ber with rician  0.13953749999999998
Test SNR 15 learn codes ber with awgn  0.500357142857143 learn codes ber with rayleigh  0.500357142857143 learn codes ber with rician  0.500357142857143 ber with awgn  0.037475 ber with rayleigh  0.083175 ber with rician  0.035112500000000005
Test SNR 20 learn codes ber with awgn  0.49861428571428573 learn codes ber with rayleigh  0.49861428571428573 learn codes ber with rician  0.49861428571428573 ber with awgn  0.0008624999999999999 ber with rayleigh  0.029975 ber with rician  0.004349999999999999
Test SNR 25 learn codes ber with awgn  0.5019 learn codes ber with rayleigh  0.5019 learn codes ber with rician  0.5019 ber with awgn  0.0 ber with rayleigh  0.010699999999999998 ber with rician  0.0007375000000000001
Test SNR 30 learn codes ber with awgn  0.5027428571428572 learn codes ber with rayleigh  0.5027428571428572 learn codes ber with rician  0.5027428571428572 ber with awgn  0.0 ber with rayleigh  0.0034625000000000003 ber with rician  0.00013749999999999998
Test SNR 35 learn codes ber with awgn  0.49614285714285716 learn codes ber with rayleigh  0.49614285714285716 learn codes ber with rician  0.49614285714285716 ber with awgn  0.0 ber with rayleigh  0.0010500000000000002 ber with rician  5e-05
Test SNR 40 learn codes ber with awgn  0.49771428571428566 learn codes ber with rayleigh  0.49771428571428566 learn codes ber with rician  0.49771428571428566 ber with awgn  0.0 ber with rayleigh  0.0003625000000000001 ber with rician  0.0
Test SNR 45 learn codes ber with awgn  0.4979857142857143 learn codes ber with rayleigh  0.4979857142857143 learn codes ber with rician  0.4979857142857143 ber with awgn  0.0 ber with rayleigh  0.00012500000000000003 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.49922857142857147 learn codes ber with rayleigh  0.49922857142857147 learn codes ber with rician  0.49922857142857147 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5007571428571429 learn codes ber with rayleigh  0.5007571428571429 learn codes ber with rician  0.5007571428571429 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4979857142857143 learn codes ber with rayleigh  0.4979857142857143 learn codes ber with rician  0.4979857142857143 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4998428571428571 learn codes ber with rayleigh  0.4998428571428571 learn codes ber with rician  0.4998428571428571 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5000571428571428 learn codes ber with rayleigh  0.5000571428571428 learn codes ber with rician  0.5000571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4997285714285714 learn codes ber with rayleigh  0.4997285714285714 learn codes ber with rician  0.4997285714285714 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5008857142857144 learn codes ber with rayleigh  0.5008857142857144 learn codes ber with rician  0.5008857142857144 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49957142857142867 learn codes ber with rayleigh  0.49957142857142867 learn codes ber with rician  0.49957142857142867 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5027571428571428 learn codes ber with rayleigh  0.5027571428571428 learn codes ber with rician  0.5027571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5022428571428571 learn codes ber with rayleigh  0.5022428571428571 learn codes ber with rician  0.5022428571428571 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49888571428571415, 0.5006428571428572, 0.4990571428571428, 0.500357142857143, 0.49861428571428573, 0.5019, 0.5027428571428572, 0.49614285714285716, 0.49771428571428566, 0.4979857142857143, 0.49922857142857147, 0.5007571428571429, 0.4979857142857143, 0.4998428571428571, 0.5000571428571428, 0.4997285714285714, 0.5008857142857144, 0.49957142857142867, 0.5027571428571428, 0.5022428571428571]
Learn Codes rayleigh [0.49888571428571415, 0.5006428571428572, 0.4990571428571428, 0.500357142857143, 0.49861428571428573, 0.5019, 0.5027428571428572, 0.49614285714285716, 0.49771428571428566, 0.4979857142857143, 0.49922857142857147, 0.5007571428571429, 0.4979857142857143, 0.4998428571428571, 0.5000571428571428, 0.4997285714285714, 0.5008857142857144, 0.49957142857142867, 0.5027571428571428, 0.5022428571428571]
Learn Codes rician [0.49888571428571415, 0.5006428571428572, 0.4990571428571428, 0.500357142857143, 0.49861428571428573, 0.5019, 0.5027428571428572, 0.49614285714285716, 0.49771428571428566, 0.4979857142857143, 0.49922857142857147, 0.5007571428571429, 0.4979857142857143, 0.4998428571428571, 0.5000571428571428, 0.4997285714285714, 0.5008857142857144, 0.49957142857142867, 0.5027571428571428, 0.5022428571428571]
AWGN [0.374625, 0.2853125, 0.15889999999999999, 0.037475, 0.0008624999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39325, 0.30567500000000003, 0.185225, 0.083175, 0.029975, 0.010699999999999998, 0.0034625000000000003, 0.0010500000000000002, 0.0003625000000000001, 0.00012500000000000003, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.38923749999999996, 0.28937500000000005, 0.13953749999999998, 0.035112500000000005, 0.004349999999999999, 0.0007375000000000001, 0.00013749999999999998, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69350022 loss Rayleigh: 0.69348254 loss Rician: 0.69347451   running time 5.365663766860962
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70546355 loss Rayleigh: 0.70198517 loss Rician: 0.70363679   running time 7.448552370071411
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71139901 loss Rayleigh: 0.69932454 loss Rician: 0.70628195   running time 5.486603260040283
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70392731 loss Rayleigh: 0.70081384 loss Rician: 0.69776920   running time 5.55799412727356
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69591405 loss Rayleigh: 0.69597998 loss Rician: 0.69530105   running time 6.021956920623779
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69377122 loss Rayleigh: 0.69376143 loss Rician: 0.69358433   running time 5.574517726898193
====> Test set BCE loss with SNR 0.0 for AWGN 0.6938656568527222 Custom Loss 0.6938656568527222 with ber  0.5011714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6938816905021667 Custom Loss 0.6938816905021667 with ber  0.5011714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6938930749893188 Custom Loss 0.6938930749893188 with ber  0.5011714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 37.802568435668945s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69379939 loss Rayleigh: 0.69380153 loss Rician: 0.69379886   running time 5.438747406005859
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69359715 loss Rayleigh: 0.69356147 loss Rician: 0.69349464   running time 5.580011367797852
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69336942 loss Rayleigh: 0.69335847 loss Rician: 0.69330963   running time 5.590868949890137
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331976 loss Rayleigh: 0.69329776 loss Rician: 0.69324707   running time 5.500833988189697
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340684 loss Rayleigh: 0.69340156 loss Rician: 0.69334717   running time 5.531671524047852
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69339593 loss Rayleigh: 0.69337173 loss Rician: 0.69331846   running time 5.666662931442261
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933084726333618 Custom Loss 0.6933084726333618 with ber  0.5007142857142858 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.69330894947052 Custom Loss 0.69330894947052 with ber  0.5007142857142858 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933002471923828 Custom Loss 0.6933002471923828 with ber  0.5007142857142858 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.53663229942322s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330083 loss Rayleigh: 0.69329179 loss Rician: 0.69328590   running time 5.385732412338257
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69321480 loss Rayleigh: 0.69321703 loss Rician: 0.69317582   running time 5.52675199508667
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330971 loss Rayleigh: 0.69329864 loss Rician: 0.69324782   running time 5.551427125930786
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330574 loss Rayleigh: 0.69327169 loss Rician: 0.69320765   running time 5.5256452560424805
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69352424 loss Rayleigh: 0.69349009 loss Rician: 0.69341031   running time 5.654181480407715
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328185 loss Rayleigh: 0.69325283 loss Rician: 0.69318999   running time 5.5516884326934814
====> Test set BCE loss with SNR 0.0 for AWGN 0.693240761756897 Custom Loss 0.693240761756897 with ber  0.4989285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932950019836426 Custom Loss 0.6932950019836426 with ber  0.4989285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932739615440369 Custom Loss 0.6932739615440369 with ber  0.4989285714285714 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.43270707130432s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69356736 loss Rayleigh: 0.69356130 loss Rician: 0.69354903   running time 5.350751638412476
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330806 loss Rayleigh: 0.69330481 loss Rician: 0.69324209   running time 5.6221022605896
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69335952 loss Rayleigh: 0.69333315 loss Rician: 0.69327291   running time 5.528340578079224
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69336900 loss Rayleigh: 0.69331290 loss Rician: 0.69323375   running time 5.674926996231079
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69337803 loss Rayleigh: 0.69335759 loss Rician: 0.69329569   running time 5.567450046539307
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69332678 loss Rayleigh: 0.69330705 loss Rician: 0.69324319   running time 5.608138084411621
====> Test set BCE loss with SNR 0.0 for AWGN 0.693293035030365 Custom Loss 0.693293035030365 with ber  0.5041714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933079957962036 Custom Loss 0.6933079957962036 with ber  0.5041714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932991147041321 Custom Loss 0.6932991147041321 with ber  0.5041714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.51519441604614s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69335644 loss Rayleigh: 0.69335037 loss Rician: 0.69334862   running time 5.449249982833862
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69342324 loss Rayleigh: 0.69341549 loss Rician: 0.69336539   running time 5.5589704513549805
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327349 loss Rayleigh: 0.69326302 loss Rician: 0.69322242   running time 5.6586220264434814
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69329596 loss Rayleigh: 0.69328534 loss Rician: 0.69324102   running time 5.514171123504639
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326766 loss Rayleigh: 0.69325935 loss Rician: 0.69322181   running time 5.59357762336731
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69328358 loss Rayleigh: 0.69327486 loss Rician: 0.69322845   running time 5.580941915512085
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931626200675964 Custom Loss 0.6931626200675964 with ber  0.5000857142857144 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931989192962646 Custom Loss 0.6931989192962646 with ber  0.5000857142857144 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931841969490051 Custom Loss 0.6931841969490051 with ber  0.5000857142857144 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.493492126464844s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69318167 loss Rayleigh: 0.69317706 loss Rician: 0.69316469   running time 5.403177261352539
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69338145 loss Rayleigh: 0.69336390 loss Rician: 0.69330998   running time 5.630508184432983
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69323564 loss Rayleigh: 0.69322320 loss Rician: 0.69317815   running time 5.552991151809692
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331275 loss Rayleigh: 0.69328191 loss Rician: 0.69321231   running time 5.4992194175720215
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331036 loss Rayleigh: 0.69327072 loss Rician: 0.69318185   running time 5.629906892776489
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69317982 loss Rayleigh: 0.69314687 loss Rician: 0.69306636   running time 5.4967334270477295
====> Test set BCE loss with SNR 0.0 for AWGN 0.693004846572876 Custom Loss 0.693004846572876 with ber  0.5018428571428573 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932417154312134 Custom Loss 0.6932417154312134 with ber  0.5018428571428573 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931766271591187 Custom Loss 0.6931766271591187 with ber  0.5018428571428573 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.36405944824219s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331631 loss Rayleigh: 0.69327637 loss Rician: 0.69321281   running time 5.370640754699707
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69333157 loss Rayleigh: 0.69326990 loss Rician: 0.69311909   running time 5.734918594360352
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69334378 loss Rayleigh: 0.69327460 loss Rician: 0.69311013   running time 5.460127115249634
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342207 loss Rayleigh: 0.69330443 loss Rician: 0.69299031   running time 5.588947296142578
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69355351 loss Rayleigh: 0.69343026 loss Rician: 0.69318002   running time 5.513688087463379
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69332945 loss Rayleigh: 0.69314263 loss Rician: 0.69280685   running time 5.5433900356292725
====> Test set BCE loss with SNR 0.0 for AWGN 0.6918586492538452 Custom Loss 0.6918586492538452 with ber  0.49974285714285716 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936174035072327 Custom Loss 0.6936174035072327 with ber  0.49974285714285716 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6928800344467163 Custom Loss 0.6928800344467163 with ber  0.49974285714285716 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.36809253692627s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69365191 loss Rayleigh: 0.69347997 loss Rician: 0.69285744   running time 5.561755657196045
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343576 loss Rayleigh: 0.69329960 loss Rician: 0.69250635   running time 5.569983959197998
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337842 loss Rayleigh: 0.69337407 loss Rician: 0.69242624   running time 5.613396167755127
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69354467 loss Rayleigh: 0.69324667 loss Rician: 0.69208532   running time 5.556227922439575
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339498 loss Rayleigh: 0.69330224 loss Rician: 0.69189376   running time 5.525078296661377
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69338865 loss Rayleigh: 0.69334414 loss Rician: 0.69238029   running time 5.54111123085022
====> Test set BCE loss with SNR 0.0 for AWGN 0.6907292604446411 Custom Loss 0.6907292604446411 with ber  0.5003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693053126335144 Custom Loss 0.693053126335144 with ber  0.5003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6926305890083313 Custom Loss 0.6926305890083313 with ber  0.5003 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.60015296936035s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69339333 loss Rayleigh: 0.69333537 loss Rician: 0.69255336   running time 5.360748052597046
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69335467 loss Rayleigh: 0.69329377 loss Rician: 0.69172919   running time 5.6098952293396
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69328089 loss Rayleigh: 0.69327474 loss Rician: 0.69104356   running time 5.511185884475708
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69353337 loss Rayleigh: 0.69327898 loss Rician: 0.69092965   running time 5.858194589614868
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69335821 loss Rayleigh: 0.69311237 loss Rician: 0.69238497   running time 6.054385185241699
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69339784 loss Rayleigh: 0.69316292 loss Rician: 0.69111024   running time 5.514667510986328
====> Test set BCE loss with SNR 0.0 for AWGN 0.6882671117782593 Custom Loss 0.6882671117782593 with ber  0.5010714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933928728103638 Custom Loss 0.6933928728103638 with ber  0.5010714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6912405490875244 Custom Loss 0.6912405490875244 with ber  0.5010714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 36.229204177856445s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337326 loss Rayleigh: 0.69310840 loss Rician: 0.69081188   running time 5.3557655811309814
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334483 loss Rayleigh: 0.69328856 loss Rician: 0.69083446   running time 5.5128703117370605
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331776 loss Rayleigh: 0.69319764 loss Rician: 0.69088221   running time 5.515580415725708
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332741 loss Rayleigh: 0.69322318 loss Rician: 0.69074160   running time 5.578036546707153
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69342026 loss Rayleigh: 0.69337886 loss Rician: 0.69050539   running time 5.542636394500732
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69353762 loss Rayleigh: 0.69317077 loss Rician: 0.69128867   running time 5.6087963581085205
====> Test set BCE loss with SNR 0.0 for AWGN 0.6901304125785828 Custom Loss 0.6901304125785828 with ber  0.49912857142857153 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934771537780762 Custom Loss 0.6934771537780762 with ber  0.49912857142857153 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6909226179122925 Custom Loss 0.6909226179122925 with ber  0.49912857142857153 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 35.55698013305664s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5011285714285714 learn codes ber with rayleigh  0.5011285714285714 learn codes ber with rician  0.5011285714285714 ber with awgn  0.4425375 ber with rayleigh  0.4529000000000001 ber with rician  0.45176250000000007
Test SNR 5 learn codes ber with awgn  0.49971428571428567 learn codes ber with rayleigh  0.49971428571428567 learn codes ber with rician  0.49971428571428567 ber with awgn  0.39031249999999995 ber with rayleigh  0.4111249999999999 ber with rician  0.4015625
Test SNR 10 learn codes ber with awgn  0.5019571428571429 learn codes ber with rayleigh  0.5019571428571429 learn codes ber with rician  0.5019571428571429 ber with awgn  0.3119624999999999 ber with rayleigh  0.3325625 ber with rician  0.3175875
Test SNR 15 learn codes ber with awgn  0.49998571428571437 learn codes ber with rayleigh  0.49998571428571437 learn codes ber with rician  0.49998571428571437 ber with awgn  0.192875 ber with rayleigh  0.2148125 ber with rician  0.176575
Test SNR 20 learn codes ber with awgn  0.49907142857142855 learn codes ber with rayleigh  0.49907142857142855 learn codes ber with rician  0.49907142857142855 ber with awgn  0.0627 ber with rayleigh  0.1046 ber with rician  0.052375000000000005
Test SNR 25 learn codes ber with awgn  0.5004571428571428 learn codes ber with rayleigh  0.5004571428571428 learn codes ber with rician  0.5004571428571428 ber with awgn  0.0031375 ber with rayleigh  0.03901249999999999 ber with rician  0.00765
Test SNR 30 learn codes ber with awgn  0.5019714285714286 learn codes ber with rayleigh  0.5019714285714286 learn codes ber with rician  0.5019714285714286 ber with awgn  0.0 ber with rayleigh  0.013974999999999998 ber with rician  0.00115
Test SNR 35 learn codes ber with awgn  0.5016714285714285 learn codes ber with rayleigh  0.5016714285714285 learn codes ber with rician  0.5016714285714285 ber with awgn  0.0 ber with rayleigh  0.003987500000000001 ber with rician  0.0002375
Test SNR 40 learn codes ber with awgn  0.5007714285714285 learn codes ber with rayleigh  0.5007714285714285 learn codes ber with rician  0.5007714285714285 ber with awgn  0.0 ber with rayleigh  0.0013624999999999998 ber with rician  3.7500000000000003e-05
Test SNR 45 learn codes ber with awgn  0.5049428571428571 learn codes ber with rayleigh  0.5049428571428571 learn codes ber with rician  0.5049428571428571 ber with awgn  0.0 ber with rayleigh  0.0004125000000000001 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.5025285714285713 learn codes ber with rayleigh  0.5025285714285713 learn codes ber with rician  0.5025285714285713 ber with awgn  0.0 ber with rayleigh  7.500000000000001e-05 ber with rician  1.25e-05
Test SNR 55 learn codes ber with awgn  0.4980285714285714 learn codes ber with rayleigh  0.4980285714285714 learn codes ber with rician  0.4980285714285714 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5012571428571428 learn codes ber with rayleigh  0.5012571428571428 learn codes ber with rician  0.5012571428571428 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5015714285714286 learn codes ber with rayleigh  0.5015714285714286 learn codes ber with rician  0.5015714285714286 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49770000000000003 learn codes ber with rayleigh  0.49770000000000003 learn codes ber with rician  0.49770000000000003 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5015285714285714 learn codes ber with rayleigh  0.5015285714285714 learn codes ber with rician  0.5015285714285714 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49940000000000007 learn codes ber with rayleigh  0.49940000000000007 learn codes ber with rician  0.49940000000000007 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49787142857142863 learn codes ber with rayleigh  0.49787142857142863 learn codes ber with rician  0.49787142857142863 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5002285714285715 learn codes ber with rayleigh  0.5002285714285715 learn codes ber with rician  0.5002285714285715 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5023428571428571 learn codes ber with rayleigh  0.5023428571428571 learn codes ber with rician  0.5023428571428571 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5011285714285714, 0.49971428571428567, 0.5019571428571429, 0.49998571428571437, 0.49907142857142855, 0.5004571428571428, 0.5019714285714286, 0.5016714285714285, 0.5007714285714285, 0.5049428571428571, 0.5025285714285713, 0.4980285714285714, 0.5012571428571428, 0.5015714285714286, 0.49770000000000003, 0.5015285714285714, 0.49940000000000007, 0.49787142857142863, 0.5002285714285715, 0.5023428571428571]
Learn Codes rayleigh [0.5011285714285714, 0.49971428571428567, 0.5019571428571429, 0.49998571428571437, 0.49907142857142855, 0.5004571428571428, 0.5019714285714286, 0.5016714285714285, 0.5007714285714285, 0.5049428571428571, 0.5025285714285713, 0.4980285714285714, 0.5012571428571428, 0.5015714285714286, 0.49770000000000003, 0.5015285714285714, 0.49940000000000007, 0.49787142857142863, 0.5002285714285715, 0.5023428571428571]
Learn Codes rician [0.5011285714285714, 0.49971428571428567, 0.5019571428571429, 0.49998571428571437, 0.49907142857142855, 0.5004571428571428, 0.5019714285714286, 0.5016714285714285, 0.5007714285714285, 0.5049428571428571, 0.5025285714285713, 0.4980285714285714, 0.5012571428571428, 0.5015714285714286, 0.49770000000000003, 0.5015285714285714, 0.49940000000000007, 0.49787142857142863, 0.5002285714285715, 0.5023428571428571]
AWGN [0.4425375, 0.39031249999999995, 0.3119624999999999, 0.192875, 0.0627, 0.0031375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.4529000000000001, 0.4111249999999999, 0.3325625, 0.2148125, 0.1046, 0.03901249999999999, 0.013974999999999998, 0.003987500000000001, 0.0013624999999999998, 0.0004125000000000001, 7.500000000000001e-05, 5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45176250000000007, 0.4015625, 0.3175875, 0.176575, 0.052375000000000005, 0.00765, 0.00115, 0.0002375, 3.7500000000000003e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69402325 loss Rayleigh: 0.69400136 loss Rician: 0.69397473   running time 11.89928412437439
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70177128 loss Rayleigh: 0.70041606 loss Rician: 0.70657570   running time 12.267398595809937
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70709603 loss Rayleigh: 0.69819567 loss Rician: 0.70027192   running time 12.022356271743774
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70011066 loss Rayleigh: 0.69669742 loss Rician: 0.69853088   running time 12.213423490524292
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69443634 loss Rayleigh: 0.69466496 loss Rician: 0.69437636   running time 12.141377925872803
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69367521 loss Rayleigh: 0.69361949 loss Rician: 0.69347016   running time 12.012287855148315
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934528946876526 Custom Loss 0.6934528946876526 with ber  0.4992 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935092210769653 Custom Loss 0.6935092210769653 with ber  0.4992 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934983134269714 Custom Loss 0.6934983134269714 with ber  0.4992 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.1095404624939s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69356282 loss Rayleigh: 0.69353809 loss Rician: 0.69353791   running time 12.075333833694458
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324423 loss Rayleigh: 0.69322323 loss Rician: 0.69318154   running time 12.054652690887451
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331170 loss Rayleigh: 0.69330553 loss Rician: 0.69325219   running time 12.056927680969238
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69318253 loss Rayleigh: 0.69316147 loss Rician: 0.69312102   running time 12.23508620262146
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69325829 loss Rayleigh: 0.69323179 loss Rician: 0.69317232   running time 12.030384063720703
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324573 loss Rayleigh: 0.69321502 loss Rician: 0.69314710   running time 12.168455362319946
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930140852928162 Custom Loss 0.6930140852928162 with ber  0.5013166666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693162202835083 Custom Loss 0.693162202835083 with ber  0.5013166666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931240558624268 Custom Loss 0.6931240558624268 with ber  0.5013166666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.09311318397522s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69315009 loss Rayleigh: 0.69311551 loss Rician: 0.69308378   running time 12.104146003723145
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323277 loss Rayleigh: 0.69319509 loss Rician: 0.69308565   running time 12.020275592803955
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69344580 loss Rayleigh: 0.69337488 loss Rician: 0.69320068   running time 12.120848655700684
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69350177 loss Rayleigh: 0.69332653 loss Rician: 0.69303156   running time 12.142138481140137
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69346174 loss Rayleigh: 0.69297693 loss Rician: 0.69191820   running time 11.942772626876831
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69350933 loss Rayleigh: 0.69347639 loss Rician: 0.69332365   running time 12.253599882125854
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932172775268555 Custom Loss 0.6932172775268555 with ber  0.4990166666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932796835899353 Custom Loss 0.6932796835899353 with ber  0.4990166666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932383179664612 Custom Loss 0.6932383179664612 with ber  0.4990166666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.07887578010559s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69323412 loss Rayleigh: 0.69322850 loss Rician: 0.69320613   running time 11.956416130065918
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69336988 loss Rayleigh: 0.69334171 loss Rician: 0.69324391   running time 11.969918251037598
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333750 loss Rayleigh: 0.69333544 loss Rician: 0.69321778   running time 12.169989585876465
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69327173 loss Rayleigh: 0.69322213 loss Rician: 0.69303064   running time 11.982076168060303
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69328040 loss Rayleigh: 0.69317160 loss Rician: 0.69289158   running time 12.1679208278656
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69343163 loss Rayleigh: 0.69331509 loss Rician: 0.69272655   running time 12.125761032104492
====> Test set BCE loss with SNR 0.0 for AWGN 0.6910317540168762 Custom Loss 0.6910317540168762 with ber  0.5008999999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692864179611206 Custom Loss 0.692864179611206 with ber  0.5008999999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6923090219497681 Custom Loss 0.6923090219497681 with ber  0.5008999999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 75.98000240325928s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69321485 loss Rayleigh: 0.69305344 loss Rician: 0.69243882   running time 11.810092449188232
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325090 loss Rayleigh: 0.69286764 loss Rician: 0.69177964   running time 12.232768774032593
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69337947 loss Rayleigh: 0.69300441 loss Rician: 0.69157170   running time 14.991954565048218
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69338937 loss Rayleigh: 0.69299145 loss Rician: 0.69189510   running time 12.158027410507202
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69328494 loss Rayleigh: 0.69293012 loss Rician: 0.69098122   running time 12.02275538444519
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69368492 loss Rayleigh: 0.69300433 loss Rician: 0.69103172   running time 12.298870086669922
====> Test set BCE loss with SNR 0.0 for AWGN 0.6904548406600952 Custom Loss 0.6904548406600952 with ber  0.49995 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932024955749512 Custom Loss 0.6932024955749512 with ber  0.49995 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.691704511642456 Custom Loss 0.691704511642456 with ber  0.49995 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 79.04059481620789s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69334957 loss Rayleigh: 0.69322877 loss Rician: 0.69185483   running time 11.926528453826904
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69357378 loss Rayleigh: 0.69317186 loss Rician: 0.69141638   running time 12.033217906951904
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69339086 loss Rayleigh: 0.69298711 loss Rician: 0.69113984   running time 12.228315830230713
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69336947 loss Rayleigh: 0.69292399 loss Rician: 0.69057150   running time 11.981842279434204
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333317 loss Rayleigh: 0.69249290 loss Rician: 0.69058356   running time 12.136804580688477
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330826 loss Rayleigh: 0.69286994 loss Rician: 0.69047542   running time 12.136186122894287
====> Test set BCE loss with SNR 0.0 for AWGN 0.6884846091270447 Custom Loss 0.6884846091270447 with ber  0.49704999999999994 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.69256192445755 Custom Loss 0.69256192445755 with ber  0.49704999999999994 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.68989497423172 Custom Loss 0.68989497423172 with ber  0.49704999999999994 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.04293775558472s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327058 loss Rayleigh: 0.69288285 loss Rician: 0.69066674   running time 11.925168991088867
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340361 loss Rayleigh: 0.69261748 loss Rician: 0.68949592   running time 12.145994424819946
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336558 loss Rayleigh: 0.69287901 loss Rician: 0.69103217   running time 12.029093265533447
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69330283 loss Rayleigh: 0.69276334 loss Rician: 0.69052572   running time 12.173275232315063
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69334006 loss Rayleigh: 0.69271156 loss Rician: 0.69061191   running time 12.199912309646606
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69343808 loss Rayleigh: 0.69276797 loss Rician: 0.69065140   running time 12.010250568389893
====> Test set BCE loss with SNR 0.0 for AWGN 0.6877089142799377 Custom Loss 0.6877089142799377 with ber  0.49958333333333327 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935093998908997 Custom Loss 0.6935093998908997 with ber  0.49958333333333327 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6910422444343567 Custom Loss 0.6910422444343567 with ber  0.49958333333333327 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.09401226043701s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69376814 loss Rayleigh: 0.69317966 loss Rician: 0.69132679   running time 11.879344701766968
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69361490 loss Rayleigh: 0.69304010 loss Rician: 0.69076640   running time 12.271512508392334
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69342641 loss Rayleigh: 0.69301480 loss Rician: 0.69053283   running time 12.024539470672607
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69334588 loss Rayleigh: 0.69292546 loss Rician: 0.69004107   running time 12.229990005493164
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69353690 loss Rayleigh: 0.69300091 loss Rician: 0.69124933   running time 12.129379272460938
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69329885 loss Rayleigh: 0.69271668 loss Rician: 0.69027592   running time 12.42783498764038
====> Test set BCE loss with SNR 0.0 for AWGN 0.6860231757164001 Custom Loss 0.6860231757164001 with ber  0.4983000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929508447647095 Custom Loss 0.6929508447647095 with ber  0.4983000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.689647912979126 Custom Loss 0.689647912979126 with ber  0.4983000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.50703120231628s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69352695 loss Rayleigh: 0.69297918 loss Rician: 0.69028735   running time 12.024823188781738
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69342330 loss Rayleigh: 0.69264428 loss Rician: 0.69052699   running time 12.075833320617676
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329433 loss Rayleigh: 0.69267364 loss Rician: 0.68979286   running time 12.17629623413086
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69353896 loss Rayleigh: 0.69292983 loss Rician: 0.69005005   running time 12.07909607887268
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69410360 loss Rayleigh: 0.69300227 loss Rician: 0.69099258   running time 12.541291236877441
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69491912 loss Rayleigh: 0.69394798 loss Rician: 0.69130818   running time 12.14570951461792
====> Test set BCE loss with SNR 0.0 for AWGN 0.6869188547134399 Custom Loss 0.6869188547134399 with ber  0.49976666666666664 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933517456054688 Custom Loss 0.6933517456054688 with ber  0.49976666666666664 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6905679702758789 Custom Loss 0.6905679702758789 with ber  0.49976666666666664 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.54536986351013s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69417676 loss Rayleigh: 0.69372724 loss Rician: 0.69185250   running time 11.916949272155762
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69662396 loss Rayleigh: 0.69585708 loss Rician: 0.69347776   running time 11.925056219100952
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.73084722 loss Rayleigh: 0.78218650 loss Rician: 0.70661979   running time 12.198559045791626
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.89414195 loss Rayleigh: 0.88685185 loss Rician: 1.03826249   running time 11.974077701568604
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.71167880 loss Rayleigh: 0.72217885 loss Rician: 0.71575198   running time 12.085582494735718
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.70413385 loss Rayleigh: 0.70530478 loss Rician: 0.70590035   running time 12.027967929840088
====> Test set BCE loss with SNR 0.0 for AWGN 0.696179986000061 Custom Loss 0.696179986000061 with ber  0.4951833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6959754228591919 Custom Loss 0.6959754228591919 with ber  0.4951833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.696050763130188 Custom Loss 0.696050763130188 with ber  0.4951833333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 75.6696228981018s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5019166666666666 learn codes ber with rayleigh  0.5019166666666666 learn codes ber with rician  0.5019166666666666 ber with awgn  0.3736 ber with rayleigh  0.3948125 ber with rician  0.39385
Test SNR 5 learn codes ber with awgn  0.49948333333333333 learn codes ber with rayleigh  0.49948333333333333 learn codes ber with rician  0.49948333333333333 ber with awgn  0.2856875 ber with rayleigh  0.30413750000000006 ber with rician  0.29436249999999997
Test SNR 10 learn codes ber with awgn  0.4970833333333332 learn codes ber with rayleigh  0.4970833333333332 learn codes ber with rician  0.4970833333333332 ber with awgn  0.159175 ber with rayleigh  0.18402499999999997 ber with rician  0.15738749999999999
Test SNR 15 learn codes ber with awgn  0.5008166666666666 learn codes ber with rayleigh  0.5008166666666666 learn codes ber with rician  0.5008166666666666 ber with awgn  0.0376875 ber with rayleigh  0.08312500000000002 ber with rician  0.056937499999999995
Test SNR 20 learn codes ber with awgn  0.4986166666666666 learn codes ber with rayleigh  0.4986166666666666 learn codes ber with rician  0.4986166666666666 ber with awgn  0.000775 ber with rayleigh  0.03055 ber with rician  0.015650000000000004
Test SNR 25 learn codes ber with awgn  0.5012833333333333 learn codes ber with rayleigh  0.5012833333333333 learn codes ber with rician  0.5012833333333333 ber with awgn  0.0 ber with rayleigh  0.009837499999999997 ber with rician  0.0048
Test SNR 30 learn codes ber with awgn  0.5000166666666666 learn codes ber with rayleigh  0.5000166666666666 learn codes ber with rician  0.5000166666666666 ber with awgn  0.0 ber with rayleigh  0.0032875 ber with rician  0.0016
Test SNR 35 learn codes ber with awgn  0.5005166666666667 learn codes ber with rayleigh  0.5005166666666667 learn codes ber with rician  0.5005166666666667 ber with awgn  0.0 ber with rayleigh  0.0011374999999999998 ber with rician  0.0004125000000000001
Test SNR 40 learn codes ber with awgn  0.5015666666666666 learn codes ber with rayleigh  0.5015666666666666 learn codes ber with rician  0.5015666666666666 ber with awgn  0.0 ber with rayleigh  0.00031250000000000006 ber with rician  0.000125
Test SNR 45 learn codes ber with awgn  0.5023666666666667 learn codes ber with rayleigh  0.5023666666666667 learn codes ber with rician  0.5023666666666667 ber with awgn  0.0 ber with rayleigh  0.00011250000000000001 ber with rician  3.7500000000000003e-05
Test SNR 50 learn codes ber with awgn  0.5009333333333335 learn codes ber with rayleigh  0.5009333333333335 learn codes ber with rician  0.5009333333333335 ber with awgn  0.0 ber with rayleigh  6.25e-05 ber with rician  1.25e-05
Test SNR 55 learn codes ber with awgn  0.4998666666666667 learn codes ber with rayleigh  0.4998666666666667 learn codes ber with rician  0.4998666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5032166666666666 learn codes ber with rayleigh  0.5032166666666666 learn codes ber with rician  0.5032166666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5016 learn codes ber with rayleigh  0.5016 learn codes ber with rician  0.5016 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5011666666666666 learn codes ber with rayleigh  0.5011666666666666 learn codes ber with rician  0.5011666666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5003833333333333 learn codes ber with rayleigh  0.5003833333333333 learn codes ber with rician  0.5003833333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5035166666666667 learn codes ber with rayleigh  0.5035166666666667 learn codes ber with rician  0.5035166666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5019166666666667 learn codes ber with rayleigh  0.5019166666666667 learn codes ber with rician  0.5019166666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49946666666666656 learn codes ber with rayleigh  0.49946666666666656 learn codes ber with rician  0.49946666666666656 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.502 learn codes ber with rayleigh  0.502 learn codes ber with rician  0.502 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5019166666666666, 0.49948333333333333, 0.4970833333333332, 0.5008166666666666, 0.4986166666666666, 0.5012833333333333, 0.5000166666666666, 0.5005166666666667, 0.5015666666666666, 0.5023666666666667, 0.5009333333333335, 0.4998666666666667, 0.5032166666666666, 0.5016, 0.5011666666666666, 0.5003833333333333, 0.5035166666666667, 0.5019166666666667, 0.49946666666666656, 0.502]
Learn Codes rayleigh [0.5019166666666666, 0.49948333333333333, 0.4970833333333332, 0.5008166666666666, 0.4986166666666666, 0.5012833333333333, 0.5000166666666666, 0.5005166666666667, 0.5015666666666666, 0.5023666666666667, 0.5009333333333335, 0.4998666666666667, 0.5032166666666666, 0.5016, 0.5011666666666666, 0.5003833333333333, 0.5035166666666667, 0.5019166666666667, 0.49946666666666656, 0.502]
Learn Codes rician [0.5019166666666666, 0.49948333333333333, 0.4970833333333332, 0.5008166666666666, 0.4986166666666666, 0.5012833333333333, 0.5000166666666666, 0.5005166666666667, 0.5015666666666666, 0.5023666666666667, 0.5009333333333335, 0.4998666666666667, 0.5032166666666666, 0.5016, 0.5011666666666666, 0.5003833333333333, 0.5035166666666667, 0.5019166666666667, 0.49946666666666656, 0.502]
AWGN [0.3736, 0.2856875, 0.159175, 0.0376875, 0.000775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3948125, 0.30413750000000006, 0.18402499999999997, 0.08312500000000002, 0.03055, 0.009837499999999997, 0.0032875, 0.0011374999999999998, 0.00031250000000000006, 0.00011250000000000001, 6.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39385, 0.29436249999999997, 0.15738749999999999, 0.056937499999999995, 0.015650000000000004, 0.0048, 0.0016, 0.0004125000000000001, 0.000125, 3.7500000000000003e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69320813 loss Rayleigh: 0.69320700 loss Rician: 0.69320305   running time 13.042290449142456
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70980688 loss Rayleigh: 0.70684437 loss Rician: 0.70566767   running time 12.647830724716187
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70800824 loss Rayleigh: 0.70304338 loss Rician: 0.70031308   running time 12.578535556793213
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69422948 loss Rayleigh: 0.69439794 loss Rician: 0.69380844   running time 12.608548402786255
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69389589 loss Rayleigh: 0.69372002 loss Rician: 0.69342623   running time 12.332922458648682
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69334971 loss Rayleigh: 0.69323719 loss Rician: 0.69310809   running time 12.53934121131897
====> Test set BCE loss with SNR 0.0 for AWGN 0.6923720240592957 Custom Loss 0.6923720240592957 with ber  0.5002333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930356025695801 Custom Loss 0.6930356025695801 with ber  0.5002333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6926625967025757 Custom Loss 0.6926625967025757 with ber  0.5002333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.54808497428894s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69323072 loss Rayleigh: 0.69314953 loss Rician: 0.69292017   running time 12.547805070877075
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69335716 loss Rayleigh: 0.69319222 loss Rician: 0.69296281   running time 12.531580209732056
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69322516 loss Rayleigh: 0.69292887 loss Rician: 0.69247281   running time 12.65689992904663
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69323968 loss Rayleigh: 0.69285656 loss Rician: 0.69174899   running time 12.449023962020874
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324883 loss Rayleigh: 0.69287254 loss Rician: 0.69195545   running time 12.669450759887695
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69341885 loss Rayleigh: 0.69303659 loss Rician: 0.69184160   running time 12.500314712524414
====> Test set BCE loss with SNR 0.0 for AWGN 0.6892567873001099 Custom Loss 0.6892567873001099 with ber  0.5019333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692704439163208 Custom Loss 0.692704439163208 with ber  0.5019333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6910414695739746 Custom Loss 0.6910414695739746 with ber  0.5019333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.33851099014282s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69344166 loss Rayleigh: 0.69303339 loss Rician: 0.69214082   running time 12.451879739761353
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325064 loss Rayleigh: 0.69289582 loss Rician: 0.69191956   running time 12.532255172729492
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329212 loss Rayleigh: 0.69280114 loss Rician: 0.69187939   running time 12.55700945854187
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69342985 loss Rayleigh: 0.69283354 loss Rician: 0.69121804   running time 12.399230241775513
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324145 loss Rayleigh: 0.69280895 loss Rician: 0.69117306   running time 12.603514194488525
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325552 loss Rayleigh: 0.69287742 loss Rician: 0.69096705   running time 12.481831312179565
====> Test set BCE loss with SNR 0.0 for AWGN 0.6894049644470215 Custom Loss 0.6894049644470215 with ber  0.4993833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928181052207947 Custom Loss 0.6928181052207947 with ber  0.4993833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6901232004165649 Custom Loss 0.6901232004165649 with ber  0.4993833333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.03185176849365s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69317103 loss Rayleigh: 0.69271805 loss Rician: 0.69160654   running time 12.400550842285156
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342093 loss Rayleigh: 0.69306044 loss Rician: 0.69141433   running time 12.580383062362671
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325665 loss Rayleigh: 0.69275218 loss Rician: 0.69167085   running time 12.674650192260742
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69323679 loss Rayleigh: 0.69274742 loss Rician: 0.69112098   running time 12.469225883483887
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330884 loss Rayleigh: 0.69275030 loss Rician: 0.69127353   running time 12.554628849029541
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333815 loss Rayleigh: 0.69293264 loss Rician: 0.69131908   running time 12.447742223739624
====> Test set BCE loss with SNR 0.0 for AWGN 0.6873155832290649 Custom Loss 0.6873155832290649 with ber  0.49903333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928750276565552 Custom Loss 0.6928750276565552 with ber  0.49903333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6889038681983948 Custom Loss 0.6889038681983948 with ber  0.49903333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.07480335235596s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69338441 loss Rayleigh: 0.69286011 loss Rician: 0.69116207   running time 12.282275199890137
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319910 loss Rayleigh: 0.69261730 loss Rician: 0.69125886   running time 12.578431367874146
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326819 loss Rayleigh: 0.69280053 loss Rician: 0.69117382   running time 12.403420448303223
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323188 loss Rayleigh: 0.69283927 loss Rician: 0.69124275   running time 12.670164585113525
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326104 loss Rayleigh: 0.69302091 loss Rician: 0.69141114   running time 12.338995933532715
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69338240 loss Rayleigh: 0.69269977 loss Rician: 0.69127982   running time 12.59373950958252
====> Test set BCE loss with SNR 0.0 for AWGN 0.6858175992965698 Custom Loss 0.6858175992965698 with ber  0.49881666666666663 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926494836807251 Custom Loss 0.6926494836807251 with ber  0.49881666666666663 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.689245343208313 Custom Loss 0.689245343208313 with ber  0.49881666666666663 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.88942193984985s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69325852 loss Rayleigh: 0.69286809 loss Rician: 0.69134094   running time 12.891277551651001
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69332523 loss Rayleigh: 0.69302972 loss Rician: 0.69117007   running time 12.57993459701538
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69327653 loss Rayleigh: 0.69274620 loss Rician: 0.69122559   running time 12.360502004623413
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69334944 loss Rayleigh: 0.69272311 loss Rician: 0.69124602   running time 12.536604404449463
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69327038 loss Rayleigh: 0.69283354 loss Rician: 0.69092946   running time 12.403193473815918
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330537 loss Rayleigh: 0.69283873 loss Rician: 0.69075767   running time 12.581081867218018
====> Test set BCE loss with SNR 0.0 for AWGN 0.6871448159217834 Custom Loss 0.6871448159217834 with ber  0.49989999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925859451293945 Custom Loss 0.6925859451293945 with ber  0.49989999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6888428926467896 Custom Loss 0.6888428926467896 with ber  0.49989999999999996 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.26789426803589s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69323945 loss Rayleigh: 0.69256308 loss Rician: 0.69107336   running time 12.312325716018677
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69321017 loss Rayleigh: 0.69270411 loss Rician: 0.69121569   running time 12.486901044845581
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327397 loss Rayleigh: 0.69304500 loss Rician: 0.69145621   running time 12.413697719573975
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69332340 loss Rayleigh: 0.69260958 loss Rician: 0.69171691   running time 12.542251110076904
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331211 loss Rayleigh: 0.69275588 loss Rician: 0.69125501   running time 12.529895782470703
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69323132 loss Rayleigh: 0.69292918 loss Rician: 0.69134033   running time 12.528664112091064
====> Test set BCE loss with SNR 0.0 for AWGN 0.6899155974388123 Custom Loss 0.6899155974388123 with ber  0.5016833333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925674676895142 Custom Loss 0.6925674676895142 with ber  0.5016833333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6896708607673645 Custom Loss 0.6896708607673645 with ber  0.5016833333333334 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.64413213729858s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69316272 loss Rayleigh: 0.69275947 loss Rician: 0.69133689   running time 12.544783115386963
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69329880 loss Rayleigh: 0.69263380 loss Rician: 0.69158883   running time 12.321410655975342
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337081 loss Rayleigh: 0.69309679 loss Rician: 0.69110045   running time 12.54305911064148
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69349640 loss Rayleigh: 0.69290080 loss Rician: 0.69130806   running time 12.423556566238403
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335185 loss Rayleigh: 0.69276383 loss Rician: 0.69127825   running time 12.621493101119995
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69351795 loss Rayleigh: 0.69299455 loss Rician: 0.69188216   running time 12.337938070297241
====> Test set BCE loss with SNR 0.0 for AWGN 0.6858206987380981 Custom Loss 0.6858206987380981 with ber  0.5007166666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927343606948853 Custom Loss 0.6927343606948853 with ber  0.5007166666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6894441843032837 Custom Loss 0.6894441843032837 with ber  0.5007166666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.7320146560669s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69351723 loss Rayleigh: 0.69283141 loss Rician: 0.69124491   running time 12.368881940841675
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69357500 loss Rayleigh: 0.69313041 loss Rician: 0.69100657   running time 12.51881742477417
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69354829 loss Rayleigh: 0.69324986 loss Rician: 0.69092169   running time 12.566136837005615
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69374509 loss Rayleigh: 0.69352670 loss Rician: 0.69182098   running time 12.417751550674438
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69337677 loss Rayleigh: 0.69289081 loss Rician: 0.69168797   running time 12.588439226150513
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69359555 loss Rayleigh: 0.69307414 loss Rician: 0.69115366   running time 12.417125701904297
====> Test set BCE loss with SNR 0.0 for AWGN 0.6907056570053101 Custom Loss 0.6907056570053101 with ber  0.49985 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927855610847473 Custom Loss 0.6927855610847473 with ber  0.49985 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6903440356254578 Custom Loss 0.6903440356254578 with ber  0.49985 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.86822962760925s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69350914 loss Rayleigh: 0.69309685 loss Rician: 0.69239476   running time 12.226099729537964
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337915 loss Rayleigh: 0.69280162 loss Rician: 0.69127264   running time 12.59888482093811
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69344237 loss Rayleigh: 0.69295929 loss Rician: 0.69161426   running time 12.38104796409607
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329824 loss Rayleigh: 0.69296110 loss Rician: 0.69165863   running time 12.635916233062744
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337814 loss Rayleigh: 0.69300858 loss Rician: 0.69093787   running time 12.410742282867432
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332955 loss Rayleigh: 0.69265116 loss Rician: 0.69148980   running time 12.598698854446411
====> Test set BCE loss with SNR 0.0 for AWGN 0.6863021850585938 Custom Loss 0.6863021850585938 with ber  0.5004833333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926047801971436 Custom Loss 0.6926047801971436 with ber  0.5004833333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.688409149646759 Custom Loss 0.688409149646759 with ber  0.5004833333333334 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.75454497337341s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.501 learn codes ber with rayleigh  0.501 learn codes ber with rician  0.501 ber with awgn  0.4380750000000001 ber with rayleigh  0.45535000000000003 ber with rician  0.45181250000000006
Test SNR 5 learn codes ber with awgn  0.5004333333333333 learn codes ber with rayleigh  0.5004333333333333 learn codes ber with rician  0.5004333333333333 ber with awgn  0.3922875 ber with rayleigh  0.41408750000000005 ber with rician  0.4086625
Test SNR 10 learn codes ber with awgn  0.49634999999999996 learn codes ber with rayleigh  0.49634999999999996 learn codes ber with rician  0.49634999999999996 ber with awgn  0.31625 ber with rayleigh  0.32935000000000003 ber with rician  0.32275
Test SNR 15 learn codes ber with awgn  0.49955 learn codes ber with rayleigh  0.49955 learn codes ber with rician  0.49955 ber with awgn  0.191925 ber with rayleigh  0.21586249999999998 ber with rician  0.19501249999999998
Test SNR 20 learn codes ber with awgn  0.5019500000000001 learn codes ber with rayleigh  0.5019500000000001 learn codes ber with rician  0.5019500000000001 ber with awgn  0.0600625 ber with rayleigh  0.10124999999999999 ber with rician  0.0762625
Test SNR 25 learn codes ber with awgn  0.5002000000000001 learn codes ber with rayleigh  0.5002000000000001 learn codes ber with rician  0.5002000000000001 ber with awgn  0.003075 ber with rayleigh  0.038825000000000005 ber with rician  0.021712500000000003
Test SNR 30 learn codes ber with awgn  0.4982333333333332 learn codes ber with rayleigh  0.4982333333333332 learn codes ber with rician  0.4982333333333332 ber with awgn  0.0 ber with rayleigh  0.012537499999999998 ber with rician  0.0063
Test SNR 35 learn codes ber with awgn  0.49729999999999996 learn codes ber with rayleigh  0.49729999999999996 learn codes ber with rician  0.49729999999999996 ber with awgn  0.0 ber with rayleigh  0.004999999999999999 ber with rician  0.0019
Test SNR 40 learn codes ber with awgn  0.5001 learn codes ber with rayleigh  0.5001 learn codes ber with rician  0.5001 ber with awgn  0.0 ber with rayleigh  0.0012749999999999999 ber with rician  0.0006375
Test SNR 45 learn codes ber with awgn  0.49939999999999996 learn codes ber with rayleigh  0.49939999999999996 learn codes ber with rician  0.49939999999999996 ber with awgn  0.0 ber with rayleigh  0.0005 ber with rician  0.00017500000000000003
Test SNR 50 learn codes ber with awgn  0.4997 learn codes ber with rayleigh  0.4997 learn codes ber with rician  0.4997 ber with awgn  0.0 ber with rayleigh  0.00015000000000000001 ber with rician  5e-05
Test SNR 55 learn codes ber with awgn  0.5002666666666666 learn codes ber with rayleigh  0.5002666666666666 learn codes ber with rician  0.5002666666666666 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  1.25e-05
Test SNR 60 learn codes ber with awgn  0.5032833333333333 learn codes ber with rayleigh  0.5032833333333333 learn codes ber with rician  0.5032833333333333 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.49700000000000005 learn codes ber with rayleigh  0.49700000000000005 learn codes ber with rician  0.49700000000000005 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5002500000000001 learn codes ber with rayleigh  0.5002500000000001 learn codes ber with rician  0.5002500000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5014333333333333 learn codes ber with rayleigh  0.5014333333333333 learn codes ber with rician  0.5014333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5031999999999999 learn codes ber with rayleigh  0.5031999999999999 learn codes ber with rician  0.5031999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49803333333333333 learn codes ber with rayleigh  0.49803333333333333 learn codes ber with rician  0.49803333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.4963 learn codes ber with rayleigh  0.4963 learn codes ber with rician  0.4963 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5005 learn codes ber with rayleigh  0.5005 learn codes ber with rician  0.5005 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.501, 0.5004333333333333, 0.49634999999999996, 0.49955, 0.5019500000000001, 0.5002000000000001, 0.4982333333333332, 0.49729999999999996, 0.5001, 0.49939999999999996, 0.4997, 0.5002666666666666, 0.5032833333333333, 0.49700000000000005, 0.5002500000000001, 0.5014333333333333, 0.5031999999999999, 0.49803333333333333, 0.4963, 0.5005]
Learn Codes rayleigh [0.501, 0.5004333333333333, 0.49634999999999996, 0.49955, 0.5019500000000001, 0.5002000000000001, 0.4982333333333332, 0.49729999999999996, 0.5001, 0.49939999999999996, 0.4997, 0.5002666666666666, 0.5032833333333333, 0.49700000000000005, 0.5002500000000001, 0.5014333333333333, 0.5031999999999999, 0.49803333333333333, 0.4963, 0.5005]
Learn Codes rician [0.501, 0.5004333333333333, 0.49634999999999996, 0.49955, 0.5019500000000001, 0.5002000000000001, 0.4982333333333332, 0.49729999999999996, 0.5001, 0.49939999999999996, 0.4997, 0.5002666666666666, 0.5032833333333333, 0.49700000000000005, 0.5002500000000001, 0.5014333333333333, 0.5031999999999999, 0.49803333333333333, 0.4963, 0.5005]
AWGN [0.4380750000000001, 0.3922875, 0.31625, 0.191925, 0.0600625, 0.003075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45535000000000003, 0.41408750000000005, 0.32935000000000003, 0.21586249999999998, 0.10124999999999999, 0.038825000000000005, 0.012537499999999998, 0.004999999999999999, 0.0012749999999999999, 0.0005, 0.00015000000000000001, 2.5e-05, 2.5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45181250000000006, 0.4086625, 0.32275, 0.19501249999999998, 0.0762625, 0.021712500000000003, 0.0063, 0.0019, 0.0006375, 0.00017500000000000003, 5e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69344790 loss Rayleigh: 0.69344028 loss Rician: 0.69342688   running time 12.842473268508911
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71520181 loss Rayleigh: 0.72080773 loss Rician: 0.70934585   running time 12.113671064376831
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71720759 loss Rayleigh: 0.70531042 loss Rician: 0.71879516   running time 12.247953176498413
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69768964 loss Rayleigh: 0.69811006 loss Rician: 0.69615346   running time 12.078120470046997
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69379311 loss Rayleigh: 0.69378893 loss Rician: 0.69370540   running time 12.197788000106812
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69331611 loss Rayleigh: 0.69330573 loss Rician: 0.69325033   running time 12.131365060806274
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930744051933289 Custom Loss 0.6930744051933289 with ber  0.4978599999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932018995285034 Custom Loss 0.6932018995285034 with ber  0.4978599999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693143367767334 Custom Loss 0.693143367767334 with ber  0.4978599999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 77.36635327339172s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324073 loss Rayleigh: 0.69320060 loss Rician: 0.69315842   running time 11.946200132369995
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69336335 loss Rayleigh: 0.69331236 loss Rician: 0.69324941   running time 12.165118217468262
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331973 loss Rayleigh: 0.69325081 loss Rician: 0.69312359   running time 12.180855989456177
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328638 loss Rayleigh: 0.69312319 loss Rician: 0.69293994   running time 12.106670379638672
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338512 loss Rayleigh: 0.69303205 loss Rician: 0.69256512   running time 12.152655839920044
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69366562 loss Rayleigh: 0.69271644 loss Rician: 0.69125360   running time 12.019428014755249
====> Test set BCE loss with SNR 0.0 for AWGN 0.6859860420227051 Custom Loss 0.6859860420227051 with ber  0.50116 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6920589208602905 Custom Loss 0.6920589208602905 with ber  0.50116 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6877163648605347 Custom Loss 0.6877163648605347 with ber  0.50116 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.18329906463623s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323269 loss Rayleigh: 0.69219682 loss Rician: 0.69010153   running time 11.963136196136475
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69356775 loss Rayleigh: 0.69273853 loss Rician: 0.69150630   running time 12.159233093261719
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69335486 loss Rayleigh: 0.69216113 loss Rician: 0.68936999   running time 12.021162033081055
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69352030 loss Rayleigh: 0.69186410 loss Rician: 0.68897736   running time 12.30359697341919
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328324 loss Rayleigh: 0.69202746 loss Rician: 0.68788237   running time 12.063565015792847
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69343446 loss Rayleigh: 0.69194909 loss Rician: 0.68774379   running time 12.266928911209106
====> Test set BCE loss with SNR 0.0 for AWGN 0.6882856488227844 Custom Loss 0.6882856488227844 with ber  0.50023 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6912411451339722 Custom Loss 0.6912411451339722 with ber  0.50023 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6858664155006409 Custom Loss 0.6858664155006409 with ber  0.50023 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.28596186637878s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325594 loss Rayleigh: 0.69152760 loss Rician: 0.68841792   running time 12.204299211502075
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69349598 loss Rayleigh: 0.69189358 loss Rician: 0.68745651   running time 12.115697860717773
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69337857 loss Rayleigh: 0.69162915 loss Rician: 0.68734717   running time 12.261342763900757
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338593 loss Rayleigh: 0.69149189 loss Rician: 0.68669435   running time 12.085957527160645
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338654 loss Rayleigh: 0.69157256 loss Rician: 0.68669171   running time 12.535390138626099
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342697 loss Rayleigh: 0.69151862 loss Rician: 0.68644333   running time 12.062764644622803
====> Test set BCE loss with SNR 0.0 for AWGN 0.68439781665802 Custom Loss 0.68439781665802 with ber  0.50102 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6921818256378174 Custom Loss 0.6921818256378174 with ber  0.50102 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6828857064247131 Custom Loss 0.6828857064247131 with ber  0.50102 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.86966037750244s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69356166 loss Rayleigh: 0.69226962 loss Rician: 0.68709947   running time 12.04232120513916
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69347361 loss Rayleigh: 0.69171208 loss Rician: 0.68701558   running time 12.214455127716064
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69336055 loss Rayleigh: 0.69171984 loss Rician: 0.68700091   running time 12.153295040130615
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69347379 loss Rayleigh: 0.69200035 loss Rician: 0.68699352   running time 12.03781771659851
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69358906 loss Rayleigh: 0.69166892 loss Rician: 0.68643193   running time 12.224254369735718
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69363286 loss Rayleigh: 0.69190938 loss Rician: 0.68790509   running time 12.041728496551514
====> Test set BCE loss with SNR 0.0 for AWGN 0.6872925758361816 Custom Loss 0.6872925758361816 with ber  0.49883999999999995 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6913794875144958 Custom Loss 0.6913794875144958 with ber  0.49883999999999995 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6842528581619263 Custom Loss 0.6842528581619263 with ber  0.49883999999999995 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.46209955215454s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333551 loss Rayleigh: 0.69135569 loss Rician: 0.68759633   running time 11.8591947555542
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330978 loss Rayleigh: 0.69172889 loss Rician: 0.68726345   running time 12.24136996269226
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69339886 loss Rayleigh: 0.69199442 loss Rician: 0.68683562   running time 14.268415451049805
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333781 loss Rayleigh: 0.69171085 loss Rician: 0.68603845   running time 12.097246408462524
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333087 loss Rayleigh: 0.69180449 loss Rician: 0.68589747   running time 12.166367053985596
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69326628 loss Rayleigh: 0.69166980 loss Rician: 0.68562022   running time 12.066582441329956
====> Test set BCE loss with SNR 0.0 for AWGN 0.6817496418952942 Custom Loss 0.6817496418952942 with ber  0.49772000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6917634010314941 Custom Loss 0.6917634010314941 with ber  0.49772000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.682409405708313 Custom Loss 0.682409405708313 with ber  0.49772000000000005 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 78.29577279090881s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69414957 loss Rayleigh: 0.69196945 loss Rician: 0.68516108   running time 11.91773271560669
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69355764 loss Rayleigh: 0.69171512 loss Rician: 0.68670610   running time 12.066471338272095
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69335141 loss Rayleigh: 0.69156736 loss Rician: 0.68689867   running time 12.240625858306885
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342496 loss Rayleigh: 0.69190238 loss Rician: 0.68654286   running time 12.059320211410522
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69330426 loss Rayleigh: 0.69191208 loss Rician: 0.68616963   running time 12.127629280090332
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336424 loss Rayleigh: 0.69178245 loss Rician: 0.68549692   running time 12.060745239257812
====> Test set BCE loss with SNR 0.0 for AWGN 0.6884146928787231 Custom Loss 0.6884146928787231 with ber  0.49817999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6913570165634155 Custom Loss 0.6913570165634155 with ber  0.49817999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6838997006416321 Custom Loss 0.6838997006416321 with ber  0.49817999999999996 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.11734509468079s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335486 loss Rayleigh: 0.69182538 loss Rician: 0.68652868   running time 11.995197057723999
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69333193 loss Rayleigh: 0.69221866 loss Rician: 0.68679245   running time 12.158419847488403
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335222 loss Rayleigh: 0.69177541 loss Rician: 0.68576893   running time 12.09343934059143
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69334461 loss Rayleigh: 0.69158941 loss Rician: 0.68537455   running time 12.3980073928833
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343080 loss Rayleigh: 0.69179535 loss Rician: 0.68572447   running time 12.041597604751587
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337529 loss Rayleigh: 0.69180151 loss Rician: 0.68588296   running time 11.981337547302246
====> Test set BCE loss with SNR 0.0 for AWGN 0.6847738027572632 Custom Loss 0.6847738027572632 with ber  0.50286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6912814378738403 Custom Loss 0.6912814378738403 with ber  0.50286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6816974878311157 Custom Loss 0.6816974878311157 with ber  0.50286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.3834958076477s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69338559 loss Rayleigh: 0.69156191 loss Rician: 0.68532140   running time 12.068808555603027
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336095 loss Rayleigh: 0.69182416 loss Rician: 0.68579310   running time 12.055656433105469
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69340819 loss Rayleigh: 0.69149981 loss Rician: 0.68576109   running time 12.008580207824707
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69338999 loss Rayleigh: 0.69167010 loss Rician: 0.68655956   running time 12.185685873031616
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333804 loss Rayleigh: 0.69191427 loss Rician: 0.68599622   running time 11.980184555053711
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69364013 loss Rayleigh: 0.69198324 loss Rician: 0.68607163   running time 12.288807392120361
====> Test set BCE loss with SNR 0.0 for AWGN 0.6909469366073608 Custom Loss 0.6909469366073608 with ber  0.50128 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6915010213851929 Custom Loss 0.6915010213851929 with ber  0.50128 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6846669912338257 Custom Loss 0.6846669912338257 with ber  0.50128 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.13523411750793s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334950 loss Rayleigh: 0.69180239 loss Rician: 0.68781660   running time 12.038863897323608
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328679 loss Rayleigh: 0.69161142 loss Rician: 0.68669910   running time 12.077318668365479
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69346988 loss Rayleigh: 0.69150189 loss Rician: 0.68613551   running time 12.101799726486206
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329614 loss Rayleigh: 0.69175196 loss Rician: 0.68578373   running time 12.202045202255249
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69361520 loss Rayleigh: 0.69199549 loss Rician: 0.68514003   running time 12.16159725189209
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334702 loss Rayleigh: 0.69178134 loss Rician: 0.68559994   running time 12.174414873123169
====> Test set BCE loss with SNR 0.0 for AWGN 0.68156898021698 Custom Loss 0.68156898021698 with ber  0.49777000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6918425559997559 Custom Loss 0.6918425559997559 with ber  0.49777000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6817196607589722 Custom Loss 0.6817196607589722 with ber  0.49777000000000005 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.3252785205841s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5024 learn codes ber with rayleigh  0.5024 learn codes ber with rician  0.5024 ber with awgn  0.3758666666666667 ber with rayleigh  0.39621666666666666 ber with rician  0.3899916666666667
Test SNR 5 learn codes ber with awgn  0.50178 learn codes ber with rayleigh  0.50178 learn codes ber with rician  0.50178 ber with awgn  0.28729166666666667 ber with rayleigh  0.3076083333333334 ber with rician  0.29098333333333326
Test SNR 10 learn codes ber with awgn  0.49982 learn codes ber with rayleigh  0.49982 learn codes ber with rician  0.49982 ber with awgn  0.16021666666666667 ber with rayleigh  0.1846 ber with rician  0.15009999999999998
Test SNR 15 learn codes ber with awgn  0.5001800000000001 learn codes ber with rayleigh  0.5001800000000001 learn codes ber with rician  0.5001800000000001 ber with awgn  0.03883333333333333 ber with rayleigh  0.08279166666666665 ber with rician  0.04507500000000001
Test SNR 20 learn codes ber with awgn  0.50049 learn codes ber with rayleigh  0.50049 learn codes ber with rician  0.50049 ber with awgn  0.0006833333333333333 ber with rayleigh  0.03068333333333333 ber with rician  0.009366666666666667
Test SNR 25 learn codes ber with awgn  0.49842000000000003 learn codes ber with rayleigh  0.49842000000000003 learn codes ber with rician  0.49842000000000003 ber with awgn  0.0 ber with rayleigh  0.009908333333333335 ber with rician  0.0019916666666666668
Test SNR 30 learn codes ber with awgn  0.49832 learn codes ber with rayleigh  0.49832 learn codes ber with rician  0.49832 ber with awgn  0.0 ber with rayleigh  0.0030499999999999998 ber with rician  0.0006166666666666666
Test SNR 35 learn codes ber with awgn  0.50136 learn codes ber with rayleigh  0.50136 learn codes ber with rician  0.50136 ber with awgn  0.0 ber with rayleigh  0.0012083333333333336 ber with rician  0.0002333333333333333
Test SNR 40 learn codes ber with awgn  0.49722999999999995 learn codes ber with rayleigh  0.49722999999999995 learn codes ber with rician  0.49722999999999995 ber with awgn  0.0 ber with rayleigh  0.00038333333333333334 ber with rician  5e-05
Test SNR 45 learn codes ber with awgn  0.50046 learn codes ber with rayleigh  0.50046 learn codes ber with rician  0.50046 ber with awgn  0.0 ber with rayleigh  0.00011666666666666665 ber with rician  4.1666666666666665e-05
Test SNR 50 learn codes ber with awgn  0.5 learn codes ber with rayleigh  0.5 learn codes ber with rician  0.5 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  8.333333333333334e-06
Test SNR 55 learn codes ber with awgn  0.49914000000000003 learn codes ber with rayleigh  0.49914000000000003 learn codes ber with rician  0.49914000000000003 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49964 learn codes ber with rayleigh  0.49964 learn codes ber with rician  0.49964 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.49836 learn codes ber with rayleigh  0.49836 learn codes ber with rician  0.49836 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49609000000000003 learn codes ber with rayleigh  0.49609000000000003 learn codes ber with rician  0.49609000000000003 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5001399999999999 learn codes ber with rayleigh  0.5001399999999999 learn codes ber with rician  0.5001399999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49966999999999995 learn codes ber with rayleigh  0.49966999999999995 learn codes ber with rician  0.49966999999999995 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5004299999999999 learn codes ber with rayleigh  0.5004299999999999 learn codes ber with rician  0.5004299999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5019199999999999 learn codes ber with rayleigh  0.5019199999999999 learn codes ber with rician  0.5019199999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49824999999999997 learn codes ber with rayleigh  0.49824999999999997 learn codes ber with rician  0.49824999999999997 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5024, 0.50178, 0.49982, 0.5001800000000001, 0.50049, 0.49842000000000003, 0.49832, 0.50136, 0.49722999999999995, 0.50046, 0.5, 0.49914000000000003, 0.49964, 0.49836, 0.49609000000000003, 0.5001399999999999, 0.49966999999999995, 0.5004299999999999, 0.5019199999999999, 0.49824999999999997]
Learn Codes rayleigh [0.5024, 0.50178, 0.49982, 0.5001800000000001, 0.50049, 0.49842000000000003, 0.49832, 0.50136, 0.49722999999999995, 0.50046, 0.5, 0.49914000000000003, 0.49964, 0.49836, 0.49609000000000003, 0.5001399999999999, 0.49966999999999995, 0.5004299999999999, 0.5019199999999999, 0.49824999999999997]
Learn Codes rician [0.5024, 0.50178, 0.49982, 0.5001800000000001, 0.50049, 0.49842000000000003, 0.49832, 0.50136, 0.49722999999999995, 0.50046, 0.5, 0.49914000000000003, 0.49964, 0.49836, 0.49609000000000003, 0.5001399999999999, 0.49966999999999995, 0.5004299999999999, 0.5019199999999999, 0.49824999999999997]
AWGN [0.3758666666666667, 0.28729166666666667, 0.16021666666666667, 0.03883333333333333, 0.0006833333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39621666666666666, 0.3076083333333334, 0.1846, 0.08279166666666665, 0.03068333333333333, 0.009908333333333335, 0.0030499999999999998, 0.0012083333333333336, 0.00038333333333333334, 0.00011666666666666665, 2.5e-05, 8.333333333333334e-06, 0.0, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3899916666666667, 0.29098333333333326, 0.15009999999999998, 0.04507500000000001, 0.009366666666666667, 0.0019916666666666668, 0.0006166666666666666, 0.0002333333333333333, 5e-05, 4.1666666666666665e-05, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69324756 loss Rayleigh: 0.69324740 loss Rician: 0.69325425   running time 12.357593059539795
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71720687 loss Rayleigh: 0.70792949 loss Rician: 0.70843957   running time 12.617065191268921
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.72816395 loss Rayleigh: 0.71103888 loss Rician: 0.71730942   running time 12.563562393188477
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70898585 loss Rayleigh: 0.69913523 loss Rician: 0.70073285   running time 12.951525688171387
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69466012 loss Rayleigh: 0.69468150 loss Rician: 0.69451644   running time 12.536681652069092
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69356153 loss Rayleigh: 0.69358901 loss Rician: 0.69352425   running time 12.736371994018555
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932321786880493 Custom Loss 0.6932321786880493 with ber  0.5013500000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933894753456116 Custom Loss 0.6933894753456116 with ber  0.5013500000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693371593952179 Custom Loss 0.693371593952179 with ber  0.5013500000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.7859570980072s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69344056 loss Rayleigh: 0.69342441 loss Rician: 0.69340974   running time 12.436762571334839
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328873 loss Rayleigh: 0.69327463 loss Rician: 0.69322777   running time 12.650995254516602
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69377878 loss Rayleigh: 0.69369012 loss Rician: 0.69355617   running time 12.55790376663208
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69341443 loss Rayleigh: 0.69336349 loss Rician: 0.69323362   running time 12.782093524932861
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69329419 loss Rayleigh: 0.69325123 loss Rician: 0.69314298   running time 12.505013942718506
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340572 loss Rayleigh: 0.69329757 loss Rician: 0.69311417   running time 12.61350965499878
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925376653671265 Custom Loss 0.6925376653671265 with ber  0.4975300000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931359767913818 Custom Loss 0.6931359767913818 with ber  0.4975300000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930176615715027 Custom Loss 0.6930176615715027 with ber  0.4975300000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.59331941604614s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324442 loss Rayleigh: 0.69319296 loss Rician: 0.69301683   running time 12.403345346450806
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69338078 loss Rayleigh: 0.69327680 loss Rician: 0.69306358   running time 12.628430128097534
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69337075 loss Rayleigh: 0.69316928 loss Rician: 0.69265841   running time 12.559128999710083
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69327949 loss Rayleigh: 0.69305818 loss Rician: 0.69224748   running time 12.603419542312622
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324281 loss Rayleigh: 0.69305328 loss Rician: 0.69070233   running time 12.610780239105225
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69339318 loss Rayleigh: 0.69312526 loss Rician: 0.69084830   running time 12.637396097183228
====> Test set BCE loss with SNR 0.0 for AWGN 0.6866768598556519 Custom Loss 0.6866768598556519 with ber  0.49803 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927021145820618 Custom Loss 0.6927021145820618 with ber  0.49803 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.690702497959137 Custom Loss 0.690702497959137 with ber  0.49803 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.57463216781616s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69320250 loss Rayleigh: 0.69289621 loss Rician: 0.69091988   running time 12.450146675109863
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69334460 loss Rayleigh: 0.69309026 loss Rician: 0.69078521   running time 12.651766061782837
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69332479 loss Rayleigh: 0.69293560 loss Rician: 0.68946174   running time 12.431870460510254
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338317 loss Rayleigh: 0.69294823 loss Rician: 0.68944805   running time 12.556547164916992
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69335212 loss Rayleigh: 0.69304188 loss Rician: 0.68989550   running time 12.632544755935669
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342553 loss Rayleigh: 0.69320566 loss Rician: 0.68961154   running time 12.706361532211304
====> Test set BCE loss with SNR 0.0 for AWGN 0.683508038520813 Custom Loss 0.683508038520813 with ber  0.50173 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692996621131897 Custom Loss 0.692996621131897 with ber  0.50173 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6890772581100464 Custom Loss 0.6890772581100464 with ber  0.50173 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.39926934242249s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69342930 loss Rayleigh: 0.69313344 loss Rician: 0.68973435   running time 12.664195537567139
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69378858 loss Rayleigh: 0.69343965 loss Rician: 0.69127378   running time 12.5731782913208
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69342541 loss Rayleigh: 0.69321530 loss Rician: 0.69194955   running time 12.881491899490356
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69350819 loss Rayleigh: 0.69317673 loss Rician: 0.69174356   running time 12.58230710029602
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332609 loss Rayleigh: 0.69288489 loss Rician: 0.69002162   running time 14.350709438323975
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326107 loss Rayleigh: 0.69297246 loss Rician: 0.69002125   running time 12.780889749526978
====> Test set BCE loss with SNR 0.0 for AWGN 0.6845377683639526 Custom Loss 0.6845377683639526 with ber  0.4997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934484839439392 Custom Loss 0.6934484839439392 with ber  0.4997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.689383864402771 Custom Loss 0.689383864402771 with ber  0.4997 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.97434568405151s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69345684 loss Rayleigh: 0.69319951 loss Rician: 0.69004046   running time 12.373745679855347
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69355839 loss Rayleigh: 0.69328547 loss Rician: 0.69024521   running time 12.69668197631836
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328390 loss Rayleigh: 0.69306237 loss Rician: 0.68932011   running time 12.591943264007568
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328303 loss Rayleigh: 0.69279434 loss Rician: 0.68882768   running time 12.734809160232544
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331244 loss Rayleigh: 0.69281631 loss Rician: 0.68865772   running time 12.461499214172363
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333596 loss Rayleigh: 0.69301451 loss Rician: 0.68956581   running time 12.821049213409424
====> Test set BCE loss with SNR 0.0 for AWGN 0.682155966758728 Custom Loss 0.682155966758728 with ber  0.5007699999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6924694776535034 Custom Loss 0.6924694776535034 with ber  0.5007699999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6881224513053894 Custom Loss 0.6881224513053894 with ber  0.5007699999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.81440258026123s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69317028 loss Rayleigh: 0.69276760 loss Rician: 0.68894933   running time 12.470271587371826
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69333768 loss Rayleigh: 0.69304915 loss Rician: 0.68875907   running time 12.729443073272705
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327243 loss Rayleigh: 0.69310723 loss Rician: 0.68874164   running time 12.418899059295654
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329584 loss Rayleigh: 0.69308487 loss Rician: 0.68843406   running time 12.655999183654785
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69324372 loss Rayleigh: 0.69295225 loss Rician: 0.68846124   running time 12.643489837646484
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69334299 loss Rayleigh: 0.69292146 loss Rician: 0.68891750   running time 12.729799509048462
====> Test set BCE loss with SNR 0.0 for AWGN 0.6841111183166504 Custom Loss 0.6841111183166504 with ber  0.49957 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6924546957015991 Custom Loss 0.6924546957015991 with ber  0.49957 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6875702738761902 Custom Loss 0.6875702738761902 with ber  0.49957 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 79.67762112617493s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69325126 loss Rayleigh: 0.69278664 loss Rician: 0.68815841   running time 12.403454065322876
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69329189 loss Rayleigh: 0.69312299 loss Rician: 0.68817774   running time 14.008616209030151
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69327783 loss Rayleigh: 0.69270504 loss Rician: 0.68846297   running time 12.395900011062622
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323071 loss Rayleigh: 0.69295042 loss Rician: 0.68826219   running time 12.941721200942993
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323900 loss Rayleigh: 0.69290361 loss Rician: 0.68924271   running time 12.51155138015747
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69325981 loss Rayleigh: 0.69279028 loss Rician: 0.68820931   running time 12.444905042648315
====> Test set BCE loss with SNR 0.0 for AWGN 0.6886079907417297 Custom Loss 0.6886079907417297 with ber  0.49887 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927304863929749 Custom Loss 0.6927304863929749 with ber  0.49887 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.687884509563446 Custom Loss 0.687884509563446 with ber  0.49887 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 80.87849521636963s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69316665 loss Rayleigh: 0.69281530 loss Rician: 0.68841567   running time 12.312398672103882
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69326180 loss Rayleigh: 0.69315460 loss Rician: 0.68928863   running time 12.592381954193115
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69327121 loss Rayleigh: 0.69296752 loss Rician: 0.68897179   running time 12.429895162582397
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69327647 loss Rayleigh: 0.69274355 loss Rician: 0.68855503   running time 12.606362342834473
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69326919 loss Rayleigh: 0.69294266 loss Rician: 0.68871748   running time 12.380200386047363
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329137 loss Rayleigh: 0.69297360 loss Rician: 0.68832123   running time 12.61111330986023
====> Test set BCE loss with SNR 0.0 for AWGN 0.6817417740821838 Custom Loss 0.6817417740821838 with ber  0.49956000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926182508468628 Custom Loss 0.6926182508468628 with ber  0.49956000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6871220469474792 Custom Loss 0.6871220469474792 with ber  0.49956000000000006 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.96938133239746s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69325357 loss Rayleigh: 0.69297270 loss Rician: 0.68802662   running time 12.369266033172607
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69319470 loss Rayleigh: 0.69259982 loss Rician: 0.68844137   running time 12.524461269378662
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69324782 loss Rayleigh: 0.69293422 loss Rician: 0.68805668   running time 12.484600067138672
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332289 loss Rayleigh: 0.69277659 loss Rician: 0.68831140   running time 12.550655841827393
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336450 loss Rayleigh: 0.69287398 loss Rician: 0.68824492   running time 12.47992467880249
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69324545 loss Rayleigh: 0.69267474 loss Rician: 0.68841546   running time 12.51726222038269
====> Test set BCE loss with SNR 0.0 for AWGN 0.688866376876831 Custom Loss 0.688866376876831 with ber  0.5003000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929416656494141 Custom Loss 0.6929416656494141 with ber  0.5003000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6872153282165527 Custom Loss 0.6872153282165527 with ber  0.5003000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 78.97094631195068s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49851 learn codes ber with rayleigh  0.49851 learn codes ber with rician  0.49851 ber with awgn  0.4375916666666667 ber with rayleigh  0.4531333333333333 ber with rician  0.4501083333333334
Test SNR 5 learn codes ber with awgn  0.4988900000000001 learn codes ber with rayleigh  0.4988900000000001 learn codes ber with rician  0.4988900000000001 ber with awgn  0.39325 ber with rayleigh  0.41152500000000003 ber with rician  0.4073666666666667
Test SNR 10 learn codes ber with awgn  0.4983099999999999 learn codes ber with rayleigh  0.4983099999999999 learn codes ber with rician  0.4983099999999999 ber with awgn  0.310525 ber with rayleigh  0.33119166666666666 ber with rician  0.3184833333333333
Test SNR 15 learn codes ber with awgn  0.5043500000000001 learn codes ber with rayleigh  0.5043500000000001 learn codes ber with rician  0.5043500000000001 ber with awgn  0.19272499999999998 ber with rayleigh  0.21708333333333335 ber with rician  0.18346666666666664
Test SNR 20 learn codes ber with awgn  0.5006700000000001 learn codes ber with rayleigh  0.5006700000000001 learn codes ber with rician  0.5006700000000001 ber with awgn  0.06134166666666666 ber with rayleigh  0.10400000000000001 ber with rician  0.06187500000000001
Test SNR 25 learn codes ber with awgn  0.49928 learn codes ber with rayleigh  0.49928 learn codes ber with rician  0.49928 ber with awgn  0.0030416666666666665 ber with rayleigh  0.03941666666666667 ber with rician  0.01391666666666667
Test SNR 30 learn codes ber with awgn  0.50051 learn codes ber with rayleigh  0.50051 learn codes ber with rician  0.50051 ber with awgn  0.0 ber with rayleigh  0.0137 ber with rician  0.003275
Test SNR 35 learn codes ber with awgn  0.50056 learn codes ber with rayleigh  0.50056 learn codes ber with rician  0.50056 ber with awgn  0.0 ber with rayleigh  0.004208333333333333 ber with rician  0.0008833333333333334
Test SNR 40 learn codes ber with awgn  0.4991 learn codes ber with rayleigh  0.4991 learn codes ber with rician  0.4991 ber with awgn  0.0 ber with rayleigh  0.0013666666666666666 ber with rician  0.0002583333333333333
Test SNR 45 learn codes ber with awgn  0.49919 learn codes ber with rayleigh  0.49919 learn codes ber with rician  0.49919 ber with awgn  0.0 ber with rayleigh  0.000375 ber with rician  7.500000000000001e-05
Test SNR 50 learn codes ber with awgn  0.49809000000000003 learn codes ber with rayleigh  0.49809000000000003 learn codes ber with rician  0.49809000000000003 ber with awgn  0.0 ber with rayleigh  0.00015833333333333332 ber with rician  3.3333333333333335e-05
Test SNR 55 learn codes ber with awgn  0.49853000000000003 learn codes ber with rayleigh  0.49853000000000003 learn codes ber with rician  0.49853000000000003 ber with awgn  0.0 ber with rayleigh  6.666666666666667e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.50266 learn codes ber with rayleigh  0.50266 learn codes ber with rician  0.50266 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.50153 learn codes ber with rayleigh  0.50153 learn codes ber with rician  0.50153 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.50196 learn codes ber with rayleigh  0.50196 learn codes ber with rician  0.50196 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49962999999999996 learn codes ber with rayleigh  0.49962999999999996 learn codes ber with rician  0.49962999999999996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5015 learn codes ber with rayleigh  0.5015 learn codes ber with rician  0.5015 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49763000000000013 learn codes ber with rayleigh  0.49763000000000013 learn codes ber with rician  0.49763000000000013 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49757999999999997 learn codes ber with rayleigh  0.49757999999999997 learn codes ber with rician  0.49757999999999997 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4992599999999999 learn codes ber with rayleigh  0.4992599999999999 learn codes ber with rician  0.4992599999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49851, 0.4988900000000001, 0.4983099999999999, 0.5043500000000001, 0.5006700000000001, 0.49928, 0.50051, 0.50056, 0.4991, 0.49919, 0.49809000000000003, 0.49853000000000003, 0.50266, 0.50153, 0.50196, 0.49962999999999996, 0.5015, 0.49763000000000013, 0.49757999999999997, 0.4992599999999999]
Learn Codes rayleigh [0.49851, 0.4988900000000001, 0.4983099999999999, 0.5043500000000001, 0.5006700000000001, 0.49928, 0.50051, 0.50056, 0.4991, 0.49919, 0.49809000000000003, 0.49853000000000003, 0.50266, 0.50153, 0.50196, 0.49962999999999996, 0.5015, 0.49763000000000013, 0.49757999999999997, 0.4992599999999999]
Learn Codes rician [0.49851, 0.4988900000000001, 0.4983099999999999, 0.5043500000000001, 0.5006700000000001, 0.49928, 0.50051, 0.50056, 0.4991, 0.49919, 0.49809000000000003, 0.49853000000000003, 0.50266, 0.50153, 0.50196, 0.49962999999999996, 0.5015, 0.49763000000000013, 0.49757999999999997, 0.4992599999999999]
AWGN [0.4375916666666667, 0.39325, 0.310525, 0.19272499999999998, 0.06134166666666666, 0.0030416666666666665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.4531333333333333, 0.41152500000000003, 0.33119166666666666, 0.21708333333333335, 0.10400000000000001, 0.03941666666666667, 0.0137, 0.004208333333333333, 0.0013666666666666666, 0.000375, 0.00015833333333333332, 6.666666666666667e-05, 8.333333333333334e-06, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4501083333333334, 0.4073666666666667, 0.3184833333333333, 0.18346666666666664, 0.06187500000000001, 0.01391666666666667, 0.003275, 0.0008833333333333334, 0.0002583333333333333, 7.500000000000001e-05, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69336444 loss Rayleigh: 0.69336157 loss Rician: 0.69336520   running time 12.147965669631958
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70816019 loss Rayleigh: 0.70666773 loss Rician: 0.70714417   running time 12.094079971313477
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.73018944 loss Rayleigh: 0.70830184 loss Rician: 0.71751580   running time 12.236191749572754
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71380492 loss Rayleigh: 0.70604941 loss Rician: 0.70886506   running time 12.113104581832886
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69529548 loss Rayleigh: 0.69516493 loss Rician: 0.69499912   running time 12.401952981948853
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69374220 loss Rayleigh: 0.69371873 loss Rician: 0.69363296   running time 12.136863470077515
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935558915138245 Custom Loss 0.6935558915138245 with ber  0.4998 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936283111572266 Custom Loss 0.6936283111572266 with ber  0.4998 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6936212182044983 Custom Loss 0.6936212182044983 with ber  0.4998 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.82714295387268s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340881 loss Rayleigh: 0.69341381 loss Rician: 0.69344876   running time 11.924244165420532
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69368459 loss Rayleigh: 0.69365751 loss Rician: 0.69359230   running time 12.123347520828247
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340324 loss Rayleigh: 0.69338768 loss Rician: 0.69333690   running time 12.077336311340332
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69327362 loss Rayleigh: 0.69325793 loss Rician: 0.69322689   running time 11.982451677322388
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69336771 loss Rayleigh: 0.69334596 loss Rician: 0.69331804   running time 12.255912065505981
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331552 loss Rayleigh: 0.69328548 loss Rician: 0.69324453   running time 12.087682485580444
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932677030563354 Custom Loss 0.6932677030563354 with ber  0.49734999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933074593544006 Custom Loss 0.6933074593544006 with ber  0.49734999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932762861251831 Custom Loss 0.6932762861251831 with ber  0.49734999999999996 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.19793486595154s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333144 loss Rayleigh: 0.69333122 loss Rician: 0.69332516   running time 11.903691291809082
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69331579 loss Rayleigh: 0.69329706 loss Rician: 0.69325876   running time 12.18341064453125
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329540 loss Rayleigh: 0.69327168 loss Rician: 0.69322411   running time 11.996269941329956
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332779 loss Rayleigh: 0.69331340 loss Rician: 0.69326491   running time 12.095858573913574
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333428 loss Rayleigh: 0.69330589 loss Rician: 0.69326308   running time 12.033684253692627
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69321374 loss Rayleigh: 0.69320691 loss Rician: 0.69317792   running time 11.952422380447388
====> Test set BCE loss with SNR 0.0 for AWGN 0.69312584400177 Custom Loss 0.69312584400177 with ber  0.5003142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931893229484558 Custom Loss 0.6931893229484558 with ber  0.5003142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931415796279907 Custom Loss 0.6931415796279907 with ber  0.5003142857142857 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 75.88994479179382s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321389 loss Rayleigh: 0.69320210 loss Rician: 0.69318567   running time 12.016768217086792
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325455 loss Rayleigh: 0.69322547 loss Rician: 0.69318153   running time 12.155044555664062
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69322335 loss Rayleigh: 0.69318934 loss Rician: 0.69314320   running time 12.044002771377563
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69322008 loss Rayleigh: 0.69317370 loss Rician: 0.69311980   running time 12.269088983535767
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329918 loss Rayleigh: 0.69319808 loss Rician: 0.69309063   running time 12.04837942123413
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69324591 loss Rayleigh: 0.69313812 loss Rician: 0.69295972   running time 12.164293050765991
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925022006034851 Custom Loss 0.6925022006034851 with ber  0.4981642857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693110466003418 Custom Loss 0.693110466003418 with ber  0.4981642857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6926328539848328 Custom Loss 0.6926328539848328 with ber  0.4981642857142857 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.30718874931335s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323800 loss Rayleigh: 0.69311755 loss Rician: 0.69294831   running time 12.133350372314453
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327400 loss Rayleigh: 0.69316275 loss Rician: 0.69293250   running time 12.012556076049805
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326498 loss Rayleigh: 0.69306589 loss Rician: 0.69271452   running time 12.192054748535156
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332072 loss Rayleigh: 0.69311879 loss Rician: 0.69271287   running time 12.201156377792358
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325246 loss Rayleigh: 0.69296976 loss Rician: 0.69247437   running time 12.167368412017822
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69336289 loss Rayleigh: 0.69299259 loss Rician: 0.69255128   running time 12.130475044250488
====> Test set BCE loss with SNR 0.0 for AWGN 0.6913769841194153 Custom Loss 0.6913769841194153 with ber  0.4997928571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930161714553833 Custom Loss 0.6930161714553833 with ber  0.4997928571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6914241313934326 Custom Loss 0.6914241313934326 with ber  0.4997928571428571 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.56958961486816s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320889 loss Rayleigh: 0.69303141 loss Rician: 0.69250143   running time 11.91818642616272
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69329005 loss Rayleigh: 0.69309020 loss Rician: 0.69247019   running time 12.137927055358887
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69332199 loss Rayleigh: 0.69301104 loss Rician: 0.69251702   running time 12.083977699279785
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69329956 loss Rayleigh: 0.69305652 loss Rician: 0.69229995   running time 12.00425910949707
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69325162 loss Rayleigh: 0.69291290 loss Rician: 0.69226058   running time 12.258103609085083
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69331365 loss Rayleigh: 0.69294100 loss Rician: 0.69231356   running time 12.031301021575928
====> Test set BCE loss with SNR 0.0 for AWGN 0.6908504366874695 Custom Loss 0.6908504366874695 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929610967636108 Custom Loss 0.6929610967636108 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6911397576332092 Custom Loss 0.6911397576332092 with ber  0.4991 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.1851212978363s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69321356 loss Rayleigh: 0.69297780 loss Rician: 0.69234957   running time 11.873146295547485
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69323977 loss Rayleigh: 0.69309840 loss Rician: 0.69239205   running time 13.9961519241333
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69325672 loss Rayleigh: 0.69291760 loss Rician: 0.69227384   running time 13.163771390914917
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327031 loss Rayleigh: 0.69294132 loss Rician: 0.69209638   running time 12.126628160476685
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327835 loss Rayleigh: 0.69298100 loss Rician: 0.69224675   running time 12.204987049102783
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69325035 loss Rayleigh: 0.69285331 loss Rician: 0.69207947   running time 12.164385080337524
====> Test set BCE loss with SNR 0.0 for AWGN 0.6902428865432739 Custom Loss 0.6902428865432739 with ber  0.4993428571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929115056991577 Custom Loss 0.6929115056991577 with ber  0.4993428571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6902878880500793 Custom Loss 0.6902878880500793 with ber  0.4993428571428571 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 79.29170680046082s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69324667 loss Rayleigh: 0.69288633 loss Rician: 0.69192141   running time 11.94218373298645
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69324772 loss Rayleigh: 0.69290133 loss Rician: 0.69219142   running time 12.194632768630981
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69327104 loss Rayleigh: 0.69297812 loss Rician: 0.69202687   running time 12.310074090957642
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69324762 loss Rayleigh: 0.69296185 loss Rician: 0.69206509   running time 12.269111633300781
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69331333 loss Rayleigh: 0.69305226 loss Rician: 0.69195799   running time 12.16649842262268
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323745 loss Rayleigh: 0.69282727 loss Rician: 0.69188747   running time 12.083216428756714
====> Test set BCE loss with SNR 0.0 for AWGN 0.6903891563415527 Custom Loss 0.6903891563415527 with ber  0.50085 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928234696388245 Custom Loss 0.6928234696388245 with ber  0.50085 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6904032230377197 Custom Loss 0.6904032230377197 with ber  0.50085 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.70262789726257s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69321529 loss Rayleigh: 0.69304491 loss Rician: 0.69180791   running time 12.086382627487183
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69323263 loss Rayleigh: 0.69296658 loss Rician: 0.69178650   running time 12.17952036857605
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69334870 loss Rayleigh: 0.69313193 loss Rician: 0.69216014   running time 12.131913423538208
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330699 loss Rayleigh: 0.69289410 loss Rician: 0.69197849   running time 12.263381719589233
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69327918 loss Rayleigh: 0.69300991 loss Rician: 0.69224825   running time 12.072216510772705
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69331385 loss Rayleigh: 0.69297386 loss Rician: 0.69201905   running time 12.284773111343384
====> Test set BCE loss with SNR 0.0 for AWGN 0.6899608373641968 Custom Loss 0.6899608373641968 with ber  0.5000785714285715 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928464770317078 Custom Loss 0.6928464770317078 with ber  0.5000785714285715 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6902998685836792 Custom Loss 0.6902998685836792 with ber  0.5000785714285715 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 76.67346334457397s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69322454 loss Rayleigh: 0.69291832 loss Rician: 0.69187774   running time 12.06524395942688
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329916 loss Rayleigh: 0.69273400 loss Rician: 0.69179338   running time 12.067524671554565
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331407 loss Rayleigh: 0.69275140 loss Rician: 0.69192213   running time 12.30307912826538
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69332925 loss Rayleigh: 0.69293687 loss Rician: 0.69191805   running time 12.13768482208252
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334270 loss Rayleigh: 0.69311908 loss Rician: 0.69220928   running time 12.732389688491821
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334873 loss Rayleigh: 0.69307237 loss Rician: 0.69210275   running time 12.100749492645264
====> Test set BCE loss with SNR 0.0 for AWGN 0.6910853385925293 Custom Loss 0.6910853385925293 with ber  0.5002 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927836537361145 Custom Loss 0.6927836537361145 with ber  0.5002 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6905447840690613 Custom Loss 0.6905447840690613 with ber  0.5002 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
each epoch training time: 77.17639756202698s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5001928571428571 learn codes ber with rayleigh  0.5001928571428571 learn codes ber with rician  0.5001928571428571 ber with awgn  0.37491875 ber with rayleigh  0.397275 ber with rician  0.38589375000000004
Test SNR 5 learn codes ber with awgn  0.5002500000000001 learn codes ber with rayleigh  0.5002500000000001 learn codes ber with rician  0.5002500000000001 ber with awgn  0.286375 ber with rayleigh  0.30634999999999996 ber with rician  0.28618750000000004
Test SNR 10 learn codes ber with awgn  0.5007357142857143 learn codes ber with rayleigh  0.5007357142857143 learn codes ber with rician  0.5007357142857143 ber with awgn  0.15945625000000002 ber with rayleigh  0.18544999999999998 ber with rician  0.14126875
Test SNR 15 learn codes ber with awgn  0.4989214285714286 learn codes ber with rayleigh  0.4989214285714286 learn codes ber with rician  0.4989214285714286 ber with awgn  0.03716875 ber with rayleigh  0.082925 ber with rician  0.03461875
Test SNR 20 learn codes ber with awgn  0.5011571428571429 learn codes ber with rayleigh  0.5011571428571429 learn codes ber with rician  0.5011571428571429 ber with awgn  0.00079375 ber with rayleigh  0.029675 ber with rician  0.00456875
Test SNR 25 learn codes ber with awgn  0.49955 learn codes ber with rayleigh  0.49955 learn codes ber with rician  0.49955 ber with awgn  0.0 ber with rayleigh  0.0103625 ber with rician  0.0006687500000000001
Test SNR 30 learn codes ber with awgn  0.500157142857143 learn codes ber with rayleigh  0.500157142857143 learn codes ber with rician  0.500157142857143 ber with awgn  0.0 ber with rayleigh  0.0030125 ber with rician  0.00016250000000000002
Test SNR 35 learn codes ber with awgn  0.4983928571428571 learn codes ber with rayleigh  0.4983928571428571 learn codes ber with rician  0.4983928571428571 ber with awgn  0.0 ber with rayleigh  0.0010312499999999998 ber with rician  5e-05
Test SNR 40 learn codes ber with awgn  0.5017785714285715 learn codes ber with rayleigh  0.5017785714285715 learn codes ber with rician  0.5017785714285715 ber with awgn  0.0 ber with rayleigh  0.00032500000000000004 ber with rician  1.8750000000000002e-05
Test SNR 45 learn codes ber with awgn  0.49965714285714286 learn codes ber with rayleigh  0.49965714285714286 learn codes ber with rician  0.49965714285714286 ber with awgn  0.0 ber with rayleigh  0.00010625000000000001 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.49672857142857135 learn codes ber with rayleigh  0.49672857142857135 learn codes ber with rician  0.49672857142857135 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5004071428571428 learn codes ber with rayleigh  0.5004071428571428 learn codes ber with rician  0.5004071428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4997857142857143 learn codes ber with rayleigh  0.4997857142857143 learn codes ber with rician  0.4997857142857143 ber with awgn  0.0 ber with rayleigh  6.25e-06 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5005428571428572 learn codes ber with rayleigh  0.5005428571428572 learn codes ber with rician  0.5005428571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5006642857142858 learn codes ber with rayleigh  0.5006642857142858 learn codes ber with rician  0.5006642857142858 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49912142857142855 learn codes ber with rayleigh  0.49912142857142855 learn codes ber with rician  0.49912142857142855 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4997928571428572 learn codes ber with rayleigh  0.4997928571428572 learn codes ber with rician  0.4997928571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4990428571428572 learn codes ber with rayleigh  0.4990428571428572 learn codes ber with rician  0.4990428571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5007428571428572 learn codes ber with rayleigh  0.5007428571428572 learn codes ber with rician  0.5007428571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49865714285714285 learn codes ber with rayleigh  0.49865714285714285 learn codes ber with rician  0.49865714285714285 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5001928571428571, 0.5002500000000001, 0.5007357142857143, 0.4989214285714286, 0.5011571428571429, 0.49955, 0.500157142857143, 0.4983928571428571, 0.5017785714285715, 0.49965714285714286, 0.49672857142857135, 0.5004071428571428, 0.4997857142857143, 0.5005428571428572, 0.5006642857142858, 0.49912142857142855, 0.4997928571428572, 0.4990428571428572, 0.5007428571428572, 0.49865714285714285]
Learn Codes rayleigh [0.5001928571428571, 0.5002500000000001, 0.5007357142857143, 0.4989214285714286, 0.5011571428571429, 0.49955, 0.500157142857143, 0.4983928571428571, 0.5017785714285715, 0.49965714285714286, 0.49672857142857135, 0.5004071428571428, 0.4997857142857143, 0.5005428571428572, 0.5006642857142858, 0.49912142857142855, 0.4997928571428572, 0.4990428571428572, 0.5007428571428572, 0.49865714285714285]
Learn Codes rician [0.5001928571428571, 0.5002500000000001, 0.5007357142857143, 0.4989214285714286, 0.5011571428571429, 0.49955, 0.500157142857143, 0.4983928571428571, 0.5017785714285715, 0.49965714285714286, 0.49672857142857135, 0.5004071428571428, 0.4997857142857143, 0.5005428571428572, 0.5006642857142858, 0.49912142857142855, 0.4997928571428572, 0.4990428571428572, 0.5007428571428572, 0.49865714285714285]
AWGN [0.37491875, 0.286375, 0.15945625000000002, 0.03716875, 0.00079375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.397275, 0.30634999999999996, 0.18544999999999998, 0.082925, 0.029675, 0.0103625, 0.0030125, 0.0010312499999999998, 0.00032500000000000004, 0.00010625000000000001, 5e-05, 0.0, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.38589375000000004, 0.28618750000000004, 0.14126875, 0.03461875, 0.00456875, 0.0006687500000000001, 0.00016250000000000002, 5e-05, 1.8750000000000002e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69399080 loss Rayleigh: 0.69397746 loss Rician: 0.69395341   running time 12.633745193481445
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71135466 loss Rayleigh: 0.70616379 loss Rician: 0.71259462   running time 12.854670286178589
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70641541 loss Rayleigh: 0.69834854 loss Rician: 0.70125132   running time 12.844261646270752
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70555640 loss Rayleigh: 0.69585784 loss Rician: 0.69945524   running time 12.837979555130005
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69764103 loss Rayleigh: 0.69547222 loss Rician: 0.69419441   running time 12.719662427902222
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69403408 loss Rayleigh: 0.69394519 loss Rician: 0.69378161   running time 13.139769077301025
====> Test set BCE loss with SNR 0.0 for AWGN 0.693793535232544 Custom Loss 0.693793535232544 with ber  0.49845000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6939502358436584 Custom Loss 0.6939502358436584 with ber  0.49845000000000006 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6939252614974976 Custom Loss 0.6939252614974976 with ber  0.49845000000000006 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.38530611991882s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69395260 loss Rayleigh: 0.69393605 loss Rician: 0.69390547   running time 12.521066904067993
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69381361 loss Rayleigh: 0.69380572 loss Rician: 0.69369246   running time 12.93561577796936
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69335340 loss Rayleigh: 0.69335592 loss Rician: 0.69331034   running time 13.168330669403076
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340997 loss Rayleigh: 0.69338580 loss Rician: 0.69334275   running time 12.812541246414185
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69321466 loss Rayleigh: 0.69321489 loss Rician: 0.69319512   running time 13.087814569473267
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69322441 loss Rayleigh: 0.69322004 loss Rician: 0.69320399   running time 12.746429920196533
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932879686355591 Custom Loss 0.6932879686355591 with ber  0.49986428571428576 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933144330978394 Custom Loss 0.6933144330978394 with ber  0.49986428571428576 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933073997497559 Custom Loss 0.6933073997497559 with ber  0.49986428571428576 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.62169194221497s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69327461 loss Rayleigh: 0.69327475 loss Rician: 0.69326637   running time 12.893435001373291
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328575 loss Rayleigh: 0.69327275 loss Rician: 0.69325152   running time 12.78191876411438
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323193 loss Rayleigh: 0.69322897 loss Rician: 0.69320874   running time 13.089906930923462
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324421 loss Rayleigh: 0.69323146 loss Rician: 0.69320211   running time 12.866009950637817
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325453 loss Rayleigh: 0.69324622 loss Rician: 0.69322361   running time 12.839935779571533
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323105 loss Rayleigh: 0.69322049 loss Rician: 0.69318992   running time 12.855001211166382
====> Test set BCE loss with SNR 0.0 for AWGN 0.693261981010437 Custom Loss 0.693261981010437 with ber  0.5010928571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932791471481323 Custom Loss 0.6932791471481323 with ber  0.5010928571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932739019393921 Custom Loss 0.6932739019393921 with ber  0.5010928571428571 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.7026960849762s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325162 loss Rayleigh: 0.69324481 loss Rician: 0.69324855   running time 12.703950881958008
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69320495 loss Rayleigh: 0.69320242 loss Rician: 0.69317894   running time 12.861107349395752
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321424 loss Rayleigh: 0.69321232 loss Rician: 0.69319884   running time 12.843350648880005
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325452 loss Rayleigh: 0.69323021 loss Rician: 0.69320084   running time 12.986251592636108
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325895 loss Rayleigh: 0.69324254 loss Rician: 0.69321027   running time 12.756779193878174
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69328015 loss Rayleigh: 0.69326715 loss Rician: 0.69323252   running time 13.045884132385254
====> Test set BCE loss with SNR 0.0 for AWGN 0.693194568157196 Custom Loss 0.693194568157196 with ber  0.49930714285714284 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932295560836792 Custom Loss 0.6932295560836792 with ber  0.49930714285714284 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932125687599182 Custom Loss 0.6932125687599182 with ber  0.49930714285714284 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.51294112205505s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323441 loss Rayleigh: 0.69323221 loss Rician: 0.69322480   running time 12.633786916732788
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69322759 loss Rayleigh: 0.69320916 loss Rician: 0.69317948   running time 12.94742202758789
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319891 loss Rayleigh: 0.69319246 loss Rician: 0.69316595   running time 12.875711917877197
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69318692 loss Rayleigh: 0.69318499 loss Rician: 0.69316434   running time 12.865034103393555
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323880 loss Rayleigh: 0.69322435 loss Rician: 0.69320366   running time 12.904571056365967
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323530 loss Rayleigh: 0.69323524 loss Rician: 0.69321064   running time 12.85640835762024
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932555437088013 Custom Loss 0.6932555437088013 with ber  0.5008714285714284 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693300724029541 Custom Loss 0.693300724029541 with ber  0.5008714285714284 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693271279335022 Custom Loss 0.693271279335022 with ber  0.5008714285714284 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.47214102745056s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69323382 loss Rayleigh: 0.69322923 loss Rician: 0.69322086   running time 12.991575002670288
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320521 loss Rayleigh: 0.69319587 loss Rician: 0.69316835   running time 12.740386962890625
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69323582 loss Rayleigh: 0.69322420 loss Rician: 0.69319848   running time 12.984790802001953
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69327977 loss Rayleigh: 0.69326330 loss Rician: 0.69321806   running time 12.897862911224365
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69321261 loss Rayleigh: 0.69320402 loss Rician: 0.69317669   running time 12.950270891189575
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320046 loss Rayleigh: 0.69318888 loss Rician: 0.69316816   running time 12.922328233718872
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930577158927917 Custom Loss 0.6930577158927917 with ber  0.4995071428571428 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931737065315247 Custom Loss 0.6931737065315247 with ber  0.4995071428571428 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931010484695435 Custom Loss 0.6931010484695435 with ber  0.4995071428571428 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.7864134311676s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69325112 loss Rayleigh: 0.69323497 loss Rician: 0.69320856   running time 12.900376319885254
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69324905 loss Rayleigh: 0.69322891 loss Rician: 0.69317447   running time 12.838327407836914
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327962 loss Rayleigh: 0.69326199 loss Rician: 0.69321507   running time 12.871417760848999
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69321495 loss Rayleigh: 0.69319704 loss Rician: 0.69315855   running time 15.443039178848267
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327977 loss Rayleigh: 0.69326793 loss Rician: 0.69320176   running time 13.05314826965332
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69322119 loss Rayleigh: 0.69317276 loss Rician: 0.69313120   running time 12.890580892562866
====> Test set BCE loss with SNR 0.0 for AWGN 0.6928489804267883 Custom Loss 0.6928489804267883 with ber  0.5004214285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931725740432739 Custom Loss 0.6931725740432739 with ber  0.5004214285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6929774284362793 Custom Loss 0.6929774284362793 with ber  0.5004214285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 84.24234700202942s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69319229 loss Rayleigh: 0.69313704 loss Rician: 0.69304240   running time 13.078105926513672
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69329147 loss Rayleigh: 0.69326938 loss Rician: 0.69316818   running time 12.96418809890747
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330270 loss Rayleigh: 0.69327211 loss Rician: 0.69323471   running time 12.904970407485962
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69320581 loss Rayleigh: 0.69317989 loss Rician: 0.69312527   running time 12.955352783203125
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69326347 loss Rayleigh: 0.69322829 loss Rician: 0.69316960   running time 12.798025369644165
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323556 loss Rayleigh: 0.69324069 loss Rician: 0.69316229   running time 13.0007004737854
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931177377700806 Custom Loss 0.6931177377700806 with ber  0.5002285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932490468025208 Custom Loss 0.6932490468025208 with ber  0.5002285714285714 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931227445602417 Custom Loss 0.6931227445602417 with ber  0.5002285714285714 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 82.03713297843933s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322577 loss Rayleigh: 0.69321522 loss Rician: 0.69320053   running time 12.733054876327515
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69326826 loss Rayleigh: 0.69324993 loss Rician: 0.69318111   running time 12.992279767990112
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69321047 loss Rayleigh: 0.69319994 loss Rician: 0.69313005   running time 12.762597799301147
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325965 loss Rayleigh: 0.69321889 loss Rician: 0.69316049   running time 12.939548015594482
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322753 loss Rayleigh: 0.69319315 loss Rician: 0.69311582   running time 13.974968433380127
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330061 loss Rayleigh: 0.69325855 loss Rician: 0.69315883   running time 12.730315685272217
====> Test set BCE loss with SNR 0.0 for AWGN 0.6926358938217163 Custom Loss 0.6926358938217163 with ber  0.5000071428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932256817817688 Custom Loss 0.6932256817817688 with ber  0.5000071428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6929268836975098 Custom Loss 0.6929268836975098 with ber  0.5000071428571429 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 82.51737904548645s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335353 loss Rayleigh: 0.69328310 loss Rician: 0.69313764   running time 12.831755638122559
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69333501 loss Rayleigh: 0.69326566 loss Rician: 0.69311275   running time 12.787091732025146
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69327198 loss Rayleigh: 0.69325193 loss Rician: 0.69323816   running time 12.98737382888794
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69323363 loss Rayleigh: 0.69320111 loss Rician: 0.69317058   running time 12.910671472549438
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69319020 loss Rayleigh: 0.69314551 loss Rician: 0.69307134   running time 12.893863439559937
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328119 loss Rayleigh: 0.69326102 loss Rician: 0.69321077   running time 12.99327039718628
====> Test set BCE loss with SNR 0.0 for AWGN 0.692891001701355 Custom Loss 0.692891001701355 with ber  0.49850714285714276 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693182110786438 Custom Loss 0.693182110786438 with ber  0.49850714285714276 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930394768714905 Custom Loss 0.6930394768714905 with ber  0.49850714285714276 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
each epoch training time: 81.72831892967224s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_233118\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_233118.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4979857142857143 learn codes ber with rayleigh  0.4979857142857143 learn codes ber with rician  0.4979857142857143 ber with awgn  0.4396125000000001 ber with rayleigh  0.45581249999999995 ber with rician  0.44858750000000003
Test SNR 5 learn codes ber with awgn  0.49809285714285717 learn codes ber with rayleigh  0.49809285714285717 learn codes ber with rician  0.49809285714285717 ber with awgn  0.394675 ber with rayleigh  0.40978125 ber with rician  0.40626875
Test SNR 10 learn codes ber with awgn  0.5020428571428571 learn codes ber with rayleigh  0.5020428571428571 learn codes ber with rician  0.5020428571428571 ber with awgn  0.3128875 ber with rayleigh  0.332175 ber with rician  0.31523125
Test SNR 15 learn codes ber with awgn  0.5015214285714285 learn codes ber with rayleigh  0.5015214285714285 learn codes ber with rician  0.5015214285714285 ber with awgn  0.1949625 ber with rayleigh  0.21335625 ber with rician  0.17598750000000002
Test SNR 20 learn codes ber with awgn  0.49836428571428576 learn codes ber with rayleigh  0.49836428571428576 learn codes ber with rician  0.49836428571428576 ber with awgn  0.06180624999999999 ber with rayleigh  0.10464375000000001 ber with rician  0.05103124999999999
Test SNR 25 learn codes ber with awgn  0.5004428571428573 learn codes ber with rayleigh  0.5004428571428573 learn codes ber with rician  0.5004428571428573 ber with awgn  0.0030687499999999994 ber with rayleigh  0.039850000000000003 ber with rician  0.007493749999999999
Test SNR 30 learn codes ber with awgn  0.5006214285714286 learn codes ber with rayleigh  0.5006214285714286 learn codes ber with rician  0.5006214285714286 ber with awgn  6.25e-06 ber with rayleigh  0.01305 ber with rician  0.0010687499999999998
Test SNR 35 learn codes ber with awgn  0.5003285714285715 learn codes ber with rayleigh  0.5003285714285715 learn codes ber with rician  0.5003285714285715 ber with awgn  0.0 ber with rayleigh  0.00439375 ber with rician  0.0002375
Test SNR 40 learn codes ber with awgn  0.49923571428571434 learn codes ber with rayleigh  0.49923571428571434 learn codes ber with rician  0.49923571428571434 ber with awgn  0.0 ber with rayleigh  0.001375 ber with rician  6.875e-05
Test SNR 45 learn codes ber with awgn  0.5016357142857142 learn codes ber with rayleigh  0.5016357142857142 learn codes ber with rician  0.5016357142857142 ber with awgn  0.0 ber with rayleigh  0.00045625000000000006 ber with rician  1.8750000000000002e-05
Test SNR 50 learn codes ber with awgn  0.4982428571428571 learn codes ber with rayleigh  0.4982428571428571 learn codes ber with rician  0.4982428571428571 ber with awgn  0.0 ber with rayleigh  0.0001375 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5020214285714286 learn codes ber with rayleigh  0.5020214285714286 learn codes ber with rician  0.5020214285714286 ber with awgn  0.0 ber with rayleigh  5.6250000000000005e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49948571428571426 learn codes ber with rayleigh  0.49948571428571426 learn codes ber with rician  0.49948571428571426 ber with awgn  0.0 ber with rayleigh  1.8750000000000002e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5020714285714285 learn codes ber with rayleigh  0.5020714285714285 learn codes ber with rician  0.5020714285714285 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5015571428571428 learn codes ber with rayleigh  0.5015571428571428 learn codes ber with rician  0.5015571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5025071428571428 learn codes ber with rayleigh  0.5025071428571428 learn codes ber with rician  0.5025071428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.50085 learn codes ber with rayleigh  0.50085 learn codes ber with rician  0.50085 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.50085 learn codes ber with rayleigh  0.50085 learn codes ber with rician  0.50085 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5014071428571428 learn codes ber with rayleigh  0.5014071428571428 learn codes ber with rician  0.5014071428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5020785714285714 learn codes ber with rayleigh  0.5020785714285714 learn codes ber with rician  0.5020785714285714 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4979857142857143, 0.49809285714285717, 0.5020428571428571, 0.5015214285714285, 0.49836428571428576, 0.5004428571428573, 0.5006214285714286, 0.5003285714285715, 0.49923571428571434, 0.5016357142857142, 0.4982428571428571, 0.5020214285714286, 0.49948571428571426, 0.5020714285714285, 0.5015571428571428, 0.5025071428571428, 0.50085, 0.50085, 0.5014071428571428, 0.5020785714285714]
Learn Codes rayleigh [0.4979857142857143, 0.49809285714285717, 0.5020428571428571, 0.5015214285714285, 0.49836428571428576, 0.5004428571428573, 0.5006214285714286, 0.5003285714285715, 0.49923571428571434, 0.5016357142857142, 0.4982428571428571, 0.5020214285714286, 0.49948571428571426, 0.5020714285714285, 0.5015571428571428, 0.5025071428571428, 0.50085, 0.50085, 0.5014071428571428, 0.5020785714285714]
Learn Codes rician [0.4979857142857143, 0.49809285714285717, 0.5020428571428571, 0.5015214285714285, 0.49836428571428576, 0.5004428571428573, 0.5006214285714286, 0.5003285714285715, 0.49923571428571434, 0.5016357142857142, 0.4982428571428571, 0.5020214285714286, 0.49948571428571426, 0.5020714285714285, 0.5015571428571428, 0.5025071428571428, 0.50085, 0.50085, 0.5014071428571428, 0.5020785714285714]
AWGN [0.4396125000000001, 0.394675, 0.3128875, 0.1949625, 0.06180624999999999, 0.0030687499999999994, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45581249999999995, 0.40978125, 0.332175, 0.21335625, 0.10464375000000001, 0.039850000000000003, 0.01305, 0.00439375, 0.001375, 0.00045625000000000006, 0.0001375, 5.6250000000000005e-05, 1.8750000000000002e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.44858750000000003, 0.40626875, 0.31523125, 0.17598750000000002, 0.05103124999999999, 0.007493749999999999, 0.0010687499999999998, 0.0002375, 6.875e-05, 1.8750000000000002e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
