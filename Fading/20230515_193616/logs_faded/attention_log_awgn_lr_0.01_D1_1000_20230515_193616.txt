Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=0.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', enc_rnn='gru', dec_rnn='gru', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=10, test_ratio=1, block_len=(10, 20), code_rate_k=(3, 5, 7), code_rate_n=(4, 6, 8), modtype=('QAM16', 'QAM64'), block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230515_193616\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230515_193616\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230515_193616\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230515_193616\\plot_faded')
use_cuda:  False

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69404556 loss Rayleigh: 0.69403273 loss Rician: 0.69402187   running time 7.215682744979858
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69905486 loss Rayleigh: 0.69873844 loss Rician: 0.70141250   running time 5.991860866546631
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69933734 loss Rayleigh: 0.69616380 loss Rician: 0.69605079   running time 4.86859393119812
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69791270 loss Rayleigh: 0.69579006 loss Rician: 0.69462968   running time 5.046050548553467
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69538627 loss Rayleigh: 0.69521490 loss Rician: 0.69413406   running time 4.971173524856567
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69387758 loss Rayleigh: 0.69393100 loss Rician: 0.69358180   running time 5.035472631454468
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932086944580078 Custom Loss 0.6932086944580078 with ber  0.4978000223636627 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693215012550354 Custom Loss 0.693215012550354 with ber  0.4976333677768707 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932226419448853 Custom Loss 0.6932226419448853 with ber  0.497666597366333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 34.924036741256714s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69329269 loss Rayleigh: 0.69328927 loss Rician: 0.69328365   running time 4.885331392288208
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69370585 loss Rayleigh: 0.69366814 loss Rician: 0.69352736   running time 4.918515205383301
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69334759 loss Rayleigh: 0.69334461 loss Rician: 0.69323250   running time 4.910410165786743
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69363183 loss Rayleigh: 0.69351416 loss Rician: 0.69329050   running time 4.944048881530762
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69344975 loss Rayleigh: 0.69345165 loss Rician: 0.69339288   running time 4.893988847732544
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328458 loss Rayleigh: 0.69329137 loss Rician: 0.69325488   running time 4.845572233200073
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932381987571716 Custom Loss 0.6932381987571716 with ber  0.5042001008987427 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932547688484192 Custom Loss 0.6932547688484192 with ber  0.5042333602905273 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932471394538879 Custom Loss 0.6932471394538879 with ber  0.5042333602905273 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.065306425094604s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69321969 loss Rayleigh: 0.69321875 loss Rician: 0.69321424   running time 4.7866737842559814
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69320809 loss Rayleigh: 0.69319825 loss Rician: 0.69315455   running time 4.838740110397339
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336179 loss Rayleigh: 0.69332997 loss Rician: 0.69325828   running time 4.791426420211792
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69349735 loss Rayleigh: 0.69346398 loss Rician: 0.69337177   running time 7.0021514892578125
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332674 loss Rayleigh: 0.69334886 loss Rician: 0.69330292   running time 6.64028263092041
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329420 loss Rayleigh: 0.69329934 loss Rician: 0.69325958   running time 6.6530749797821045
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931869387626648 Custom Loss 0.6931869387626648 with ber  0.4974333345890045 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931999325752258 Custom Loss 0.6931999325752258 with ber  0.49943333864212036 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693198561668396 Custom Loss 0.693198561668396 with ber  0.49943333864212036 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 36.81661367416382s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69319116 loss Rayleigh: 0.69318632 loss Rician: 0.69318387   running time 4.8760786056518555
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69331263 loss Rayleigh: 0.69329035 loss Rician: 0.69323477   running time 5.1629414558410645
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330819 loss Rayleigh: 0.69328888 loss Rician: 0.69324237   running time 5.080374717712402
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338199 loss Rayleigh: 0.69337506 loss Rician: 0.69331391   running time 4.9479475021362305
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325486 loss Rayleigh: 0.69324718 loss Rician: 0.69322038   running time 4.842569589614868
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330228 loss Rayleigh: 0.69330017 loss Rician: 0.69325561   running time 4.937720537185669
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932281851768494 Custom Loss 0.6932281851768494 with ber  0.5008000135421753 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932361721992493 Custom Loss 0.6932361721992493 with ber  0.5008000135421753 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932353377342224 Custom Loss 0.6932353377342224 with ber  0.5008000135421753 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.556487321853638s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327349 loss Rayleigh: 0.69327354 loss Rician: 0.69327404   running time 4.7443060874938965
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69329044 loss Rayleigh: 0.69327879 loss Rician: 0.69323931   running time 5.602802753448486
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319890 loss Rayleigh: 0.69317424 loss Rician: 0.69312637   running time 4.920377016067505
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330810 loss Rayleigh: 0.69328215 loss Rician: 0.69319875   running time 4.885280609130859
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330828 loss Rayleigh: 0.69331921 loss Rician: 0.69328523   running time 4.850456953048706
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69333911 loss Rayleigh: 0.69334980 loss Rician: 0.69330282   running time 4.879400730133057
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932419538497925 Custom Loss 0.6932419538497925 with ber  0.5005332827568054 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932634115219116 Custom Loss 0.6932634115219116 with ber  0.4988333284854889 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932603716850281 Custom Loss 0.6932603716850281 with ber  0.5003000497817993 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.54121160507202s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69314492 loss Rayleigh: 0.69314340 loss Rician: 0.69314012   running time 4.749508619308472
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69327772 loss Rayleigh: 0.69326413 loss Rician: 0.69323649   running time 4.876946449279785
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69329545 loss Rayleigh: 0.69325129 loss Rician: 0.69316843   running time 4.9262073040008545
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69326750 loss Rayleigh: 0.69324229 loss Rician: 0.69315584   running time 4.8329174518585205
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69413205 loss Rayleigh: 0.69395834 loss Rician: 0.69346071   running time 4.861575126647949
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69442050 loss Rayleigh: 0.69423563 loss Rician: 0.69467513   running time 4.897838592529297
====> Test set BCE loss with SNR 0.0 for AWGN 0.6981567144393921 Custom Loss 0.6981567144393921 with ber  0.49969998002052307 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6990972757339478 Custom Loss 0.6990972757339478 with ber  0.4994666576385498 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6990942358970642 Custom Loss 0.6990942358970642 with ber  0.4996333718299866 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.90747356414795s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69898877 loss Rayleigh: 0.69871601 loss Rician: 0.69856705   running time 4.623938322067261
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69833149 loss Rayleigh: 0.69598093 loss Rician: 0.70207301   running time 4.960862636566162
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.70618654 loss Rayleigh: 0.70653731 loss Rician: 0.70554773   running time 4.846869230270386
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.70233798 loss Rayleigh: 0.69977198 loss Rician: 0.69616376   running time 6.052680015563965
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69471807 loss Rayleigh: 0.69464678 loss Rician: 0.69439271   running time 4.851627826690674
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69358661 loss Rayleigh: 0.69358410 loss Rician: 0.69351962   running time 4.837769269943237
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933542490005493 Custom Loss 0.6933542490005493 with ber  0.5003666281700134 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933547854423523 Custom Loss 0.6933547854423523 with ber  0.5000332593917847 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933556795120239 Custom Loss 0.6933556795120239 with ber  0.5003666281700134 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.900151014328003s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330042 loss Rayleigh: 0.69329982 loss Rician: 0.69329973   running time 4.7264134883880615
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330446 loss Rayleigh: 0.69330822 loss Rician: 0.69328819   running time 5.656064748764038
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69347898 loss Rayleigh: 0.69347757 loss Rician: 0.69342771   running time 4.8352251052856445
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343952 loss Rayleigh: 0.69343352 loss Rician: 0.69338943   running time 4.821410417556763
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69326285 loss Rayleigh: 0.69324561 loss Rician: 0.69321894   running time 4.808370113372803
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323972 loss Rayleigh: 0.69324183 loss Rician: 0.69322551   running time 4.825324773788452
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932626962661743 Custom Loss 0.6932626962661743 with ber  0.5006333589553833 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932610869407654 Custom Loss 0.6932610869407654 with ber  0.5006333589553833 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932610869407654 Custom Loss 0.6932610869407654 with ber  0.5006333589553833 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.354657411575317s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69321352 loss Rayleigh: 0.69321382 loss Rician: 0.69321488   running time 4.692809104919434
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69328096 loss Rayleigh: 0.69327816 loss Rician: 0.69325785   running time 4.842177152633667
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322788 loss Rayleigh: 0.69322091 loss Rician: 0.69319671   running time 4.858973503112793
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330019 loss Rayleigh: 0.69329516 loss Rician: 0.69327093   running time 4.871964931488037
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69331890 loss Rayleigh: 0.69332529 loss Rician: 0.69329983   running time 4.843929767608643
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69313638 loss Rayleigh: 0.69312022 loss Rician: 0.69308525   running time 4.838528871536255
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934114694595337 Custom Loss 0.6934114694595337 with ber  0.497333288192749 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934201717376709 Custom Loss 0.6934201717376709 with ber  0.497333288192749 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934139728546143 Custom Loss 0.6934139728546143 with ber  0.497333288192749 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.637046813964844s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69344298 loss Rayleigh: 0.69344073 loss Rician: 0.69344037   running time 4.705408334732056
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69322022 loss Rayleigh: 0.69320986 loss Rician: 0.69318232   running time 4.821357727050781
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69320424 loss Rayleigh: 0.69321170 loss Rician: 0.69319511   running time 4.745820045471191
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69327548 loss Rayleigh: 0.69327811 loss Rician: 0.69325790   running time 5.755694389343262
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337164 loss Rayleigh: 0.69335934 loss Rician: 0.69331063   running time 4.993844985961914
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336417 loss Rayleigh: 0.69332997 loss Rician: 0.69327892   running time 4.82368278503418
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933104395866394 Custom Loss 0.6933104395866394 with ber  0.49799999594688416 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933054327964783 Custom Loss 0.6933054327964783 with ber  0.49799999594688416 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933044195175171 Custom Loss 0.6933044195175171 with ber  0.49799999594688416 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.64504837989807s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49879997968673706 learn codes ber with rayleigh  0.49879997968673706 learn codes ber with rician  0.49879997968673706 ber with awgn  0.37124999999999997 ber with rayleigh  0.3997 ber with rician  0.39175
Test SNR 5 learn codes ber with awgn  0.5006999969482422 learn codes ber with rayleigh  0.5006999969482422 learn codes ber with rician  0.5006999969482422 ber with awgn  0.28712499999999996 ber with rayleigh  0.3049 ber with rician  0.29064999999999996
Test SNR 10 learn codes ber with awgn  0.4966666102409363 learn codes ber with rayleigh  0.4966666102409363 learn codes ber with rician  0.4966666102409363 ber with awgn  0.15757500000000002 ber with rayleigh  0.183125 ber with rician  0.162275
Test SNR 15 learn codes ber with awgn  0.49986663460731506 learn codes ber with rayleigh  0.49986663460731506 learn codes ber with rician  0.49986663460731506 ber with awgn  0.037524999999999996 ber with rayleigh  0.084925 ber with rician  0.058175
Test SNR 20 learn codes ber with awgn  0.49826663732528687 learn codes ber with rayleigh  0.49826663732528687 learn codes ber with rician  0.49826663732528687 ber with awgn  0.000625 ber with rayleigh  0.030125000000000002 ber with rician  0.016375
Test SNR 25 learn codes ber with awgn  0.5011000037193298 learn codes ber with rayleigh  0.5011000037193298 learn codes ber with rician  0.5011000037193298 ber with awgn  0.0 ber with rayleigh  0.008875000000000003 ber with rician  0.004025000000000001
Test SNR 30 learn codes ber with awgn  0.5027333498001099 learn codes ber with rayleigh  0.5027333498001099 learn codes ber with rician  0.5027333498001099 ber with awgn  0.0 ber with rayleigh  0.0029000000000000002 ber with rician  0.001175
Test SNR 35 learn codes ber with awgn  0.5004000067710876 learn codes ber with rayleigh  0.5004000067710876 learn codes ber with rician  0.5004000067710876 ber with awgn  0.0 ber with rayleigh  0.0012499999999999998 ber with rician  0.00037500000000000006
Test SNR 40 learn codes ber with awgn  0.5017000436782837 learn codes ber with rayleigh  0.5017000436782837 learn codes ber with rician  0.5017000436782837 ber with awgn  0.0 ber with rayleigh  0.00045000000000000004 ber with rician  0.00015000000000000001
Test SNR 45 learn codes ber with awgn  0.5047000050544739 learn codes ber with rayleigh  0.5047000050544739 learn codes ber with rician  0.5047000050544739 ber with awgn  0.0 ber with rayleigh  7.500000000000001e-05 ber with rician  5e-05
Test SNR 50 learn codes ber with awgn  0.5015000104904175 learn codes ber with rayleigh  0.5015000104904175 learn codes ber with rician  0.5015000104904175 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5055999755859375 learn codes ber with rayleigh  0.5055999755859375 learn codes ber with rician  0.5055999755859375 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49356669187545776 learn codes ber with rayleigh  0.49356669187545776 learn codes ber with rician  0.49356669187545776 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  2.5e-05
Test SNR 65 learn codes ber with awgn  0.5036333203315735 learn codes ber with rayleigh  0.5036333203315735 learn codes ber with rician  0.5036333203315735 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5023999810218811 learn codes ber with rayleigh  0.5023999810218811 learn codes ber with rician  0.5023999810218811 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5029666423797607 learn codes ber with rayleigh  0.5029666423797607 learn codes ber with rician  0.5029666423797607 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5012666583061218 learn codes ber with rayleigh  0.5012666583061218 learn codes ber with rician  0.5012666583061218 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4940333366394043 learn codes ber with rayleigh  0.4940333366394043 learn codes ber with rician  0.4940333366394043 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.4976666569709778 learn codes ber with rayleigh  0.4976666569709778 learn codes ber with rician  0.4976666569709778 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5027333498001099 learn codes ber with rayleigh  0.5027333498001099 learn codes ber with rician  0.5027333498001099 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49879997968673706, 0.5006999969482422, 0.4966666102409363, 0.49986663460731506, 0.49826663732528687, 0.5011000037193298, 0.5027333498001099, 0.5004000067710876, 0.5017000436782837, 0.5047000050544739, 0.5015000104904175, 0.5055999755859375, 0.49356669187545776, 0.5036333203315735, 0.5023999810218811, 0.5029666423797607, 0.5012666583061218, 0.4940333366394043, 0.4976666569709778, 0.5027333498001099]
Learn Codes rayleigh [0.49879997968673706, 0.5006999969482422, 0.4966666102409363, 0.49986663460731506, 0.49826663732528687, 0.5011000037193298, 0.5027333498001099, 0.5004000067710876, 0.5017000436782837, 0.5047000050544739, 0.5015000104904175, 0.5055999755859375, 0.49356669187545776, 0.5036333203315735, 0.5023999810218811, 0.5029666423797607, 0.5012666583061218, 0.4940333366394043, 0.4976666569709778, 0.5027333498001099]
Learn Codes rician [0.49879997968673706, 0.5006999969482422, 0.4966666102409363, 0.49986663460731506, 0.49826663732528687, 0.5011000037193298, 0.5027333498001099, 0.5004000067710876, 0.5017000436782837, 0.5047000050544739, 0.5015000104904175, 0.5055999755859375, 0.49356669187545776, 0.5036333203315735, 0.5023999810218811, 0.5029666423797607, 0.5012666583061218, 0.4940333366394043, 0.4976666569709778, 0.5027333498001099]
AWGN [0.37124999999999997, 0.28712499999999996, 0.15757500000000002, 0.037524999999999996, 0.000625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3997, 0.3049, 0.183125, 0.084925, 0.030125000000000002, 0.008875000000000003, 0.0029000000000000002, 0.0012499999999999998, 0.00045000000000000004, 7.500000000000001e-05, 0.0, 0.0, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39175, 0.29064999999999996, 0.162275, 0.058175, 0.016375, 0.004025000000000001, 0.001175, 0.00037500000000000006, 0.00015000000000000001, 5e-05, 0.0, 0.0, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69357654 loss Rayleigh: 0.69357286 loss Rician: 0.69357132   running time 4.85310959815979
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71452800 loss Rayleigh: 0.70104021 loss Rician: 0.70716386   running time 5.052199125289917
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70543271 loss Rayleigh: 0.70197594 loss Rician: 0.69993358   running time 5.07848596572876
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69509463 loss Rayleigh: 0.69530438 loss Rician: 0.69478329   running time 4.983990430831909
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69362903 loss Rayleigh: 0.69363725 loss Rician: 0.69358432   running time 4.989935398101807
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69339309 loss Rayleigh: 0.69334930 loss Rician: 0.69324024   running time 5.141775608062744
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932100653648376 Custom Loss 0.6932100653648376 with ber  0.49713334441185 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932328939437866 Custom Loss 0.6932328939437866 with ber  0.49849995970726013 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932230591773987 Custom Loss 0.6932230591773987 with ber  0.4989333152770996 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.996647357940674s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69339805 loss Rayleigh: 0.69339593 loss Rician: 0.69338784   running time 4.894639015197754
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69332219 loss Rayleigh: 0.69331335 loss Rician: 0.69329181   running time 5.059007167816162
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69327152 loss Rayleigh: 0.69328429 loss Rician: 0.69324119   running time 5.037536144256592
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69330362 loss Rayleigh: 0.69327052 loss Rician: 0.69317203   running time 4.996493816375732
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69355646 loss Rayleigh: 0.69353192 loss Rician: 0.69346260   running time 5.058731555938721
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338980 loss Rayleigh: 0.69337641 loss Rician: 0.69329743   running time 5.036003828048706
====> Test set BCE loss with SNR 0.0 for AWGN 0.693108320236206 Custom Loss 0.693108320236206 with ber  0.49273332953453064 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931023597717285 Custom Loss 0.6931023597717285 with ber  0.4944000244140625 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931034922599792 Custom Loss 0.6931034922599792 with ber  0.49406662583351135 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.91361141204834s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69350396 loss Rayleigh: 0.69350220 loss Rician: 0.69350175   running time 4.849400997161865
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323988 loss Rayleigh: 0.69323238 loss Rician: 0.69319716   running time 4.9741129875183105
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69327347 loss Rayleigh: 0.69326862 loss Rician: 0.69323368   running time 4.9731268882751465
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69331627 loss Rayleigh: 0.69330995 loss Rician: 0.69325438   running time 5.051100492477417
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332232 loss Rayleigh: 0.69329513 loss Rician: 0.69321230   running time 4.986349582672119
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332705 loss Rayleigh: 0.69333596 loss Rician: 0.69329427   running time 5.035660982131958
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932035088539124 Custom Loss 0.6932035088539124 with ber  0.5034000277519226 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932253837585449 Custom Loss 0.6932253837585449 with ber  0.5038000345230103 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932302713394165 Custom Loss 0.6932302713394165 with ber  0.5029000043869019 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.900152683258057s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69315411 loss Rayleigh: 0.69315699 loss Rician: 0.69314352   running time 4.946157932281494
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330054 loss Rayleigh: 0.69328833 loss Rician: 0.69325281   running time 5.031522989273071
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329801 loss Rayleigh: 0.69328265 loss Rician: 0.69323965   running time 5.041018486022949
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333147 loss Rayleigh: 0.69328052 loss Rician: 0.69319075   running time 5.013545751571655
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342703 loss Rayleigh: 0.69336370 loss Rician: 0.69326673   running time 5.0802083015441895
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69358137 loss Rayleigh: 0.69354444 loss Rician: 0.69342852   running time 4.980770111083984
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935188174247742 Custom Loss 0.6935188174247742 with ber  0.49843329191207886 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936424374580383 Custom Loss 0.6936424374580383 with ber  0.49843329191207886 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935949921607971 Custom Loss 0.6935949921607971 with ber  0.49843329191207886 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.934804916381836s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69370162 loss Rayleigh: 0.69367825 loss Rician: 0.69364822   running time 4.820492506027222
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69345269 loss Rayleigh: 0.69340327 loss Rician: 0.69330153   running time 5.049415111541748
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69341671 loss Rayleigh: 0.69341117 loss Rician: 0.69330719   running time 5.049123764038086
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69334615 loss Rayleigh: 0.69334632 loss Rician: 0.69326998   running time 5.3448264598846436
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69344688 loss Rayleigh: 0.69340578 loss Rician: 0.69332036   running time 5.120102405548096
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69339789 loss Rayleigh: 0.69338435 loss Rician: 0.69332718   running time 5.221961498260498
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931713819503784 Custom Loss 0.6931713819503784 with ber  0.49960002303123474 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931706666946411 Custom Loss 0.6931706666946411 with ber  0.49960002303123474 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931678056716919 Custom Loss 0.6931678056716919 with ber  0.49960002303123474 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.600515604019165s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69309121 loss Rayleigh: 0.69308412 loss Rician: 0.69307566   running time 4.838577032089233
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320430 loss Rayleigh: 0.69321119 loss Rician: 0.69320303   running time 5.061595916748047
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69313942 loss Rayleigh: 0.69314122 loss Rician: 0.69313079   running time 5.013431072235107
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328610 loss Rayleigh: 0.69328322 loss Rician: 0.69322521   running time 5.058946371078491
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69320367 loss Rayleigh: 0.69319697 loss Rician: 0.69316951   running time 5.094836711883545
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328752 loss Rayleigh: 0.69326262 loss Rician: 0.69322272   running time 4.998242378234863
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933696269989014 Custom Loss 0.6933696269989014 with ber  0.5005000233650208 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933677196502686 Custom Loss 0.6933677196502686 with ber  0.5005000233650208 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933685541152954 Custom Loss 0.6933685541152954 with ber  0.5005000233650208 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.97429847717285s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69339704 loss Rayleigh: 0.69339539 loss Rician: 0.69339580   running time 4.876648426055908
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69324632 loss Rayleigh: 0.69324349 loss Rician: 0.69320670   running time 5.0367162227630615
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69314278 loss Rayleigh: 0.69313199 loss Rician: 0.69308550   running time 4.9935619831085205
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69339826 loss Rayleigh: 0.69333355 loss Rician: 0.69322303   running time 5.012505292892456
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69357229 loss Rayleigh: 0.69355003 loss Rician: 0.69343417   running time 5.001612186431885
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69309228 loss Rayleigh: 0.69308994 loss Rician: 0.69305705   running time 5.0321502685546875
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934125423431396 Custom Loss 0.6934125423431396 with ber  0.4991666376590729 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934310793876648 Custom Loss 0.6934310793876648 with ber  0.4978000223636627 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934224367141724 Custom Loss 0.6934224367141724 with ber  0.49766668677330017 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.905736207962036s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69340346 loss Rayleigh: 0.69340227 loss Rician: 0.69339405   running time 4.73909330368042
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69347004 loss Rayleigh: 0.69343320 loss Rician: 0.69329855   running time 5.003737688064575
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339054 loss Rayleigh: 0.69338901 loss Rician: 0.69331569   running time 5.119420051574707
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69322492 loss Rayleigh: 0.69321548 loss Rician: 0.69316826   running time 5.115061521530151
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69344944 loss Rayleigh: 0.69341671 loss Rician: 0.69333256   running time 5.085777282714844
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69350867 loss Rayleigh: 0.69350672 loss Rician: 0.69323962   running time 5.03701376914978
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934162378311157 Custom Loss 0.6934162378311157 with ber  0.5029666423797607 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934241652488708 Custom Loss 0.6934241652488708 with ber  0.5029666423797607 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693426251411438 Custom Loss 0.693426251411438 with ber  0.5029666423797607 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.03256940841675s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333767 loss Rayleigh: 0.69333543 loss Rician: 0.69333030   running time 4.8850462436676025
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69343669 loss Rayleigh: 0.69345126 loss Rician: 0.69330224   running time 5.006983757019043
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69390896 loss Rayleigh: 0.69390272 loss Rician: 0.69357913   running time 5.095818042755127
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69424814 loss Rayleigh: 0.69434826 loss Rician: 0.69357041   running time 5.03718376159668
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.70276319 loss Rayleigh: 0.70233757 loss Rician: 0.69830246   running time 5.0452046394348145
====> Epoch: 9 with snr 0.0 Average loss AWGN: 1.06185078 loss Rayleigh: 1.39288096 loss Rician: 1.31365713   running time 5.031849145889282
====> Test set BCE loss with SNR 0.0 for AWGN 0.7139504551887512 Custom Loss 0.7139504551887512 with ber  0.49929994344711304 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.7138729691505432 Custom Loss 0.7138729691505432 with ber  0.49929994344711304 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.7138726711273193 Custom Loss 0.7138726711273193 with ber  0.49929994344711304 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 31.955560445785522s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.71093195 loss Rayleigh: 0.71093758 loss Rician: 0.71094173   running time 4.931087255477905
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.75866560 loss Rayleigh: 0.76122096 loss Rician: 0.76345855   running time 5.03851318359375
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69796021 loss Rayleigh: 0.69739678 loss Rician: 0.69678541   running time 4.985553741455078
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69355863 loss Rayleigh: 0.69352680 loss Rician: 0.69348156   running time 4.965284109115601
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329868 loss Rayleigh: 0.69329665 loss Rician: 0.69327675   running time 5.000722646713257
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328328 loss Rayleigh: 0.69327669 loss Rician: 0.69325350   running time 5.051873207092285
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933269500732422 Custom Loss 0.6933269500732422 with ber  0.5015999674797058 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933269500732422 Custom Loss 0.6933269500732422 with ber  0.5015999674797058 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933269500732422 Custom Loss 0.6933269500732422 with ber  0.5015999674797058 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.00396251678467s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4977666735649109 learn codes ber with rayleigh  0.4977666735649109 learn codes ber with rician  0.4977666735649109 ber with awgn  0.4424 ber with rayleigh  0.45432500000000003 ber with rician  0.4546
Test SNR 5 learn codes ber with awgn  0.5022667050361633 learn codes ber with rayleigh  0.5022667050361633 learn codes ber with rician  0.5022667050361633 ber with awgn  0.3908999999999999 ber with rayleigh  0.411475 ber with rician  0.40695
Test SNR 10 learn codes ber with awgn  0.49816665053367615 learn codes ber with rayleigh  0.49816665053367615 learn codes ber with rician  0.49816665053367615 ber with awgn  0.315225 ber with rayleigh  0.33442500000000003 ber with rician  0.3258
Test SNR 15 learn codes ber with awgn  0.5000666379928589 learn codes ber with rayleigh  0.5000666379928589 learn codes ber with rician  0.5000666379928589 ber with awgn  0.195175 ber with rayleigh  0.2143 ber with rician  0.19585000000000002
Test SNR 20 learn codes ber with awgn  0.49980002641677856 learn codes ber with rayleigh  0.49980002641677856 learn codes ber with rician  0.49980002641677856 ber with awgn  0.059775 ber with rayleigh  0.105025 ber with rician  0.0737
Test SNR 25 learn codes ber with awgn  0.5059666633605957 learn codes ber with rayleigh  0.5059666633605957 learn codes ber with rician  0.5059666633605957 ber with awgn  0.0035250000000000004 ber with rayleigh  0.04095 ber with rician  0.021374999999999995
Test SNR 30 learn codes ber with awgn  0.4961000084877014 learn codes ber with rayleigh  0.4961000084877014 learn codes ber with rician  0.4961000084877014 ber with awgn  0.0 ber with rayleigh  0.013199999999999998 ber with rician  0.0052
Test SNR 35 learn codes ber with awgn  0.4994666576385498 learn codes ber with rayleigh  0.4994666576385498 learn codes ber with rician  0.4994666576385498 ber with awgn  0.0 ber with rayleigh  0.004350000000000001 ber with rician  0.00245
Test SNR 40 learn codes ber with awgn  0.49863332509994507 learn codes ber with rayleigh  0.49863332509994507 learn codes ber with rician  0.49863332509994507 ber with awgn  0.0 ber with rayleigh  0.00125 ber with rician  0.0005250000000000001
Test SNR 45 learn codes ber with awgn  0.5066334009170532 learn codes ber with rayleigh  0.5066334009170532 learn codes ber with rician  0.5066334009170532 ber with awgn  0.0 ber with rayleigh  0.0006500000000000001 ber with rician  0.000125
Test SNR 50 learn codes ber with awgn  0.5021000504493713 learn codes ber with rayleigh  0.5021000504493713 learn codes ber with rician  0.5021000504493713 ber with awgn  0.0 ber with rayleigh  0.00015000000000000001 ber with rician  0.0001
Test SNR 55 learn codes ber with awgn  0.5027666687965393 learn codes ber with rayleigh  0.5027666687965393 learn codes ber with rician  0.5027666687965393 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5005333423614502 learn codes ber with rayleigh  0.5005333423614502 learn codes ber with rician  0.5005333423614502 ber with awgn  0.0 ber with rayleigh  7.500000000000001e-05 ber with rician  2.5e-05
Test SNR 65 learn codes ber with awgn  0.4968666434288025 learn codes ber with rayleigh  0.4968666434288025 learn codes ber with rician  0.4968666434288025 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49879997968673706 learn codes ber with rayleigh  0.49879997968673706 learn codes ber with rician  0.49879997968673706 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49833330512046814 learn codes ber with rayleigh  0.49833330512046814 learn codes ber with rician  0.49833330512046814 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4936666488647461 learn codes ber with rayleigh  0.4936666488647461 learn codes ber with rician  0.4936666488647461 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5031332969665527 learn codes ber with rayleigh  0.5031332969665527 learn codes ber with rician  0.5031332969665527 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.4968999922275543 learn codes ber with rayleigh  0.4968999922275543 learn codes ber with rician  0.4968999922275543 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4982999861240387 learn codes ber with rayleigh  0.4982999861240387 learn codes ber with rician  0.4982999861240387 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4977666735649109, 0.5022667050361633, 0.49816665053367615, 0.5000666379928589, 0.49980002641677856, 0.5059666633605957, 0.4961000084877014, 0.4994666576385498, 0.49863332509994507, 0.5066334009170532, 0.5021000504493713, 0.5027666687965393, 0.5005333423614502, 0.4968666434288025, 0.49879997968673706, 0.49833330512046814, 0.4936666488647461, 0.5031332969665527, 0.4968999922275543, 0.4982999861240387]
Learn Codes rayleigh [0.4977666735649109, 0.5022667050361633, 0.49816665053367615, 0.5000666379928589, 0.49980002641677856, 0.5059666633605957, 0.4961000084877014, 0.4994666576385498, 0.49863332509994507, 0.5066334009170532, 0.5021000504493713, 0.5027666687965393, 0.5005333423614502, 0.4968666434288025, 0.49879997968673706, 0.49833330512046814, 0.4936666488647461, 0.5031332969665527, 0.4968999922275543, 0.4982999861240387]
Learn Codes rician [0.4977666735649109, 0.5022667050361633, 0.49816665053367615, 0.5000666379928589, 0.49980002641677856, 0.5059666633605957, 0.4961000084877014, 0.4994666576385498, 0.49863332509994507, 0.5066334009170532, 0.5021000504493713, 0.5027666687965393, 0.5005333423614502, 0.4968666434288025, 0.49879997968673706, 0.49833330512046814, 0.4936666488647461, 0.5031332969665527, 0.4968999922275543, 0.4982999861240387]
AWGN [0.4424, 0.3908999999999999, 0.315225, 0.195175, 0.059775, 0.0035250000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45432500000000003, 0.411475, 0.33442500000000003, 0.2143, 0.105025, 0.04095, 0.013199999999999998, 0.004350000000000001, 0.00125, 0.0006500000000000001, 0.00015000000000000001, 2.5e-05, 7.500000000000001e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4546, 0.40695, 0.3258, 0.19585000000000002, 0.0737, 0.021374999999999995, 0.0052, 0.00245, 0.0005250000000000001, 0.000125, 0.0001, 0.0, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69346591 loss Rayleigh: 0.69347883 loss Rician: 0.69347256   running time 4.775442838668823
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69962859 loss Rayleigh: 0.69960988 loss Rician: 0.69765390   running time 4.878348350524902
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70003209 loss Rayleigh: 0.69706154 loss Rician: 0.69695541   running time 4.846969842910767
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69448646 loss Rayleigh: 0.69460114 loss Rician: 0.69395465   running time 4.876540899276733
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69426883 loss Rayleigh: 0.69443430 loss Rician: 0.69376932   running time 4.887830972671509
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69349716 loss Rayleigh: 0.69351725 loss Rician: 0.69344121   running time 4.904324769973755
====> Test set BCE loss with SNR 0.0 for AWGN 0.693657398223877 Custom Loss 0.693657398223877 with ber  0.4973599910736084 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6937452554702759 Custom Loss 0.6937452554702759 with ber  0.49740004539489746 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6937307119369507 Custom Loss 0.6937307119369507 with ber  0.49727997183799744 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.915831804275513s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69405110 loss Rayleigh: 0.69403402 loss Rician: 0.69403849   running time 4.705960512161255
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69397607 loss Rayleigh: 0.69385578 loss Rician: 0.69355530   running time 4.849653005599976
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69356244 loss Rayleigh: 0.69352957 loss Rician: 0.69339711   running time 4.893982172012329
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69349807 loss Rayleigh: 0.69347626 loss Rician: 0.69335501   running time 4.869797468185425
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340185 loss Rayleigh: 0.69337731 loss Rician: 0.69328884   running time 4.851526498794556
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69344190 loss Rayleigh: 0.69342318 loss Rician: 0.69334608   running time 4.857244253158569
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935402154922485 Custom Loss 0.6935402154922485 with ber  0.5017000436782837 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935228705406189 Custom Loss 0.6935228705406189 with ber  0.5017000436782837 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935224533081055 Custom Loss 0.6935224533081055 with ber  0.5017000436782837 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.864861011505127s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69349426 loss Rayleigh: 0.69349552 loss Rician: 0.69349705   running time 4.721682071685791
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69335250 loss Rayleigh: 0.69334614 loss Rician: 0.69329364   running time 4.895890951156616
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329948 loss Rayleigh: 0.69328101 loss Rician: 0.69323319   running time 4.888411998748779
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69326074 loss Rayleigh: 0.69324466 loss Rician: 0.69318646   running time 5.01112961769104
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336028 loss Rayleigh: 0.69332148 loss Rician: 0.69323130   running time 4.947893381118774
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69351666 loss Rayleigh: 0.69348742 loss Rician: 0.69336458   running time 4.817699432373047
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932758092880249 Custom Loss 0.6932758092880249 with ber  0.5018799901008606 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932772397994995 Custom Loss 0.6932772397994995 with ber  0.5017999410629272 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932783126831055 Custom Loss 0.6932783126831055 with ber  0.5028200745582581 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.118325233459473s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321226 loss Rayleigh: 0.69321133 loss Rician: 0.69321479   running time 4.75174355506897
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69340481 loss Rayleigh: 0.69337655 loss Rician: 0.69327893   running time 4.815475225448608
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69344944 loss Rayleigh: 0.69344063 loss Rician: 0.69335992   running time 4.857911109924316
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329688 loss Rayleigh: 0.69330809 loss Rician: 0.69326954   running time 4.823950290679932
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330029 loss Rayleigh: 0.69328895 loss Rician: 0.69322241   running time 4.883368968963623
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325113 loss Rayleigh: 0.69325510 loss Rician: 0.69322461   running time 4.854058504104614
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932543516159058 Custom Loss 0.6932543516159058 with ber  0.5002400279045105 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932532787322998 Custom Loss 0.6932532787322998 with ber  0.5002400279045105 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932543516159058 Custom Loss 0.6932543516159058 with ber  0.5002400279045105 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.757638454437256s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332479 loss Rayleigh: 0.69332576 loss Rician: 0.69332641   running time 4.7407612800598145
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330424 loss Rayleigh: 0.69329083 loss Rician: 0.69321319   running time 4.867397785186768
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69343975 loss Rayleigh: 0.69345128 loss Rician: 0.69339325   running time 4.871946096420288
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332940 loss Rayleigh: 0.69331203 loss Rician: 0.69323673   running time 4.826671361923218
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69322926 loss Rayleigh: 0.69321876 loss Rician: 0.69318357   running time 4.875604867935181
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326739 loss Rayleigh: 0.69324937 loss Rician: 0.69319922   running time 4.881504535675049
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935642957687378 Custom Loss 0.6935642957687378 with ber  0.5023800134658813 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935667991638184 Custom Loss 0.6935667991638184 with ber  0.5023800134658813 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935663223266602 Custom Loss 0.6935663223266602 with ber  0.5023800134658813 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.753545999526978s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69349536 loss Rayleigh: 0.69349307 loss Rician: 0.69349070   running time 4.771663188934326
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333583 loss Rayleigh: 0.69332497 loss Rician: 0.69326802   running time 4.88563084602356
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69351808 loss Rayleigh: 0.69349149 loss Rician: 0.69337158   running time 4.917351007461548
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69339728 loss Rayleigh: 0.69339039 loss Rician: 0.69327390   running time 4.903342247009277
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69343359 loss Rayleigh: 0.69346349 loss Rician: 0.69331086   running time 4.822970628738403
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69378979 loss Rayleigh: 0.69386989 loss Rician: 0.69354957   running time 4.884281635284424
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933953166007996 Custom Loss 0.6933953166007996 with ber  0.5028800368309021 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933998465538025 Custom Loss 0.6933998465538025 with ber  0.5028800368309021 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693398118019104 Custom Loss 0.693398118019104 with ber  0.5028800368309021 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.861433029174805s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342117 loss Rayleigh: 0.69341695 loss Rician: 0.69341626   running time 4.695512056350708
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69360456 loss Rayleigh: 0.69361669 loss Rician: 0.69341577   running time 4.835806846618652
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69358291 loss Rayleigh: 0.69361559 loss Rician: 0.69335341   running time 4.931835412979126
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69384764 loss Rayleigh: 0.69383084 loss Rician: 0.69354795   running time 4.865462779998779
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69379576 loss Rayleigh: 0.69376923 loss Rician: 0.69353005   running time 4.872098922729492
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69389685 loss Rayleigh: 0.69382468 loss Rician: 0.69352582   running time 4.874283075332642
====> Test set BCE loss with SNR 0.0 for AWGN 0.6936885118484497 Custom Loss 0.6936885118484497 with ber  0.49696001410484314 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936917901039124 Custom Loss 0.6936917901039124 with ber  0.49724000692367554 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6936939358711243 Custom Loss 0.6936939358711243 with ber  0.49678000807762146 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.8416748046875s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69368735 loss Rayleigh: 0.69368579 loss Rician: 0.69368882   running time 4.658241510391235
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69389518 loss Rayleigh: 0.69392208 loss Rician: 0.69367548   running time 4.842815399169922
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69378110 loss Rayleigh: 0.69378505 loss Rician: 0.69359055   running time 4.842576503753662
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69340711 loss Rayleigh: 0.69340235 loss Rician: 0.69334246   running time 4.896199703216553
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69346057 loss Rayleigh: 0.69344106 loss Rician: 0.69334274   running time 4.925175428390503
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339497 loss Rayleigh: 0.69339953 loss Rician: 0.69334899   running time 4.881823301315308
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932213306427002 Custom Loss 0.6932213306427002 with ber  0.4993800222873688 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932207345962524 Custom Loss 0.6932207345962524 with ber  0.4993800222873688 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932204961776733 Custom Loss 0.6932204961776733 with ber  0.4993800222873688 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.88341474533081s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69331029 loss Rayleigh: 0.69331032 loss Rician: 0.69331101   running time 4.702845096588135
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69338406 loss Rayleigh: 0.69335644 loss Rician: 0.69329135   running time 4.894970417022705
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69358928 loss Rayleigh: 0.69354442 loss Rician: 0.69344452   running time 4.911787986755371
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325158 loss Rayleigh: 0.69325793 loss Rician: 0.69323662   running time 4.8952250480651855
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69321201 loss Rayleigh: 0.69319389 loss Rician: 0.69314604   running time 4.882845163345337
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69347668 loss Rayleigh: 0.69346803 loss Rician: 0.69340689   running time 4.859588146209717
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934260129928589 Custom Loss 0.6934260129928589 with ber  0.49991995096206665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934245824813843 Custom Loss 0.6934245824813843 with ber  0.49991995096206665 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934248208999634 Custom Loss 0.6934248208999634 with ber  0.49991995096206665 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.953480005264282s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335472 loss Rayleigh: 0.69335513 loss Rician: 0.69335546   running time 4.77136754989624
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328110 loss Rayleigh: 0.69328297 loss Rician: 0.69324683   running time 4.870108366012573
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336188 loss Rayleigh: 0.69334827 loss Rician: 0.69330493   running time 4.979290008544922
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334600 loss Rayleigh: 0.69332085 loss Rician: 0.69326586   running time 4.853117942810059
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337897 loss Rayleigh: 0.69339141 loss Rician: 0.69334565   running time 4.808740854263306
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335079 loss Rayleigh: 0.69334706 loss Rician: 0.69330247   running time 4.868054628372192
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934386491775513 Custom Loss 0.6934386491775513 with ber  0.5021200180053711 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934378743171692 Custom Loss 0.6934378743171692 with ber  0.5021200180053711 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934377551078796 Custom Loss 0.6934377551078796 with ber  0.5021200180053711 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 30.915632247924805s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4985199570655823 learn codes ber with rayleigh  0.4985199570655823 learn codes ber with rician  0.4985199570655823 ber with awgn  0.3761 ber with rayleigh  0.3948166666666667 ber with rician  0.3922833333333333
Test SNR 5 learn codes ber with awgn  0.49786001443862915 learn codes ber with rayleigh  0.49786001443862915 learn codes ber with rician  0.49786001443862915 ber with awgn  0.28514999999999996 ber with rayleigh  0.30883333333333335 ber with rician  0.2901166666666667
Test SNR 10 learn codes ber with awgn  0.5013200044631958 learn codes ber with rayleigh  0.5013200044631958 learn codes ber with rician  0.5013200044631958 ber with awgn  0.15705000000000002 ber with rayleigh  0.1834 ber with rician  0.14968333333333333
Test SNR 15 learn codes ber with awgn  0.5024399757385254 learn codes ber with rayleigh  0.5024399757385254 learn codes ber with rician  0.5024399757385254 ber with awgn  0.0383 ber with rayleigh  0.08325 ber with rician  0.04316666666666667
Test SNR 20 learn codes ber with awgn  0.4985399842262268 learn codes ber with rayleigh  0.4985399842262268 learn codes ber with rician  0.4985399842262268 ber with awgn  0.0006500000000000001 ber with rayleigh  0.030516666666666664 ber with rician  0.009716666666666667
Test SNR 25 learn codes ber with awgn  0.5019999742507935 learn codes ber with rayleigh  0.5019999742507935 learn codes ber with rician  0.5019999742507935 ber with awgn  0.0 ber with rayleigh  0.0104 ber with rician  0.0021999999999999997
Test SNR 30 learn codes ber with awgn  0.5007199645042419 learn codes ber with rayleigh  0.5007199645042419 learn codes ber with rician  0.5007199645042419 ber with awgn  0.0 ber with rayleigh  0.0030166666666666666 ber with rician  0.0007666666666666667
Test SNR 35 learn codes ber with awgn  0.5009999871253967 learn codes ber with rayleigh  0.5009999871253967 learn codes ber with rician  0.5009999871253967 ber with awgn  0.0 ber with rayleigh  0.0011 ber with rician  0.00011666666666666668
Test SNR 40 learn codes ber with awgn  0.49987998604774475 learn codes ber with rayleigh  0.49987998604774475 learn codes ber with rician  0.49987998604774475 ber with awgn  0.0 ber with rayleigh  0.00041666666666666664 ber with rician  6.666666666666667e-05
Test SNR 45 learn codes ber with awgn  0.5017600059509277 learn codes ber with rayleigh  0.5017600059509277 learn codes ber with rician  0.5017600059509277 ber with awgn  0.0 ber with rayleigh  6.666666666666667e-05 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.4945400357246399 learn codes ber with rayleigh  0.4945400357246399 learn codes ber with rician  0.4945400357246399 ber with awgn  0.0 ber with rayleigh  8.333333333333333e-05 ber with rician  1.6666666666666667e-05
Test SNR 55 learn codes ber with awgn  0.49619999527931213 learn codes ber with rayleigh  0.49619999527931213 learn codes ber with rician  0.49619999527931213 ber with awgn  0.0 ber with rayleigh  1.6666666666666667e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4973599910736084 learn codes ber with rayleigh  0.4973599910736084 learn codes ber with rician  0.4973599910736084 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4982600808143616 learn codes ber with rayleigh  0.4982600808143616 learn codes ber with rician  0.4982600808143616 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.500700056552887 learn codes ber with rayleigh  0.500700056552887 learn codes ber with rician  0.500700056552887 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4994800090789795 learn codes ber with rayleigh  0.4994800090789795 learn codes ber with rician  0.4994800090789795 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49651995301246643 learn codes ber with rayleigh  0.49651995301246643 learn codes ber with rician  0.49651995301246643 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4981600344181061 learn codes ber with rayleigh  0.4981600344181061 learn codes ber with rician  0.4981600344181061 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5004600286483765 learn codes ber with rayleigh  0.5004600286483765 learn codes ber with rician  0.5004600286483765 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5054199695587158 learn codes ber with rayleigh  0.5054199695587158 learn codes ber with rician  0.5054199695587158 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4985199570655823, 0.49786001443862915, 0.5013200044631958, 0.5024399757385254, 0.4985399842262268, 0.5019999742507935, 0.5007199645042419, 0.5009999871253967, 0.49987998604774475, 0.5017600059509277, 0.4945400357246399, 0.49619999527931213, 0.4973599910736084, 0.4982600808143616, 0.500700056552887, 0.4994800090789795, 0.49651995301246643, 0.4981600344181061, 0.5004600286483765, 0.5054199695587158]
Learn Codes rayleigh [0.4985199570655823, 0.49786001443862915, 0.5013200044631958, 0.5024399757385254, 0.4985399842262268, 0.5019999742507935, 0.5007199645042419, 0.5009999871253967, 0.49987998604774475, 0.5017600059509277, 0.4945400357246399, 0.49619999527931213, 0.4973599910736084, 0.4982600808143616, 0.500700056552887, 0.4994800090789795, 0.49651995301246643, 0.4981600344181061, 0.5004600286483765, 0.5054199695587158]
Learn Codes rician [0.4985199570655823, 0.49786001443862915, 0.5013200044631958, 0.5024399757385254, 0.4985399842262268, 0.5019999742507935, 0.5007199645042419, 0.5009999871253967, 0.49987998604774475, 0.5017600059509277, 0.4945400357246399, 0.49619999527931213, 0.4973599910736084, 0.4982600808143616, 0.500700056552887, 0.4994800090789795, 0.49651995301246643, 0.4981600344181061, 0.5004600286483765, 0.5054199695587158]
AWGN [0.3761, 0.28514999999999996, 0.15705000000000002, 0.0383, 0.0006500000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3948166666666667, 0.30883333333333335, 0.1834, 0.08325, 0.030516666666666664, 0.0104, 0.0030166666666666666, 0.0011, 0.00041666666666666664, 6.666666666666667e-05, 8.333333333333333e-05, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3922833333333333, 0.2901166666666667, 0.14968333333333333, 0.04316666666666667, 0.009716666666666667, 0.0021999999999999997, 0.0007666666666666667, 0.00011666666666666668, 6.666666666666667e-05, 0.0, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69345545 loss Rayleigh: 0.69344653 loss Rician: 0.69342212   running time 5.040514230728149
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70617187 loss Rayleigh: 0.70071842 loss Rician: 0.70270596   running time 5.096904516220093
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70030954 loss Rayleigh: 0.69801439 loss Rician: 0.70300536   running time 5.22442364692688
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69589645 loss Rayleigh: 0.69588002 loss Rician: 0.69462059   running time 5.1622607707977295
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69402461 loss Rayleigh: 0.69394812 loss Rician: 0.69373215   running time 5.1778483390808105
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69366432 loss Rayleigh: 0.69364350 loss Rician: 0.69350789   running time 5.138871669769287
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933042407035828 Custom Loss 0.6933042407035828 with ber  0.5024200081825256 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933475732803345 Custom Loss 0.6933475732803345 with ber  0.5023000836372375 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933436989784241 Custom Loss 0.6933436989784241 with ber  0.5028799772262573 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.87242150306702s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69329224 loss Rayleigh: 0.69329184 loss Rician: 0.69327543   running time 5.071235418319702
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69360516 loss Rayleigh: 0.69352635 loss Rician: 0.69337485   running time 5.259969711303711
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69355906 loss Rayleigh: 0.69353355 loss Rician: 0.69344820   running time 5.113290309906006
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69343210 loss Rayleigh: 0.69338572 loss Rician: 0.69327510   running time 5.122889518737793
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69333939 loss Rayleigh: 0.69333104 loss Rician: 0.69327903   running time 5.1587138175964355
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69330492 loss Rayleigh: 0.69329015 loss Rician: 0.69325365   running time 5.112852096557617
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932128071784973 Custom Loss 0.6932128071784973 with ber  0.5007799863815308 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932118535041809 Custom Loss 0.6932118535041809 with ber  0.5007799863815308 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932133436203003 Custom Loss 0.6932133436203003 with ber  0.5007799863815308 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.967063903808594s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69306341 loss Rayleigh: 0.69306235 loss Rician: 0.69306272   running time 5.0125486850738525
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325798 loss Rayleigh: 0.69324717 loss Rician: 0.69320260   running time 5.667438268661499
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69341845 loss Rayleigh: 0.69338321 loss Rician: 0.69330572   running time 5.160860300064087
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69321603 loss Rayleigh: 0.69320796 loss Rician: 0.69315407   running time 5.141374826431274
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69345328 loss Rayleigh: 0.69343806 loss Rician: 0.69335433   running time 5.1284215450286865
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69337824 loss Rayleigh: 0.69334797 loss Rician: 0.69327703   running time 5.1197288036346436
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932042241096497 Custom Loss 0.6932042241096497 with ber  0.4980599880218506 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693210244178772 Custom Loss 0.693210244178772 with ber  0.4980599880218506 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932053565979004 Custom Loss 0.6932053565979004 with ber  0.4980599880218506 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 33.204915285110474s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69324051 loss Rayleigh: 0.69323921 loss Rician: 0.69323711   running time 5.027177333831787
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69323508 loss Rayleigh: 0.69323220 loss Rician: 0.69320328   running time 5.145821571350098
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333050 loss Rayleigh: 0.69331170 loss Rician: 0.69323686   running time 5.116772174835205
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333460 loss Rayleigh: 0.69332197 loss Rician: 0.69327955   running time 5.224624395370483
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342906 loss Rayleigh: 0.69341317 loss Rician: 0.69335095   running time 5.1574482917785645
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333193 loss Rayleigh: 0.69331731 loss Rician: 0.69325627   running time 5.174145460128784
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933133602142334 Custom Loss 0.6933133602142334 with ber  0.500980019569397 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933380365371704 Custom Loss 0.6933380365371704 with ber  0.5011999607086182 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933295130729675 Custom Loss 0.6933295130729675 with ber  0.5011999607086182 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 33.04534101486206s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327977 loss Rayleigh: 0.69327567 loss Rician: 0.69327001   running time 5.07538628578186
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326583 loss Rayleigh: 0.69328840 loss Rician: 0.69325429   running time 5.1756346225738525
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332280 loss Rayleigh: 0.69329342 loss Rician: 0.69323443   running time 5.1651036739349365
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325747 loss Rayleigh: 0.69325657 loss Rician: 0.69322336   running time 5.155143737792969
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69324380 loss Rayleigh: 0.69324225 loss Rician: 0.69319329   running time 5.190264701843262
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69335388 loss Rayleigh: 0.69332500 loss Rician: 0.69325885   running time 5.138758420944214
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935039758682251 Custom Loss 0.6935039758682251 with ber  0.5039800405502319 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935409307479858 Custom Loss 0.6935409307479858 with ber  0.5033400058746338 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935216188430786 Custom Loss 0.6935216188430786 with ber  0.5032399892807007 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.88178777694702s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69354856 loss Rayleigh: 0.69354367 loss Rician: 0.69353458   running time 5.001462697982788
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69336343 loss Rayleigh: 0.69333063 loss Rician: 0.69324354   running time 5.139240264892578
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333029 loss Rayleigh: 0.69328883 loss Rician: 0.69317741   running time 5.184072971343994
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69342795 loss Rayleigh: 0.69338942 loss Rician: 0.69328207   running time 5.240357875823975
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69350940 loss Rayleigh: 0.69349606 loss Rician: 0.69337538   running time 5.071874141693115
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69334354 loss Rayleigh: 0.69330645 loss Rician: 0.69319060   running time 5.105805158615112
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932404637336731 Custom Loss 0.6932404637336731 with ber  0.4949999749660492 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933594942092896 Custom Loss 0.6933594942092896 with ber  0.49845999479293823 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933023929595947 Custom Loss 0.6933023929595947 with ber  0.49675998091697693 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.81989407539368s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69345620 loss Rayleigh: 0.69344261 loss Rician: 0.69341431   running time 5.002512454986572
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336426 loss Rayleigh: 0.69335524 loss Rician: 0.69325539   running time 5.18536901473999
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342563 loss Rayleigh: 0.69335183 loss Rician: 0.69315529   running time 5.102772235870361
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69357358 loss Rayleigh: 0.69359026 loss Rician: 0.69341328   running time 5.147381544113159
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342355 loss Rayleigh: 0.69340876 loss Rician: 0.69323600   running time 5.1335835456848145
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69369397 loss Rayleigh: 0.69362777 loss Rician: 0.69328085   running time 5.131246328353882
====> Test set BCE loss with SNR 0.0 for AWGN 0.6936947703361511 Custom Loss 0.6936947703361511 with ber  0.5004400014877319 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936517357826233 Custom Loss 0.6936517357826233 with ber  0.502020001411438 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6936724185943604 Custom Loss 0.6936724185943604 with ber  0.5039199590682983 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.80481958389282s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69346295 loss Rayleigh: 0.69346954 loss Rician: 0.69349141   running time 4.995811939239502
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69355236 loss Rayleigh: 0.69353294 loss Rician: 0.69326717   running time 5.236718654632568
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69357134 loss Rayleigh: 0.69353306 loss Rician: 0.69323182   running time 5.111086368560791
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69324690 loss Rayleigh: 0.69314984 loss Rician: 0.69302781   running time 5.154090642929077
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69365809 loss Rayleigh: 0.69338821 loss Rician: 0.69289702   running time 5.151492357254028
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69360363 loss Rayleigh: 0.69355162 loss Rician: 0.69309793   running time 5.114472150802612
====> Test set BCE loss with SNR 0.0 for AWGN 0.6928011178970337 Custom Loss 0.6928011178970337 with ber  0.49116000533103943 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933143138885498 Custom Loss 0.6933143138885498 with ber  0.4964600205421448 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930631399154663 Custom Loss 0.6930631399154663 with ber  0.4936400055885315 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.783891439437866s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69349633 loss Rayleigh: 0.69334807 loss Rician: 0.69329231   running time 5.009388208389282
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69364268 loss Rayleigh: 0.69364193 loss Rician: 0.69329469   running time 5.163973808288574
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69388260 loss Rayleigh: 0.69372079 loss Rician: 0.69323990   running time 5.159733772277832
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69373242 loss Rayleigh: 0.69366974 loss Rician: 0.69292746   running time 5.156432628631592
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69433410 loss Rayleigh: 0.69419360 loss Rician: 0.69315299   running time 5.149426460266113
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69372766 loss Rayleigh: 0.69379142 loss Rician: 0.69352563   running time 5.123218059539795
====> Test set BCE loss with SNR 0.0 for AWGN 0.6928159594535828 Custom Loss 0.6928159594535828 with ber  0.48472005128860474 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693354070186615 Custom Loss 0.693354070186615 with ber  0.49796000123023987 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930666565895081 Custom Loss 0.6930666565895081 with ber  0.4925599992275238 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.87092900276184s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331936 loss Rayleigh: 0.69324088 loss Rician: 0.69309259   running time 5.035631418228149
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69380959 loss Rayleigh: 0.69365090 loss Rician: 0.69335500   running time 5.135205030441284
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69387152 loss Rayleigh: 0.69377258 loss Rician: 0.69345733   running time 5.211847305297852
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69357357 loss Rayleigh: 0.69336029 loss Rician: 0.69298937   running time 5.208455562591553
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69386705 loss Rayleigh: 0.69362316 loss Rician: 0.69316986   running time 5.194592237472534
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69373360 loss Rayleigh: 0.69367906 loss Rician: 0.69334660   running time 5.163254976272583
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925725936889648 Custom Loss 0.6925725936889648 with ber  0.4852200150489807 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932355761528015 Custom Loss 0.6932355761528015 with ber  0.4976600110530853 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6928170919418335 Custom Loss 0.6928170919418335 with ber  0.49379998445510864 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 32.970155477523804s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.498119980096817 learn codes ber with rayleigh  0.4957199990749359 learn codes ber with rician  0.49258002638816833 ber with awgn  0.4402666666666667 ber with rayleigh  0.45004999999999995 ber with rician  0.45426666666666665
Test SNR 5 learn codes ber with awgn  0.5005000233650208 learn codes ber with rayleigh  0.49886003136634827 learn codes ber with rician  0.49626001715660095 ber with awgn  0.39333333333333337 ber with rayleigh  0.4152666666666667 ber with rician  0.40705
Test SNR 10 learn codes ber with awgn  0.5024800300598145 learn codes ber with rayleigh  0.5013799667358398 learn codes ber with rician  0.49935999512672424 ber with awgn  0.3128833333333333 ber with rayleigh  0.33198333333333335 ber with rician  0.31948333333333334
Test SNR 15 learn codes ber with awgn  0.5023399591445923 learn codes ber with rayleigh  0.4997600018978119 learn codes ber with rician  0.4989199638366699 ber with awgn  0.19408333333333333 ber with rayleigh  0.21736666666666665 ber with rician  0.1852
Test SNR 20 learn codes ber with awgn  0.4993000030517578 learn codes ber with rayleigh  0.497219979763031 learn codes ber with rician  0.49685996770858765 ber with awgn  0.06358333333333334 ber with rayleigh  0.10583333333333333 ber with rician  0.06456666666666666
Test SNR 25 learn codes ber with awgn  0.5011399388313293 learn codes ber with rayleigh  0.49915996193885803 learn codes ber with rician  0.49820002913475037 ber with awgn  0.002966666666666667 ber with rayleigh  0.039866666666666675 ber with rician  0.013766666666666667
Test SNR 30 learn codes ber with awgn  0.5016200542449951 learn codes ber with rayleigh  0.5002599954605103 learn codes ber with rician  0.49904003739356995 ber with awgn  0.0 ber with rayleigh  0.013716666666666665 ber with rician  0.0032166666666666663
Test SNR 35 learn codes ber with awgn  0.5023999810218811 learn codes ber with rayleigh  0.5021399855613708 learn codes ber with rician  0.4998200535774231 ber with awgn  0.0 ber with rayleigh  0.004633333333333333 ber with rician  0.0008500000000000001
Test SNR 40 learn codes ber with awgn  0.4985799789428711 learn codes ber with rayleigh  0.4972800314426422 learn codes ber with rician  0.4954000413417816 ber with awgn  0.0 ber with rayleigh  0.0012666666666666668 ber with rician  0.00016666666666666666
Test SNR 45 learn codes ber with awgn  0.5004599690437317 learn codes ber with rayleigh  0.49772000312805176 learn codes ber with rician  0.49786001443862915 ber with awgn  0.0 ber with rayleigh  0.0004 ber with rician  8.333333333333333e-05
Test SNR 50 learn codes ber with awgn  0.49827998876571655 learn codes ber with rayleigh  0.496800035238266 learn codes ber with rician  0.49563997983932495 ber with awgn  0.0 ber with rayleigh  0.00016666666666666666 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.49969998002052307 learn codes ber with rayleigh  0.497840017080307 learn codes ber with rician  0.49647998809814453 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  1.6666666666666667e-05
Test SNR 60 learn codes ber with awgn  0.5013200044631958 learn codes ber with rayleigh  0.49900001287460327 learn codes ber with rician  0.49873995780944824 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4982999861240387 learn codes ber with rayleigh  0.49729999899864197 learn codes ber with rician  0.4972600042819977 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5029000043869019 learn codes ber with rayleigh  0.501479983329773 learn codes ber with rician  0.4989200234413147 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4997600018978119 learn codes ber with rayleigh  0.4986400008201599 learn codes ber with rician  0.4975600242614746 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5069599747657776 learn codes ber with rayleigh  0.5065000057220459 learn codes ber with rician  0.5045599937438965 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49911999702453613 learn codes ber with rayleigh  0.4980999529361725 learn codes ber with rician  0.495959997177124 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5016800165176392 learn codes ber with rayleigh  0.49953994154930115 learn codes ber with rician  0.49858003854751587 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49973997473716736 learn codes ber with rayleigh  0.498960018157959 learn codes ber with rician  0.49720001220703125 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.498119980096817, 0.5005000233650208, 0.5024800300598145, 0.5023399591445923, 0.4993000030517578, 0.5011399388313293, 0.5016200542449951, 0.5023999810218811, 0.4985799789428711, 0.5004599690437317, 0.49827998876571655, 0.49969998002052307, 0.5013200044631958, 0.4982999861240387, 0.5029000043869019, 0.4997600018978119, 0.5069599747657776, 0.49911999702453613, 0.5016800165176392, 0.49973997473716736]
Learn Codes rayleigh [0.4957199990749359, 0.49886003136634827, 0.5013799667358398, 0.4997600018978119, 0.497219979763031, 0.49915996193885803, 0.5002599954605103, 0.5021399855613708, 0.4972800314426422, 0.49772000312805176, 0.496800035238266, 0.497840017080307, 0.49900001287460327, 0.49729999899864197, 0.501479983329773, 0.4986400008201599, 0.5065000057220459, 0.4980999529361725, 0.49953994154930115, 0.498960018157959]
Learn Codes rician [0.49258002638816833, 0.49626001715660095, 0.49935999512672424, 0.4989199638366699, 0.49685996770858765, 0.49820002913475037, 0.49904003739356995, 0.4998200535774231, 0.4954000413417816, 0.49786001443862915, 0.49563997983932495, 0.49647998809814453, 0.49873995780944824, 0.4972600042819977, 0.4989200234413147, 0.4975600242614746, 0.5045599937438965, 0.495959997177124, 0.49858003854751587, 0.49720001220703125]
AWGN [0.4402666666666667, 0.39333333333333337, 0.3128833333333333, 0.19408333333333333, 0.06358333333333334, 0.002966666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45004999999999995, 0.4152666666666667, 0.33198333333333335, 0.21736666666666665, 0.10583333333333333, 0.039866666666666675, 0.013716666666666665, 0.004633333333333333, 0.0012666666666666668, 0.0004, 0.00016666666666666666, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45426666666666665, 0.40705, 0.31948333333333334, 0.1852, 0.06456666666666666, 0.013766666666666667, 0.0032166666666666663, 0.0008500000000000001, 0.00016666666666666666, 8.333333333333333e-05, 0.0, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69347961 loss Rayleigh: 0.69347615 loss Rician: 0.69346697   running time 4.773430347442627
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70298926 loss Rayleigh: 0.69935509 loss Rician: 0.70010142   running time 4.979896545410156
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70386995 loss Rayleigh: 0.69911002 loss Rician: 0.70349796   running time 4.912660837173462
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69555078 loss Rayleigh: 0.69577402 loss Rician: 0.69533587   running time 4.958838224411011
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69378924 loss Rayleigh: 0.69379259 loss Rician: 0.69359110   running time 4.966736316680908
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69383608 loss Rayleigh: 0.69376575 loss Rician: 0.69353275   running time 4.9552412033081055
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935311555862427 Custom Loss 0.6935311555862427 with ber  0.4984714388847351 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6938267946243286 Custom Loss 0.6938267946243286 with ber  0.4992856979370117 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.693708062171936 Custom Loss 0.693708062171936 with ber  0.4993285536766052 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.300398349761963s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69410411 loss Rayleigh: 0.69409328 loss Rician: 0.69404778   running time 4.768354654312134
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69347880 loss Rayleigh: 0.69338256 loss Rician: 0.69320948   running time 4.9411420822143555
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69336900 loss Rayleigh: 0.69326531 loss Rician: 0.69311549   running time 4.931182861328125
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69350764 loss Rayleigh: 0.69325906 loss Rician: 0.69280020   running time 4.975709915161133
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69348996 loss Rayleigh: 0.69269077 loss Rician: 0.69177517   running time 4.929844617843628
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69357861 loss Rayleigh: 0.69330713 loss Rician: 0.69252273   running time 4.949820280075073
====> Test set BCE loss with SNR 0.0 for AWGN 0.6919476985931396 Custom Loss 0.6919476985931396 with ber  0.4759142994880676 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933576464653015 Custom Loss 0.6933576464653015 with ber  0.4944000244140625 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6927018165588379 Custom Loss 0.6927018165588379 with ber  0.48354285955429077 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.272290468215942s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69340541 loss Rayleigh: 0.69308119 loss Rician: 0.69272597   running time 4.786960124969482
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69362286 loss Rayleigh: 0.69321640 loss Rician: 0.69206094   running time 4.9204277992248535
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69388680 loss Rayleigh: 0.69294373 loss Rician: 0.69107821   running time 4.959017515182495
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69342248 loss Rayleigh: 0.69295612 loss Rician: 0.69110046   running time 4.897024869918823
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69351257 loss Rayleigh: 0.69281083 loss Rician: 0.69079170   running time 4.966348886489868
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69362496 loss Rayleigh: 0.69259955 loss Rician: 0.69046299   running time 4.864402770996094
====> Test set BCE loss with SNR 0.0 for AWGN 0.6896109580993652 Custom Loss 0.6896109580993652 with ber  0.46901431679725647 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926293969154358 Custom Loss 0.6926293969154358 with ber  0.48627138137817383 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6887885332107544 Custom Loss 0.6887885332107544 with ber  0.46478575468063354 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.267430305480957s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69408090 loss Rayleigh: 0.69311740 loss Rician: 0.69118452   running time 4.7512526512146
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333988 loss Rayleigh: 0.69259653 loss Rician: 0.69046944   running time 4.9441986083984375
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69355101 loss Rayleigh: 0.69271014 loss Rician: 0.68985959   running time 4.982789039611816
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69345023 loss Rayleigh: 0.69250745 loss Rician: 0.69000687   running time 4.925894498825073
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69371830 loss Rayleigh: 0.69284104 loss Rician: 0.69114029   running time 4.974323749542236
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69378567 loss Rayleigh: 0.69319879 loss Rician: 0.69068636   running time 4.920002460479736
====> Test set BCE loss with SNR 0.0 for AWGN 0.6888852119445801 Custom Loss 0.6888852119445801 with ber  0.4653142988681793 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6922479867935181 Custom Loss 0.6922479867935181 with ber  0.4829571843147278 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6890826225280762 Custom Loss 0.6890826225280762 with ber  0.4559428095817566 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.327836751937866s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69341987 loss Rayleigh: 0.69245624 loss Rician: 0.69076192   running time 4.817561864852905
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69337050 loss Rayleigh: 0.69270573 loss Rician: 0.69034944   running time 5.037173509597778
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69355864 loss Rayleigh: 0.69265068 loss Rician: 0.69022729   running time 4.92923378944397
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69359384 loss Rayleigh: 0.69260660 loss Rician: 0.69000487   running time 4.95573878288269
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69352270 loss Rayleigh: 0.69246962 loss Rician: 0.69055447   running time 4.9372429847717285
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69365749 loss Rayleigh: 0.69306942 loss Rician: 0.69006985   running time 4.964784383773804
====> Test set BCE loss with SNR 0.0 for AWGN 0.6907228231430054 Custom Loss 0.6907228231430054 with ber  0.47604283690452576 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6923230290412903 Custom Loss 0.6923230290412903 with ber  0.4823857247829437 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6880078315734863 Custom Loss 0.6880078315734863 with ber  0.45871424674987793 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.406432151794434s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69345177 loss Rayleigh: 0.69227283 loss Rician: 0.68986242   running time 4.9261698722839355
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69348369 loss Rayleigh: 0.69259728 loss Rician: 0.68963963   running time 4.974054574966431
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69374226 loss Rayleigh: 0.69281709 loss Rician: 0.68996174   running time 4.925363779067993
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69353894 loss Rayleigh: 0.69262137 loss Rician: 0.68991249   running time 4.969643831253052
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69364138 loss Rayleigh: 0.69275261 loss Rician: 0.68960080   running time 4.923327684402466
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69346414 loss Rayleigh: 0.69244119 loss Rician: 0.68919297   running time 4.930173397064209
====> Test set BCE loss with SNR 0.0 for AWGN 0.690160870552063 Custom Loss 0.690160870552063 with ber  0.4716857373714447 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925889253616333 Custom Loss 0.6925889253616333 with ber  0.48587146401405334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6874579787254333 Custom Loss 0.6874579787254333 with ber  0.45578569173812866 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.558847665786743s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327953 loss Rayleigh: 0.69289636 loss Rician: 0.68994672   running time 4.800348281860352
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69356360 loss Rayleigh: 0.69261076 loss Rician: 0.69031353   running time 4.982621908187866
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69342207 loss Rayleigh: 0.69270734 loss Rician: 0.68975247   running time 4.959748268127441
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69347541 loss Rayleigh: 0.69213250 loss Rician: 0.68906378   running time 4.887836694717407
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69352813 loss Rayleigh: 0.69225016 loss Rician: 0.68921729   running time 4.905375003814697
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69345938 loss Rayleigh: 0.69276061 loss Rician: 0.69022996   running time 4.972893476486206
====> Test set BCE loss with SNR 0.0 for AWGN 0.6901599168777466 Custom Loss 0.6901599168777466 with ber  0.47362858057022095 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6923805475234985 Custom Loss 0.6923805475234985 with ber  0.48337140679359436 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6884444355964661 Custom Loss 0.6884444355964661 with ber  0.4559714198112488 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.432028770446777s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69321206 loss Rayleigh: 0.69224668 loss Rician: 0.68979943   running time 4.82094669342041
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337298 loss Rayleigh: 0.69235035 loss Rician: 0.68943899   running time 4.953392267227173
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69352193 loss Rayleigh: 0.69259131 loss Rician: 0.68949396   running time 4.943567991256714
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69354542 loss Rayleigh: 0.69222649 loss Rician: 0.68933145   running time 4.93982458114624
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69334581 loss Rayleigh: 0.69256338 loss Rician: 0.68967460   running time 4.9924187660217285
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337542 loss Rayleigh: 0.69246464 loss Rician: 0.68899436   running time 4.895718812942505
====> Test set BCE loss with SNR 0.0 for AWGN 0.6894035339355469 Custom Loss 0.6894035339355469 with ber  0.4741000235080719 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6923949122428894 Custom Loss 0.6923949122428894 with ber  0.4859713912010193 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6872619390487671 Custom Loss 0.6872619390487671 with ber  0.45509999990463257 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.29635715484619s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69367881 loss Rayleigh: 0.69256045 loss Rician: 0.68924417   running time 4.909366130828857
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69377688 loss Rayleigh: 0.69292596 loss Rician: 0.68991461   running time 5.041570425033569
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69362962 loss Rayleigh: 0.69231518 loss Rician: 0.68905450   running time 5.072512865066528
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69351814 loss Rayleigh: 0.69263467 loss Rician: 0.68944039   running time 4.9938647747039795
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69345858 loss Rayleigh: 0.69231712 loss Rician: 0.68945692   running time 4.90990138053894
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69364398 loss Rayleigh: 0.69268258 loss Rician: 0.68937742   running time 4.977708101272583
====> Test set BCE loss with SNR 0.0 for AWGN 0.690679669380188 Custom Loss 0.690679669380188 with ber  0.4740571081638336 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6924155950546265 Custom Loss 0.6924155950546265 with ber  0.48098573088645935 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6870070695877075 Custom Loss 0.6870070695877075 with ber  0.4523142874240875 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.672914028167725s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69341353 loss Rayleigh: 0.69231657 loss Rician: 0.68947231   running time 4.8362438678741455
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69368920 loss Rayleigh: 0.69256570 loss Rician: 0.68939381   running time 4.988520383834839
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69355271 loss Rayleigh: 0.69266062 loss Rician: 0.68971387   running time 4.936784982681274
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69350845 loss Rayleigh: 0.69291304 loss Rician: 0.68981431   running time 4.974902391433716
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69362350 loss Rayleigh: 0.69265737 loss Rician: 0.68919811   running time 5.003433704376221
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69347841 loss Rayleigh: 0.69242535 loss Rician: 0.68862607   running time 5.057856321334839
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931244730949402 Custom Loss 0.6931244730949402 with ber  0.4802857041358948 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926537156105042 Custom Loss 0.6926537156105042 with ber  0.4807285666465759 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6879494786262512 Custom Loss 0.6879494786262512 with ber  0.4593571126461029 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 31.783010482788086s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5001143217086792 learn codes ber with rayleigh  0.484585702419281 learn codes ber with rician  0.46844282746315 ber with awgn  0.37557500000000005 ber with rayleigh  0.394775 ber with rician  0.38772500000000004
Test SNR 5 learn codes ber with awgn  0.5030571222305298 learn codes ber with rayleigh  0.4897286295890808 learn codes ber with rician  0.4657714366912842 ber with awgn  0.2865875 ber with rayleigh  0.3089375 ber with rician  0.28737500000000005
Test SNR 10 learn codes ber with awgn  0.4982428550720215 learn codes ber with rayleigh  0.48767146468162537 learn codes ber with rician  0.45809999108314514 ber with awgn  0.1590125 ber with rayleigh  0.18536249999999999 ber with rician  0.1407875
Test SNR 15 learn codes ber with awgn  0.4960857331752777 learn codes ber with rayleigh  0.4870571196079254 learn codes ber with rician  0.45895713567733765 ber with awgn  0.036775 ber with rayleigh  0.08317500000000001 ber with rician  0.0339
Test SNR 20 learn codes ber with awgn  0.4975428581237793 learn codes ber with rayleigh  0.48732858896255493 learn codes ber with rician  0.45905715227127075 ber with awgn  0.0007 ber with rayleigh  0.03055 ber with rician  0.0045000000000000005
Test SNR 25 learn codes ber with awgn  0.4981857240200043 learn codes ber with rayleigh  0.4883999824523926 learn codes ber with rician  0.4616857171058655 ber with awgn  0.0 ber with rayleigh  0.010562499999999999 ber with rician  0.0008624999999999999
Test SNR 30 learn codes ber with awgn  0.4983428120613098 learn codes ber with rayleigh  0.4889143109321594 learn codes ber with rician  0.4575428366661072 ber with awgn  0.0 ber with rayleigh  0.0032375 ber with rician  0.00015000000000000001
Test SNR 35 learn codes ber with awgn  0.5015570521354675 learn codes ber with rayleigh  0.4910571575164795 learn codes ber with rician  0.4594714641571045 ber with awgn  0.0 ber with rayleigh  0.0011375 ber with rician  7.500000000000001e-05
Test SNR 40 learn codes ber with awgn  0.4975714087486267 learn codes ber with rayleigh  0.48808568716049194 learn codes ber with rician  0.45672860741615295 ber with awgn  0.0 ber with rayleigh  0.00032499999999999993 ber with rician  0.0
Test SNR 45 learn codes ber with awgn  0.5005285739898682 learn codes ber with rayleigh  0.491328626871109 learn codes ber with rician  0.459371417760849 ber with awgn  0.0 ber with rayleigh  8.75e-05 ber with rician  1.25e-05
Test SNR 50 learn codes ber with awgn  0.5000285506248474 learn codes ber with rayleigh  0.49048566818237305 learn codes ber with rician  0.45824283361434937 ber with awgn  0.0 ber with rayleigh  3.7500000000000003e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.49894285202026367 learn codes ber with rayleigh  0.48832860589027405 learn codes ber with rician  0.45972856879234314 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.501885712146759 learn codes ber with rayleigh  0.48961424827575684 learn codes ber with rician  0.45657142996788025 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5005571842193604 learn codes ber with rayleigh  0.49075713753700256 learn codes ber with rician  0.46071428060531616 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49802860617637634 learn codes ber with rayleigh  0.48994284868240356 learn codes ber with rician  0.46145716309547424 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5008571743965149 learn codes ber with rayleigh  0.4917285442352295 learn codes ber with rician  0.46132856607437134 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4999571442604065 learn codes ber with rayleigh  0.4918143153190613 learn codes ber with rician  0.4620571732521057 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5015285611152649 learn codes ber with rayleigh  0.49152860045433044 learn codes ber with rician  0.4579285681247711 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49851423501968384 learn codes ber with rayleigh  0.4883142411708832 learn codes ber with rician  0.4592857360839844 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.499828577041626 learn codes ber with rayleigh  0.49230003356933594 learn codes ber with rician  0.45952853560447693 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5001143217086792, 0.5030571222305298, 0.4982428550720215, 0.4960857331752777, 0.4975428581237793, 0.4981857240200043, 0.4983428120613098, 0.5015570521354675, 0.4975714087486267, 0.5005285739898682, 0.5000285506248474, 0.49894285202026367, 0.501885712146759, 0.5005571842193604, 0.49802860617637634, 0.5008571743965149, 0.4999571442604065, 0.5015285611152649, 0.49851423501968384, 0.499828577041626]
Learn Codes rayleigh [0.484585702419281, 0.4897286295890808, 0.48767146468162537, 0.4870571196079254, 0.48732858896255493, 0.4883999824523926, 0.4889143109321594, 0.4910571575164795, 0.48808568716049194, 0.491328626871109, 0.49048566818237305, 0.48832860589027405, 0.48961424827575684, 0.49075713753700256, 0.48994284868240356, 0.4917285442352295, 0.4918143153190613, 0.49152860045433044, 0.4883142411708832, 0.49230003356933594]
Learn Codes rician [0.46844282746315, 0.4657714366912842, 0.45809999108314514, 0.45895713567733765, 0.45905715227127075, 0.4616857171058655, 0.4575428366661072, 0.4594714641571045, 0.45672860741615295, 0.459371417760849, 0.45824283361434937, 0.45972856879234314, 0.45657142996788025, 0.46071428060531616, 0.46145716309547424, 0.46132856607437134, 0.4620571732521057, 0.4579285681247711, 0.4592857360839844, 0.45952853560447693]
AWGN [0.37557500000000005, 0.2865875, 0.1590125, 0.036775, 0.0007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.394775, 0.3089375, 0.18536249999999999, 0.08317500000000001, 0.03055, 0.010562499999999999, 0.0032375, 0.0011375, 0.00032499999999999993, 8.75e-05, 3.7500000000000003e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.38772500000000004, 0.28737500000000005, 0.1407875, 0.0339, 0.0045000000000000005, 0.0008624999999999999, 0.00015000000000000001, 7.500000000000001e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69365419 loss Rayleigh: 0.69364885 loss Rician: 0.69363160   running time 5.200934648513794
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70796788 loss Rayleigh: 0.70195063 loss Rician: 0.70305373   running time 5.277294397354126
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70492471 loss Rayleigh: 0.70690131 loss Rician: 0.70134269   running time 5.2995500564575195
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69523280 loss Rayleigh: 0.69527396 loss Rician: 0.69461038   running time 5.326946496963501
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69367519 loss Rayleigh: 0.69366506 loss Rician: 0.69356367   running time 5.2721521854400635
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69337184 loss Rayleigh: 0.69337918 loss Rician: 0.69332685   running time 5.274060487747192
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933369636535645 Custom Loss 0.6933369636535645 with ber  0.49869999289512634 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693361759185791 Custom Loss 0.693361759185791 with ber  0.4984428286552429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933999061584473 Custom Loss 0.6933999061584473 with ber  0.498285710811615 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 33.79962491989136s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69357461 loss Rayleigh: 0.69357973 loss Rician: 0.69359815   running time 5.20172119140625
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328793 loss Rayleigh: 0.69329046 loss Rician: 0.69326145   running time 5.292354106903076
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69346641 loss Rayleigh: 0.69344587 loss Rician: 0.69337566   running time 5.499230861663818
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338727 loss Rayleigh: 0.69337528 loss Rician: 0.69332402   running time 5.3509910106658936
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69329537 loss Rayleigh: 0.69326468 loss Rician: 0.69318309   running time 5.2853593826293945
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69334186 loss Rayleigh: 0.69332228 loss Rician: 0.69325494   running time 5.346368789672852
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933584809303284 Custom Loss 0.6933584809303284 with ber  0.4986000061035156 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933670043945312 Custom Loss 0.6933670043945312 with ber  0.49882858991622925 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933633685112 Custom Loss 0.6933633685112 with ber  0.49874281883239746 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.139952182769775s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328029 loss Rayleigh: 0.69327735 loss Rician: 0.69327351   running time 5.157644987106323
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69341926 loss Rayleigh: 0.69339629 loss Rician: 0.69333030   running time 5.315011262893677
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336689 loss Rayleigh: 0.69334627 loss Rician: 0.69327642   running time 5.3242199420928955
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328238 loss Rayleigh: 0.69327388 loss Rician: 0.69322904   running time 5.304097652435303
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329283 loss Rayleigh: 0.69327032 loss Rician: 0.69321709   running time 5.326571464538574
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69340650 loss Rayleigh: 0.69338579 loss Rician: 0.69330856   running time 5.488672733306885
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931856870651245 Custom Loss 0.6931856870651245 with ber  0.4985714554786682 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931859850883484 Custom Loss 0.6931859850883484 with ber  0.4985428750514984 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931909322738647 Custom Loss 0.6931909322738647 with ber  0.4984142780303955 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.12081241607666s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69318449 loss Rayleigh: 0.69317799 loss Rician: 0.69318658   running time 5.146012783050537
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69320630 loss Rayleigh: 0.69321058 loss Rician: 0.69319719   running time 5.297463655471802
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330704 loss Rayleigh: 0.69327189 loss Rician: 0.69319605   running time 5.2560224533081055
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69345573 loss Rayleigh: 0.69343724 loss Rician: 0.69334431   running time 5.281074285507202
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69331145 loss Rayleigh: 0.69330444 loss Rician: 0.69324809   running time 5.324256420135498
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69323442 loss Rayleigh: 0.69324005 loss Rician: 0.69320968   running time 5.29816460609436
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932920217514038 Custom Loss 0.6932920217514038 with ber  0.499828577041626 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932981610298157 Custom Loss 0.6932981610298157 with ber  0.4998142719268799 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932976841926575 Custom Loss 0.6932976841926575 with ber  0.4997285306453705 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 33.92717790603638s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330025 loss Rayleigh: 0.69329933 loss Rician: 0.69329933   running time 5.202093601226807
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325066 loss Rayleigh: 0.69324640 loss Rician: 0.69322184   running time 5.301103591918945
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69328963 loss Rayleigh: 0.69325962 loss Rician: 0.69319982   running time 5.307390213012695
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69331359 loss Rayleigh: 0.69330127 loss Rician: 0.69325088   running time 5.242933988571167
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69343548 loss Rayleigh: 0.69341154 loss Rician: 0.69333724   running time 5.302384376525879
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69344231 loss Rayleigh: 0.69343063 loss Rician: 0.69335924   running time 5.342758417129517
====> Test set BCE loss with SNR 0.0 for AWGN 0.6930538415908813 Custom Loss 0.6930538415908813 with ber  0.49378570914268494 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930584907531738 Custom Loss 0.6930584907531738 with ber  0.4931570887565613 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930629014968872 Custom Loss 0.6930629014968872 with ber  0.49330005049705505 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 33.92740535736084s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69324232 loss Rayleigh: 0.69324179 loss Rician: 0.69323744   running time 5.233073711395264
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328822 loss Rayleigh: 0.69326937 loss Rician: 0.69321400   running time 5.318184852600098
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69342691 loss Rayleigh: 0.69341093 loss Rician: 0.69334546   running time 5.359915018081665
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69334143 loss Rayleigh: 0.69334384 loss Rician: 0.69328920   running time 5.328205823898315
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69321596 loss Rayleigh: 0.69322006 loss Rician: 0.69319072   running time 5.369142055511475
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69334784 loss Rayleigh: 0.69333145 loss Rician: 0.69327096   running time 5.315504312515259
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934446096420288 Custom Loss 0.6934446096420288 with ber  0.5012428760528564 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934458613395691 Custom Loss 0.6934458613395691 with ber  0.5012428760528564 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934451460838318 Custom Loss 0.6934451460838318 with ber  0.5012428760528564 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.47555947303772s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69338020 loss Rayleigh: 0.69338093 loss Rician: 0.69338470   running time 5.368650197982788
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340621 loss Rayleigh: 0.69338865 loss Rician: 0.69332573   running time 5.338905334472656
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331030 loss Rayleigh: 0.69329572 loss Rician: 0.69322976   running time 5.334789276123047
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69346709 loss Rayleigh: 0.69344894 loss Rician: 0.69337423   running time 5.393475294113159
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69333407 loss Rayleigh: 0.69332072 loss Rician: 0.69325850   running time 5.339665412902832
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69343843 loss Rayleigh: 0.69339845 loss Rician: 0.69329386   running time 5.310224533081055
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934224367141724 Custom Loss 0.6934224367141724 with ber  0.49891430139541626 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934720873832703 Custom Loss 0.6934720873832703 with ber  0.49891430139541626 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934717297554016 Custom Loss 0.6934717297554016 with ber  0.49891430139541626 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.20267176628113s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69333065 loss Rayleigh: 0.69332792 loss Rician: 0.69331936   running time 5.15242600440979
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69342183 loss Rayleigh: 0.69334652 loss Rician: 0.69317706   running time 5.989544153213501
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69360349 loss Rayleigh: 0.69354623 loss Rician: 0.69339275   running time 5.341989517211914
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69368268 loss Rayleigh: 0.69366674 loss Rician: 0.69349043   running time 5.299280881881714
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69348886 loss Rayleigh: 0.69347072 loss Rician: 0.69332232   running time 5.3041651248931885
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69343411 loss Rayleigh: 0.69345768 loss Rician: 0.69337067   running time 5.395411968231201
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932083368301392 Custom Loss 0.6932083368301392 with ber  0.49875718355178833 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932244896888733 Custom Loss 0.6932244896888733 with ber  0.49884286522865295 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932289600372314 Custom Loss 0.6932289600372314 with ber  0.4990285336971283 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.592878103256226s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325114 loss Rayleigh: 0.69325145 loss Rician: 0.69325428   running time 5.17888331413269
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333227 loss Rayleigh: 0.69331135 loss Rician: 0.69324895   running time 5.290666103363037
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69342870 loss Rayleigh: 0.69339777 loss Rician: 0.69330472   running time 5.357443809509277
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69340421 loss Rayleigh: 0.69339029 loss Rician: 0.69331769   running time 5.316782474517822
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336160 loss Rayleigh: 0.69333824 loss Rician: 0.69326965   running time 5.436546087265015
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333095 loss Rayleigh: 0.69331940 loss Rician: 0.69324647   running time 5.32525897026062
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933178305625916 Custom Loss 0.6933178305625916 with ber  0.4989714026451111 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933227181434631 Custom Loss 0.6933227181434631 with ber  0.4989714026451111 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933227777481079 Custom Loss 0.6933227777481079 with ber  0.4989714026451111 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.07685303688049s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336042 loss Rayleigh: 0.69336041 loss Rician: 0.69336066   running time 5.188362121582031
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337915 loss Rayleigh: 0.69336018 loss Rician: 0.69328341   running time 5.34611439704895
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336418 loss Rayleigh: 0.69334593 loss Rician: 0.69328405   running time 5.353846788406372
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69342726 loss Rayleigh: 0.69338077 loss Rician: 0.69325246   running time 5.3832714557647705
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69348215 loss Rayleigh: 0.69345694 loss Rician: 0.69334418   running time 5.309277057647705
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69338187 loss Rayleigh: 0.69335088 loss Rician: 0.69328067   running time 5.341084957122803
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934173703193665 Custom Loss 0.6934173703193665 with ber  0.5010142922401428 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934212446212769 Custom Loss 0.6934212446212769 with ber  0.5011571645736694 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934231519699097 Custom Loss 0.6934231519699097 with ber  0.5012000203132629 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 34.24970626831055s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4989285469055176 learn codes ber with rayleigh  0.498957097530365 learn codes ber with rician  0.4989857077598572 ber with awgn  0.4412 ber with rayleigh  0.45583750000000006 ber with rician  0.44765
Test SNR 5 learn codes ber with awgn  0.5003000497817993 learn codes ber with rayleigh  0.5002714395523071 learn codes ber with rician  0.5003142952919006 ber with awgn  0.39225 ber with rayleigh  0.4146875 ber with rician  0.4058624999999999
Test SNR 10 learn codes ber with awgn  0.5010000467300415 learn codes ber with rayleigh  0.5009142756462097 learn codes ber with rician  0.5009857416152954 ber with awgn  0.3154 ber with rayleigh  0.3316375 ber with rician  0.3172125
Test SNR 15 learn codes ber with awgn  0.5011714696884155 learn codes ber with rayleigh  0.5011571645736694 learn codes ber with rician  0.5011714696884155 ber with awgn  0.19146249999999998 ber with rayleigh  0.216675 ber with rician  0.17331249999999995
Test SNR 20 learn codes ber with awgn  0.5009571313858032 learn codes ber with rayleigh  0.5009428858757019 learn codes ber with rician  0.5009428858757019 ber with awgn  0.061837500000000004 ber with rayleigh  0.1041 ber with rician  0.05197499999999999
Test SNR 25 learn codes ber with awgn  0.5011857151985168 learn codes ber with rayleigh  0.5012000203132629 learn codes ber with rician  0.5011857151985168 ber with awgn  0.0029375 ber with rayleigh  0.039462500000000005 ber with rician  0.007575
Test SNR 30 learn codes ber with awgn  0.5028571486473083 learn codes ber with rayleigh  0.5028428435325623 learn codes ber with rician  0.5028713941574097 ber with awgn  0.0 ber with rayleigh  0.013375000000000001 ber with rician  0.0010624999999999999
Test SNR 35 learn codes ber with awgn  0.4966856837272644 learn codes ber with rayleigh  0.4966999888420105 learn codes ber with rician  0.4966856837272644 ber with awgn  0.0 ber with rayleigh  0.003962500000000001 ber with rician  0.00016250000000000002
Test SNR 40 learn codes ber with awgn  0.5005571842193604 learn codes ber with rayleigh  0.5005571842193604 learn codes ber with rician  0.5005571842193604 ber with awgn  0.0 ber with rayleigh  0.00135 ber with rician  1.25e-05
Test SNR 45 learn codes ber with awgn  0.5006142854690552 learn codes ber with rayleigh  0.5006142854690552 learn codes ber with rician  0.5006142854690552 ber with awgn  0.0 ber with rayleigh  0.0005625 ber with rician  6.25e-05
Test SNR 50 learn codes ber with awgn  0.5012571811676025 learn codes ber with rayleigh  0.5012571811676025 learn codes ber with rician  0.5012714862823486 ber with awgn  0.0 ber with rayleigh  0.0001375 ber with rician  1.25e-05
Test SNR 55 learn codes ber with awgn  0.5001286268234253 learn codes ber with rayleigh  0.5001286268234253 learn codes ber with rician  0.5001286268234253 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49982863664627075 learn codes ber with rayleigh  0.49984288215637207 learn codes ber with rician  0.49982863664627075 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  1.25e-05
Test SNR 65 learn codes ber with awgn  0.5012428760528564 learn codes ber with rayleigh  0.5012571811676025 learn codes ber with rician  0.5012428760528564 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5008285641670227 learn codes ber with rayleigh  0.5008285641670227 learn codes ber with rician  0.5008285641670227 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.500499963760376 learn codes ber with rayleigh  0.5004856586456299 learn codes ber with rician  0.5005285739898682 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5018714666366577 learn codes ber with rayleigh  0.5018714666366577 learn codes ber with rician  0.5018428564071655 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5022714138031006 learn codes ber with rayleigh  0.5022857189178467 learn codes ber with rician  0.5022571086883545 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5031000375747681 learn codes ber with rayleigh  0.5031000375747681 learn codes ber with rician  0.5031000375747681 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49967139959335327 learn codes ber with rayleigh  0.49968570470809937 learn codes ber with rician  0.49965715408325195 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4989285469055176, 0.5003000497817993, 0.5010000467300415, 0.5011714696884155, 0.5009571313858032, 0.5011857151985168, 0.5028571486473083, 0.4966856837272644, 0.5005571842193604, 0.5006142854690552, 0.5012571811676025, 0.5001286268234253, 0.49982863664627075, 0.5012428760528564, 0.5008285641670227, 0.500499963760376, 0.5018714666366577, 0.5022714138031006, 0.5031000375747681, 0.49967139959335327]
Learn Codes rayleigh [0.498957097530365, 0.5002714395523071, 0.5009142756462097, 0.5011571645736694, 0.5009428858757019, 0.5012000203132629, 0.5028428435325623, 0.4966999888420105, 0.5005571842193604, 0.5006142854690552, 0.5012571811676025, 0.5001286268234253, 0.49984288215637207, 0.5012571811676025, 0.5008285641670227, 0.5004856586456299, 0.5018714666366577, 0.5022857189178467, 0.5031000375747681, 0.49968570470809937]
Learn Codes rician [0.4989857077598572, 0.5003142952919006, 0.5009857416152954, 0.5011714696884155, 0.5009428858757019, 0.5011857151985168, 0.5028713941574097, 0.4966856837272644, 0.5005571842193604, 0.5006142854690552, 0.5012714862823486, 0.5001286268234253, 0.49982863664627075, 0.5012428760528564, 0.5008285641670227, 0.5005285739898682, 0.5018428564071655, 0.5022571086883545, 0.5031000375747681, 0.49965715408325195]
AWGN [0.4412, 0.39225, 0.3154, 0.19146249999999998, 0.061837500000000004, 0.0029375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45583750000000006, 0.4146875, 0.3316375, 0.216675, 0.1041, 0.039462500000000005, 0.013375000000000001, 0.003962500000000001, 0.00135, 0.0005625, 0.0001375, 5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.44765, 0.4058624999999999, 0.3172125, 0.17331249999999995, 0.05197499999999999, 0.007575, 0.0010624999999999999, 0.00016250000000000002, 1.25e-05, 6.25e-05, 1.25e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69338610 loss Rayleigh: 0.69337449 loss Rician: 0.69335583   running time 11.55325436592102
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71697806 loss Rayleigh: 0.70948099 loss Rician: 0.70610389   running time 11.63790512084961
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.72979062 loss Rayleigh: 0.70995545 loss Rician: 0.72970994   running time 11.769759893417358
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70432172 loss Rayleigh: 0.70417652 loss Rician: 0.69900483   running time 11.701081991195679
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69377035 loss Rayleigh: 0.69381614 loss Rician: 0.69378806   running time 11.584565162658691
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69342728 loss Rayleigh: 0.69342507 loss Rician: 0.69336588   running time 11.83154582977295
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932719945907593 Custom Loss 0.6932719945907593 with ber  0.49994999170303345 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932799816131592 Custom Loss 0.6932799816131592 with ber  0.4989333748817444 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932870149612427 Custom Loss 0.6932870149612427 with ber  0.4990333020687103 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 73.5194685459137s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69334550 loss Rayleigh: 0.69335533 loss Rician: 0.69335283   running time 11.70531439781189
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69323707 loss Rayleigh: 0.69322377 loss Rician: 0.69316933   running time 11.752753973007202
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69332496 loss Rayleigh: 0.69330535 loss Rician: 0.69327802   running time 11.538190841674805
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331541 loss Rayleigh: 0.69327765 loss Rician: 0.69325813   running time 12.112310647964478
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69332592 loss Rayleigh: 0.69327016 loss Rician: 0.69322432   running time 11.707632064819336
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69325551 loss Rayleigh: 0.69322326 loss Rician: 0.69320120   running time 11.646878957748413
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932646036148071 Custom Loss 0.6932646036148071 with ber  0.49808335304260254 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932625770568848 Custom Loss 0.6932625770568848 with ber  0.4989999830722809 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932410001754761 Custom Loss 0.6932410001754761 with ber  0.4984833598136902 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 74.00097036361694s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69343406 loss Rayleigh: 0.69343896 loss Rician: 0.69343331   running time 11.5956289768219
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333701 loss Rayleigh: 0.69329620 loss Rician: 0.69321391   running time 11.924445867538452
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333519 loss Rayleigh: 0.69327488 loss Rician: 0.69316828   running time 11.684125423431396
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328640 loss Rayleigh: 0.69324692 loss Rician: 0.69320219   running time 11.800480842590332
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69322852 loss Rayleigh: 0.69322258 loss Rician: 0.69314340   running time 11.737732887268066
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323030 loss Rayleigh: 0.69320745 loss Rician: 0.69313519   running time 11.630390644073486
====> Test set BCE loss with SNR 0.0 for AWGN 0.6929537653923035 Custom Loss 0.6929537653923035 with ber  0.4961666166782379 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931365132331848 Custom Loss 0.6931365132331848 with ber  0.49924999475479126 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930416822433472 Custom Loss 0.6930416822433472 with ber  0.4967833459377289 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 73.97207140922546s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321421 loss Rayleigh: 0.69318077 loss Rician: 0.69313571   running time 11.573813438415527
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69318523 loss Rayleigh: 0.69315041 loss Rician: 0.69304960   running time 11.742785453796387
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69319531 loss Rayleigh: 0.69308749 loss Rician: 0.69306412   running time 11.791576147079468
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69332761 loss Rayleigh: 0.69330385 loss Rician: 0.69319701   running time 11.739962816238403
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69323970 loss Rayleigh: 0.69320133 loss Rician: 0.69314607   running time 11.84000301361084
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69315422 loss Rayleigh: 0.69314192 loss Rician: 0.69306083   running time 11.77821660041809
====> Test set BCE loss with SNR 0.0 for AWGN 0.6929652690887451 Custom Loss 0.6929652690887451 with ber  0.48988333344459534 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931383609771729 Custom Loss 0.6931383609771729 with ber  0.49576669931411743 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6930387616157532 Custom Loss 0.6930387616157532 with ber  0.49076661467552185 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 73.93502688407898s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69316162 loss Rayleigh: 0.69312067 loss Rician: 0.69305018   running time 13.855605125427246
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69320425 loss Rayleigh: 0.69317297 loss Rician: 0.69306903   running time 11.876478433609009
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325349 loss Rayleigh: 0.69320084 loss Rician: 0.69306352   running time 11.670992612838745
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69323803 loss Rayleigh: 0.69311874 loss Rician: 0.69304364   running time 11.750445365905762
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69322539 loss Rayleigh: 0.69310492 loss Rician: 0.69294560   running time 11.723299264907837
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69324551 loss Rayleigh: 0.69312121 loss Rician: 0.69291676   running time 264.7181613445282
====> Test set BCE loss with SNR 0.0 for AWGN 0.6923004388809204 Custom Loss 0.6923004388809204 with ber  0.4855000376701355 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693200945854187 Custom Loss 0.693200945854187 with ber  0.4957999587059021 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6928080320358276 Custom Loss 0.6928080320358276 with ber  0.49363335967063904 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 329.2633581161499s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69338387 loss Rayleigh: 0.69314322 loss Rician: 0.69292194   running time 11.825235605239868
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69317679 loss Rayleigh: 0.69297250 loss Rician: 0.69287971   running time 17.2109317779541
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328693 loss Rayleigh: 0.69314112 loss Rician: 0.69290499   running time 13.185232639312744
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69332463 loss Rayleigh: 0.69316632 loss Rician: 0.69288496   running time 11.93149995803833
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69326481 loss Rayleigh: 0.69312623 loss Rician: 0.69291730   running time 12.09784746170044
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69318393 loss Rayleigh: 0.69298824 loss Rician: 0.69266303   running time 11.903716564178467
====> Test set BCE loss with SNR 0.0 for AWGN 0.6922837495803833 Custom Loss 0.6922837495803833 with ber  0.4875500202178955 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931735277175903 Custom Loss 0.6931735277175903 with ber  0.4985833764076233 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.692366361618042 Custom Loss 0.692366361618042 with ber  0.4861833155155182 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 81.76348114013672s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69330678 loss Rayleigh: 0.69314038 loss Rician: 0.69309967   running time 11.758366107940674
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69322273 loss Rayleigh: 0.69310475 loss Rician: 0.69289414   running time 12.004693984985352
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69320523 loss Rayleigh: 0.69303170 loss Rician: 0.69265382   running time 11.839937925338745
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331979 loss Rayleigh: 0.69310565 loss Rician: 0.69294036   running time 11.955871105194092
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327887 loss Rayleigh: 0.69299038 loss Rician: 0.69274701   running time 12.238166332244873
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69335292 loss Rayleigh: 0.69324237 loss Rician: 0.69275018   running time 11.83712387084961
====> Test set BCE loss with SNR 0.0 for AWGN 0.6921035051345825 Custom Loss 0.6921035051345825 with ber  0.4809500277042389 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929833292961121 Custom Loss 0.6929833292961121 with ber  0.4950333535671234 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6924226880073547 Custom Loss 0.6924226880073547 with ber  0.482283353805542 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 75.21801662445068s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69325496 loss Rayleigh: 0.69303432 loss Rician: 0.69277658   running time 11.86324143409729
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69320384 loss Rayleigh: 0.69289613 loss Rician: 0.69273736   running time 12.043162822723389
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69323712 loss Rayleigh: 0.69300742 loss Rician: 0.69270510   running time 11.909374475479126
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335303 loss Rayleigh: 0.69317694 loss Rician: 0.69275504   running time 12.1994309425354
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339353 loss Rayleigh: 0.69312729 loss Rician: 0.69281110   running time 11.922430276870728
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69328761 loss Rayleigh: 0.69324880 loss Rician: 0.69306730   running time 11.984508752822876
====> Test set BCE loss with SNR 0.0 for AWGN 0.6926482915878296 Custom Loss 0.6926482915878296 with ber  0.4960666596889496 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933072805404663 Custom Loss 0.6933072805404663 with ber  0.49888333678245544 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931006908416748 Custom Loss 0.6931006908416748 with ber  0.4973999857902527 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 75.63254475593567s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330694 loss Rayleigh: 0.69318069 loss Rician: 0.69305165   running time 11.567737102508545
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325171 loss Rayleigh: 0.69300925 loss Rician: 0.69264963   running time 12.331414222717285
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69324808 loss Rayleigh: 0.69314446 loss Rician: 0.69270931   running time 11.79622507095337
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69339957 loss Rayleigh: 0.69302053 loss Rician: 0.69289576   running time 12.150366306304932
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330605 loss Rayleigh: 0.69295671 loss Rician: 0.69258397   running time 12.67104172706604
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69327445 loss Rayleigh: 0.69315242 loss Rician: 0.69279015   running time 11.919363260269165
====> Test set BCE loss with SNR 0.0 for AWGN 0.6923764944076538 Custom Loss 0.6923764944076538 with ber  0.4876999855041504 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929663419723511 Custom Loss 0.6929663419723511 with ber  0.49365001916885376 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6924718022346497 Custom Loss 0.6924718022346497 with ber  0.4859999716281891 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 75.93564653396606s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69320334 loss Rayleigh: 0.69312742 loss Rician: 0.69280498   running time 11.966589450836182
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331437 loss Rayleigh: 0.69308152 loss Rician: 0.69283403   running time 11.935176134109497
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69324514 loss Rayleigh: 0.69313128 loss Rician: 0.69250525   running time 11.789859056472778
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328859 loss Rayleigh: 0.69319641 loss Rician: 0.69270456   running time 12.116657257080078
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69315543 loss Rayleigh: 0.69302349 loss Rician: 0.69264158   running time 11.840977191925049
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69323785 loss Rayleigh: 0.69320295 loss Rician: 0.69271092   running time 12.501691579818726
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925305724143982 Custom Loss 0.6925305724143982 with ber  0.49461668729782104 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932984590530396 Custom Loss 0.6932984590530396 with ber  0.4989500045776367 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6927593946456909 Custom Loss 0.6927593946456909 with ber  0.4954667091369629 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 75.69065380096436s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5051167011260986 learn codes ber with rayleigh  0.5043833255767822 learn codes ber with rician  0.5023499727249146 ber with awgn  0.37658749999999996 ber with rayleigh  0.39686250000000006 ber with rician  0.39193749999999994
Test SNR 5 learn codes ber with awgn  0.4980500340461731 learn codes ber with rayleigh  0.4977167248725891 learn codes ber with rician  0.4943666458129883 ber with awgn  0.28765 ber with rayleigh  0.30477499999999996 ber with rician  0.2981
Test SNR 10 learn codes ber with awgn  0.5025999546051025 learn codes ber with rayleigh  0.5019832849502563 learn codes ber with rician  0.5001000165939331 ber with awgn  0.1579625 ber with rayleigh  0.18618749999999998 ber with rician  0.15895
Test SNR 15 learn codes ber with awgn  0.5005666613578796 learn codes ber with rayleigh  0.5008000135421753 learn codes ber with rician  0.49799999594688416 ber with awgn  0.0388375 ber with rayleigh  0.08522500000000002 ber with rician  0.05785
Test SNR 20 learn codes ber with awgn  0.4993000626564026 learn codes ber with rayleigh  0.49863332509994507 learn codes ber with rician  0.496183305978775 ber with awgn  0.0009000000000000001 ber with rayleigh  0.030575 ber with rician  0.01615
Test SNR 25 learn codes ber with awgn  0.4990333020687103 learn codes ber with rayleigh  0.4984167218208313 learn codes ber with rician  0.49629998207092285 ber with awgn  0.0 ber with rayleigh  0.011024999999999998 ber with rician  0.0048
Test SNR 30 learn codes ber with awgn  0.5022500157356262 learn codes ber with rayleigh  0.5020666718482971 learn codes ber with rician  0.5000333189964294 ber with awgn  0.0 ber with rayleigh  0.0033375 ber with rician  0.001225
Test SNR 35 learn codes ber with awgn  0.4992167055606842 learn codes ber with rayleigh  0.4985000193119049 learn codes ber with rician  0.4964166581630707 ber with awgn  0.0 ber with rayleigh  0.0010374999999999998 ber with rician  0.0005124999999999999
Test SNR 40 learn codes ber with awgn  0.5012166500091553 learn codes ber with rayleigh  0.5008000135421753 learn codes ber with rician  0.4991999566555023 ber with awgn  0.0 ber with rayleigh  0.0004 ber with rician  0.000125
Test SNR 45 learn codes ber with awgn  0.5005666613578796 learn codes ber with rayleigh  0.5002999901771545 learn codes ber with rician  0.4973166584968567 ber with awgn  0.0 ber with rayleigh  0.0001375 ber with rician  5e-05
Test SNR 50 learn codes ber with awgn  0.49916666746139526 learn codes ber with rayleigh  0.49868330359458923 learn codes ber with rician  0.4956333041191101 ber with awgn  0.0 ber with rayleigh  3.7500000000000003e-05 ber with rician  2.5e-05
Test SNR 55 learn codes ber with awgn  0.50041663646698 learn codes ber with rayleigh  0.499666690826416 learn codes ber with rician  0.4981667101383209 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5019166469573975 learn codes ber with rayleigh  0.5019000172615051 learn codes ber with rician  0.5003499984741211 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.49951666593551636 learn codes ber with rayleigh  0.4992000162601471 learn codes ber with rician  0.49631667137145996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5028833150863647 learn codes ber with rayleigh  0.5023499727249146 learn codes ber with rician  0.49966663122177124 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5016666650772095 learn codes ber with rayleigh  0.5019499659538269 learn codes ber with rician  0.49890002608299255 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49650001525878906 learn codes ber with rayleigh  0.49650001525878906 learn codes ber with rician  0.49443331360816956 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4984166622161865 learn codes ber with rayleigh  0.49781665205955505 learn codes ber with rician  0.495983362197876 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49904996156692505 learn codes ber with rayleigh  0.4987833499908447 learn codes ber with rician  0.4973166882991791 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49853330850601196 learn codes ber with rayleigh  0.49834999442100525 learn codes ber with rician  0.49633336067199707 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5051167011260986, 0.4980500340461731, 0.5025999546051025, 0.5005666613578796, 0.4993000626564026, 0.4990333020687103, 0.5022500157356262, 0.4992167055606842, 0.5012166500091553, 0.5005666613578796, 0.49916666746139526, 0.50041663646698, 0.5019166469573975, 0.49951666593551636, 0.5028833150863647, 0.5016666650772095, 0.49650001525878906, 0.4984166622161865, 0.49904996156692505, 0.49853330850601196]
Learn Codes rayleigh [0.5043833255767822, 0.4977167248725891, 0.5019832849502563, 0.5008000135421753, 0.49863332509994507, 0.4984167218208313, 0.5020666718482971, 0.4985000193119049, 0.5008000135421753, 0.5002999901771545, 0.49868330359458923, 0.499666690826416, 0.5019000172615051, 0.4992000162601471, 0.5023499727249146, 0.5019499659538269, 0.49650001525878906, 0.49781665205955505, 0.4987833499908447, 0.49834999442100525]
Learn Codes rician [0.5023499727249146, 0.4943666458129883, 0.5001000165939331, 0.49799999594688416, 0.496183305978775, 0.49629998207092285, 0.5000333189964294, 0.4964166581630707, 0.4991999566555023, 0.4973166584968567, 0.4956333041191101, 0.4981667101383209, 0.5003499984741211, 0.49631667137145996, 0.49966663122177124, 0.49890002608299255, 0.49443331360816956, 0.495983362197876, 0.4973166882991791, 0.49633336067199707]
AWGN [0.37658749999999996, 0.28765, 0.1579625, 0.0388375, 0.0009000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39686250000000006, 0.30477499999999996, 0.18618749999999998, 0.08522500000000002, 0.030575, 0.011024999999999998, 0.0033375, 0.0010374999999999998, 0.0004, 0.0001375, 3.7500000000000003e-05, 1.25e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39193749999999994, 0.2981, 0.15895, 0.05785, 0.01615, 0.0048, 0.001225, 0.0005124999999999999, 0.000125, 5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69318630 loss Rayleigh: 0.69318569 loss Rician: 0.69318556   running time 12.28272294998169
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.73123657 loss Rayleigh: 0.70535339 loss Rician: 0.72972322   running time 12.226449728012085
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.72676457 loss Rayleigh: 0.70979356 loss Rician: 0.71601735   running time 12.29690170288086
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70659641 loss Rayleigh: 0.70377470 loss Rician: 0.69981984   running time 12.299118757247925
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69548935 loss Rayleigh: 0.69534250 loss Rician: 0.69471453   running time 12.31135106086731
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69348426 loss Rayleigh: 0.69347433 loss Rician: 0.69327758   running time 12.378069400787354
====> Test set BCE loss with SNR 0.0 for AWGN 0.6927700042724609 Custom Loss 0.6927700042724609 with ber  0.4998833239078522 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934921741485596 Custom Loss 0.6934921741485596 with ber  0.49961668252944946 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931739449501038 Custom Loss 0.6931739449501038 with ber  0.4992833137512207 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 77.80661368370056s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69369063 loss Rayleigh: 0.69357699 loss Rician: 0.69345452   running time 12.209869146347046
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69345620 loss Rayleigh: 0.69330765 loss Rician: 0.69299707   running time 12.364303827285767
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328526 loss Rayleigh: 0.69314061 loss Rician: 0.69288331   running time 12.252262592315674
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69342936 loss Rayleigh: 0.69308148 loss Rician: 0.69275532   running time 12.508614301681519
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69347741 loss Rayleigh: 0.69321290 loss Rician: 0.69282860   running time 12.402798891067505
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69330471 loss Rayleigh: 0.69311853 loss Rician: 0.69266654   running time 12.351707696914673
====> Test set BCE loss with SNR 0.0 for AWGN 0.6907080411911011 Custom Loss 0.6907080411911011 with ber  0.47589999437332153 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929153203964233 Custom Loss 0.6929153203964233 with ber  0.49441665410995483 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6917134523391724 Custom Loss 0.6917134523391724 with ber  0.4812333583831787 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 77.95211744308472s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69334887 loss Rayleigh: 0.69314140 loss Rician: 0.69253703   running time 12.322858095169067
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325630 loss Rayleigh: 0.69293814 loss Rician: 0.69214309   running time 12.296347379684448
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69334679 loss Rayleigh: 0.69311710 loss Rician: 0.69210616   running time 12.650744438171387
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332485 loss Rayleigh: 0.69313828 loss Rician: 0.69210675   running time 12.300331592559814
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69329100 loss Rayleigh: 0.69304450 loss Rician: 0.69205414   running time 12.430428743362427
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333855 loss Rayleigh: 0.69309301 loss Rician: 0.69196225   running time 12.590119123458862
====> Test set BCE loss with SNR 0.0 for AWGN 0.6882225275039673 Custom Loss 0.6882225275039673 with ber  0.4490000307559967 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925823092460632 Custom Loss 0.6925823092460632 with ber  0.4879833161830902 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6906514167785645 Custom Loss 0.6906514167785645 with ber  0.46316665410995483 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.63720560073853s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69352801 loss Rayleigh: 0.69292280 loss Rician: 0.69189526   running time 12.394614696502686
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69334381 loss Rayleigh: 0.69293612 loss Rician: 0.69188237   running time 12.406550168991089
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69318893 loss Rayleigh: 0.69289984 loss Rician: 0.69194992   running time 12.41758131980896
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338732 loss Rayleigh: 0.69290565 loss Rician: 0.69172414   running time 12.335904598236084
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69326744 loss Rayleigh: 0.69299170 loss Rician: 0.69153306   running time 12.381070375442505
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330256 loss Rayleigh: 0.69306844 loss Rician: 0.69137864   running time 13.264090061187744
====> Test set BCE loss with SNR 0.0 for AWGN 0.6882889866828918 Custom Loss 0.6882889866828918 with ber  0.4640166759490967 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6925814747810364 Custom Loss 0.6925814747810364 with ber  0.4874333441257477 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6898413896560669 Custom Loss 0.6898413896560669 with ber  0.4605333209037781 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 79.28552532196045s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69340121 loss Rayleigh: 0.69298647 loss Rician: 0.69156825   running time 12.220697402954102
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69337444 loss Rayleigh: 0.69287971 loss Rician: 0.69182707   running time 12.520037412643433
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69337577 loss Rayleigh: 0.69292347 loss Rician: 0.69155431   running time 12.435547351837158
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319213 loss Rayleigh: 0.69286330 loss Rician: 0.69161832   running time 12.421063899993896
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69329790 loss Rayleigh: 0.69308172 loss Rician: 0.69167059   running time 12.342173099517822
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325922 loss Rayleigh: 0.69290189 loss Rician: 0.69184121   running time 12.48026728630066
====> Test set BCE loss with SNR 0.0 for AWGN 0.68751460313797 Custom Loss 0.68751460313797 with ber  0.4528833329677582 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929495334625244 Custom Loss 0.6929495334625244 with ber  0.4912499785423279 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6902488470077515 Custom Loss 0.6902488470077515 with ber  0.4652000069618225 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.33001971244812s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69342291 loss Rayleigh: 0.69329358 loss Rician: 0.69181610   running time 12.145762920379639
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69337263 loss Rayleigh: 0.69297243 loss Rician: 0.69151402   running time 12.616066694259644
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330122 loss Rayleigh: 0.69303269 loss Rician: 0.69154510   running time 12.531994104385376
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69329603 loss Rayleigh: 0.69293081 loss Rician: 0.69154433   running time 12.43582272529602
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69325750 loss Rayleigh: 0.69294279 loss Rician: 0.69132228   running time 12.3223876953125
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69322633 loss Rayleigh: 0.69282133 loss Rician: 0.69105168   running time 12.369393348693848
====> Test set BCE loss with SNR 0.0 for AWGN 0.6880537271499634 Custom Loss 0.6880537271499634 with ber  0.46826666593551636 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927881240844727 Custom Loss 0.6927881240844727 with ber  0.49078336358070374 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6896660327911377 Custom Loss 0.6896660327911377 with ber  0.46903330087661743 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.27714323997498s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69315150 loss Rayleigh: 0.69271033 loss Rician: 0.69151154   running time 12.236990213394165
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69320864 loss Rayleigh: 0.69282438 loss Rician: 0.69138408   running time 12.46375846862793
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340600 loss Rayleigh: 0.69305228 loss Rician: 0.69153359   running time 12.343166589736938
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69337773 loss Rayleigh: 0.69304410 loss Rician: 0.69176065   running time 12.276097774505615
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69338695 loss Rayleigh: 0.69293612 loss Rician: 0.69179245   running time 12.297763347625732
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69328934 loss Rayleigh: 0.69293468 loss Rician: 0.69128402   running time 12.361774682998657
====> Test set BCE loss with SNR 0.0 for AWGN 0.6877387762069702 Custom Loss 0.6877387762069702 with ber  0.45713335275650024 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692508339881897 Custom Loss 0.692508339881897 with ber  0.4875999987125397 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.689655065536499 Custom Loss 0.689655065536499 with ber  0.4651000499725342 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.00353980064392s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69317394 loss Rayleigh: 0.69274765 loss Rician: 0.69119388   running time 12.109790563583374
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335436 loss Rayleigh: 0.69324280 loss Rician: 0.69188101   running time 12.59099268913269
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69331632 loss Rayleigh: 0.69280632 loss Rician: 0.69140525   running time 12.432492971420288
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69321453 loss Rayleigh: 0.69279486 loss Rician: 0.69168326   running time 12.481237649917603
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69333093 loss Rayleigh: 0.69300203 loss Rician: 0.69169898   running time 12.259238243103027
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69327785 loss Rayleigh: 0.69289059 loss Rician: 0.69139836   running time 12.455389499664307
====> Test set BCE loss with SNR 0.0 for AWGN 0.6904667615890503 Custom Loss 0.6904667615890503 with ber  0.47126665711402893 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929889917373657 Custom Loss 0.6929889917373657 with ber  0.49123334884643555 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6896158456802368 Custom Loss 0.6896158456802368 with ber  0.4693833291530609 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.31247425079346s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330572 loss Rayleigh: 0.69303639 loss Rician: 0.69162840   running time 12.258749723434448
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325855 loss Rayleigh: 0.69297041 loss Rician: 0.69147176   running time 12.470273494720459
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322301 loss Rayleigh: 0.69263891 loss Rician: 0.69148920   running time 12.4799063205719
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69333087 loss Rayleigh: 0.69303199 loss Rician: 0.69145457   running time 12.405703783035278
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69326969 loss Rayleigh: 0.69297672 loss Rician: 0.69138134   running time 12.424237489700317
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69324031 loss Rayleigh: 0.69281658 loss Rician: 0.69148382   running time 12.244023561477661
====> Test set BCE loss with SNR 0.0 for AWGN 0.6872417330741882 Custom Loss 0.6872417330741882 with ber  0.4535333514213562 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927930116653442 Custom Loss 0.6927930116653442 with ber  0.4880499839782715 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6896206140518188 Custom Loss 0.6896206140518188 with ber  0.45910000801086426 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.36342263221741s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69333904 loss Rayleigh: 0.69313617 loss Rician: 0.69124926   running time 12.15651822090149
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337965 loss Rayleigh: 0.69278311 loss Rician: 0.69154320   running time 12.755071640014648
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335803 loss Rayleigh: 0.69295422 loss Rician: 0.69142200   running time 12.407073736190796
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69324971 loss Rayleigh: 0.69295180 loss Rician: 0.69163325   running time 12.392923831939697
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69331481 loss Rayleigh: 0.69271863 loss Rician: 0.69071760   running time 12.494455337524414
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69342031 loss Rayleigh: 0.69294019 loss Rician: 0.69132026   running time 12.364392518997192
====> Test set BCE loss with SNR 0.0 for AWGN 0.6886170506477356 Custom Loss 0.6886170506477356 with ber  0.4635166525840759 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929160356521606 Custom Loss 0.6929160356521606 with ber  0.4899999499320984 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6902758479118347 Custom Loss 0.6902758479118347 with ber  0.46381664276123047 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 78.60523772239685s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5014666318893433 learn codes ber with rayleigh  0.49026671051979065 learn codes ber with rician  0.47003331780433655 ber with awgn  0.4408875 ber with rayleigh  0.45512499999999995 ber with rician  0.45065
Test SNR 5 learn codes ber with awgn  0.49923333525657654 learn codes ber with rayleigh  0.49119997024536133 learn codes ber with rician  0.4737332761287689 ber with awgn  0.39141250000000005 ber with rayleigh  0.4125375 ber with rician  0.4063375000000001
Test SNR 10 learn codes ber with awgn  0.5004666447639465 learn codes ber with rayleigh  0.49131664633750916 learn codes ber with rician  0.4699666500091553 ber with awgn  0.3127375 ber with rayleigh  0.3332 ber with rician  0.3229625
Test SNR 15 learn codes ber with awgn  0.5010333061218262 learn codes ber with rayleigh  0.4943000376224518 learn codes ber with rician  0.4699833393096924 ber with awgn  0.192725 ber with rayleigh  0.21651250000000002 ber with rician  0.1938
Test SNR 20 learn codes ber with awgn  0.4991333484649658 learn codes ber with rayleigh  0.4924499988555908 learn codes ber with rician  0.47086668014526367 ber with awgn  0.06228750000000001 ber with rayleigh  0.10523750000000001 ber with rician  0.0752875
Test SNR 25 learn codes ber with awgn  0.496966689825058 learn codes ber with rayleigh  0.4881667196750641 learn codes ber with rician  0.4702666699886322 ber with awgn  0.0029625000000000003 ber with rayleigh  0.040350000000000004 ber with rician  0.021625
Test SNR 30 learn codes ber with awgn  0.49853333830833435 learn codes ber with rayleigh  0.4917833209037781 learn codes ber with rician  0.47049999237060547 ber with awgn  0.0 ber with rayleigh  0.0136875 ber with rician  0.006412499999999999
Test SNR 35 learn codes ber with awgn  0.49773329496383667 learn codes ber with rayleigh  0.4878666400909424 learn codes ber with rician  0.4678833484649658 ber with awgn  0.0 ber with rayleigh  0.0043 ber with rician  0.0015
Test SNR 40 learn codes ber with awgn  0.49764999747276306 learn codes ber with rayleigh  0.4906499981880188 learn codes ber with rician  0.4697500169277191 ber with awgn  0.0 ber with rayleigh  0.0011375 ber with rician  0.0006375
Test SNR 45 learn codes ber with awgn  0.4999333322048187 learn codes ber with rayleigh  0.4928832948207855 learn codes ber with rician  0.47091665863990784 ber with awgn  0.0 ber with rayleigh  0.0003375 ber with rician  0.0001375
Test SNR 50 learn codes ber with awgn  0.498683363199234 learn codes ber with rayleigh  0.49036669731140137 learn codes ber with rician  0.4728166460990906 ber with awgn  0.0 ber with rayleigh  0.00017499999999999997 ber with rician  8.75e-05
Test SNR 55 learn codes ber with awgn  0.5014833211898804 learn codes ber with rayleigh  0.49236664175987244 learn codes ber with rician  0.4706665873527527 ber with awgn  0.0 ber with rayleigh  6.25e-05 ber with rician  1.25e-05
Test SNR 60 learn codes ber with awgn  0.500083327293396 learn codes ber with rayleigh  0.49061664938926697 learn codes ber with rician  0.4714999794960022 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5036333203315735 learn codes ber with rayleigh  0.4953332841396332 learn codes ber with rician  0.4749666154384613 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5020666718482971 learn codes ber with rayleigh  0.49213331937789917 learn codes ber with rician  0.4708166718482971 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.500583291053772 learn codes ber with rayleigh  0.4905166029930115 learn codes ber with rician  0.4713166356086731 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5009833574295044 learn codes ber with rayleigh  0.49369996786117554 learn codes ber with rician  0.47101664543151855 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4999333322048187 learn codes ber with rayleigh  0.4910999834537506 learn codes ber with rician  0.4715999960899353 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5013166666030884 learn codes ber with rayleigh  0.4911666810512543 learn codes ber with rician  0.4744666516780853 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49880003929138184 learn codes ber with rayleigh  0.4904666841030121 learn codes ber with rician  0.4727500081062317 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5014666318893433, 0.49923333525657654, 0.5004666447639465, 0.5010333061218262, 0.4991333484649658, 0.496966689825058, 0.49853333830833435, 0.49773329496383667, 0.49764999747276306, 0.4999333322048187, 0.498683363199234, 0.5014833211898804, 0.500083327293396, 0.5036333203315735, 0.5020666718482971, 0.500583291053772, 0.5009833574295044, 0.4999333322048187, 0.5013166666030884, 0.49880003929138184]
Learn Codes rayleigh [0.49026671051979065, 0.49119997024536133, 0.49131664633750916, 0.4943000376224518, 0.4924499988555908, 0.4881667196750641, 0.4917833209037781, 0.4878666400909424, 0.4906499981880188, 0.4928832948207855, 0.49036669731140137, 0.49236664175987244, 0.49061664938926697, 0.4953332841396332, 0.49213331937789917, 0.4905166029930115, 0.49369996786117554, 0.4910999834537506, 0.4911666810512543, 0.4904666841030121]
Learn Codes rician [0.47003331780433655, 0.4737332761287689, 0.4699666500091553, 0.4699833393096924, 0.47086668014526367, 0.4702666699886322, 0.47049999237060547, 0.4678833484649658, 0.4697500169277191, 0.47091665863990784, 0.4728166460990906, 0.4706665873527527, 0.4714999794960022, 0.4749666154384613, 0.4708166718482971, 0.4713166356086731, 0.47101664543151855, 0.4715999960899353, 0.4744666516780853, 0.4727500081062317]
AWGN [0.4408875, 0.39141250000000005, 0.3127375, 0.192725, 0.06228750000000001, 0.0029625000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45512499999999995, 0.4125375, 0.3332, 0.21651250000000002, 0.10523750000000001, 0.040350000000000004, 0.0136875, 0.0043, 0.0011375, 0.0003375, 0.00017499999999999997, 6.25e-05, 1.25e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45065, 0.4063375000000001, 0.3229625, 0.1938, 0.0752875, 0.021625, 0.006412499999999999, 0.0015, 0.0006375, 0.0001375, 8.75e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69329685 loss Rayleigh: 0.69329025 loss Rician: 0.69329265   running time 12.39349913597107
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70393156 loss Rayleigh: 0.70002938 loss Rician: 0.70756669   running time 12.316112756729126
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70223336 loss Rayleigh: 0.69742672 loss Rician: 0.70092292   running time 12.607147693634033
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69716383 loss Rayleigh: 0.69703682 loss Rician: 0.69618898   running time 12.407248973846436
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69415807 loss Rayleigh: 0.69418156 loss Rician: 0.69386375   running time 12.558070182800293
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69339759 loss Rayleigh: 0.69341691 loss Rician: 0.69339314   running time 12.352665901184082
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933725476264954 Custom Loss 0.6933725476264954 with ber  0.49921998381614685 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693318784236908 Custom Loss 0.693318784236908 with ber  0.49908003211021423 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933330297470093 Custom Loss 0.6933330297470093 with ber  0.4987899661064148 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 78.4042329788208s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324718 loss Rayleigh: 0.69324907 loss Rician: 0.69324946   running time 11.977192163467407
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69338734 loss Rayleigh: 0.69338149 loss Rician: 0.69332423   running time 12.296634435653687
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331973 loss Rayleigh: 0.69331453 loss Rician: 0.69328334   running time 12.078033924102783
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69325941 loss Rayleigh: 0.69325424 loss Rician: 0.69322839   running time 12.269707441329956
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69323796 loss Rayleigh: 0.69324103 loss Rician: 0.69321957   running time 12.147542238235474
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69329427 loss Rayleigh: 0.69327972 loss Rician: 0.69324159   running time 12.27637529373169
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931670904159546 Custom Loss 0.6931670904159546 with ber  0.497810035943985 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931847333908081 Custom Loss 0.6931847333908081 with ber  0.4976300299167633 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931856870651245 Custom Loss 0.6931856870651245 with ber  0.4978399872779846 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.73769044876099s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69325098 loss Rayleigh: 0.69324316 loss Rician: 0.69323269   running time 12.178572177886963
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324896 loss Rayleigh: 0.69323243 loss Rician: 0.69320004   running time 12.079962253570557
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69328275 loss Rayleigh: 0.69327112 loss Rician: 0.69323451   running time 12.265837907791138
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69324561 loss Rayleigh: 0.69322808 loss Rician: 0.69319499   running time 12.201108455657959
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69322309 loss Rayleigh: 0.69322311 loss Rician: 0.69319469   running time 12.29250454902649
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69319690 loss Rayleigh: 0.69318243 loss Rician: 0.69315464   running time 12.551664113998413
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931977868080139 Custom Loss 0.6931977868080139 with ber  0.49966001510620117 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6932265162467957 Custom Loss 0.6932265162467957 with ber  0.5001099705696106 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932232975959778 Custom Loss 0.6932232975959778 with ber  0.49991002678871155 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.5637526512146s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69320738 loss Rayleigh: 0.69320461 loss Rician: 0.69319580   running time 12.444405555725098
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321275 loss Rayleigh: 0.69319977 loss Rician: 0.69316751   running time 12.762603282928467
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329062 loss Rayleigh: 0.69327409 loss Rician: 0.69321749   running time 12.701658248901367
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329364 loss Rayleigh: 0.69329005 loss Rician: 0.69323827   running time 12.653038501739502
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330444 loss Rayleigh: 0.69328768 loss Rician: 0.69322957   running time 12.712847709655762
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321895 loss Rayleigh: 0.69321942 loss Rician: 0.69318220   running time 12.352493286132812
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934382319450378 Custom Loss 0.6934382319450378 with ber  0.5011900067329407 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934850215911865 Custom Loss 0.6934850215911865 with ber  0.5011800527572632 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934779286384583 Custom Loss 0.6934779286384583 with ber  0.5011999607086182 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 79.44415378570557s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69370022 loss Rayleigh: 0.69369075 loss Rician: 0.69367599   running time 12.004154443740845
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330954 loss Rayleigh: 0.69330299 loss Rician: 0.69326661   running time 12.266135931015015
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69320447 loss Rayleigh: 0.69320928 loss Rician: 0.69318228   running time 12.110227346420288
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325402 loss Rayleigh: 0.69323921 loss Rician: 0.69320170   running time 12.260479211807251
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69321849 loss Rayleigh: 0.69321923 loss Rician: 0.69318786   running time 12.21241021156311
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69319153 loss Rayleigh: 0.69318109 loss Rician: 0.69314818   running time 12.149644613265991
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931189298629761 Custom Loss 0.6931189298629761 with ber  0.4992000162601471 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693160891532898 Custom Loss 0.693160891532898 with ber  0.4996799826622009 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931506991386414 Custom Loss 0.6931506991386414 with ber  0.49915003776550293 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.79580903053284s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69316980 loss Rayleigh: 0.69316239 loss Rician: 0.69314122   running time 12.172748565673828
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328222 loss Rayleigh: 0.69326363 loss Rician: 0.69322187   running time 12.208984851837158
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69325334 loss Rayleigh: 0.69324584 loss Rician: 0.69320658   running time 12.106045246124268
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69318895 loss Rayleigh: 0.69318094 loss Rician: 0.69314955   running time 12.423024892807007
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69322071 loss Rayleigh: 0.69320829 loss Rician: 0.69315293   running time 12.115451097488403
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69323424 loss Rayleigh: 0.69321376 loss Rician: 0.69314415   running time 15.11375093460083
====> Test set BCE loss with SNR 0.0 for AWGN 0.6934465169906616 Custom Loss 0.6934465169906616 with ber  0.5017399191856384 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6934919357299805 Custom Loss 0.6934919357299805 with ber  0.5017799139022827 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6934860348701477 Custom Loss 0.6934860348701477 with ber  0.5016499757766724 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 80.28204846382141s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69354427 loss Rayleigh: 0.69353665 loss Rician: 0.69350582   running time 12.324968576431274
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69332991 loss Rayleigh: 0.69330650 loss Rician: 0.69323689   running time 12.511280059814453
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69321969 loss Rayleigh: 0.69320109 loss Rician: 0.69312651   running time 12.488497018814087
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69322149 loss Rayleigh: 0.69321055 loss Rician: 0.69303771   running time 12.431509494781494
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331026 loss Rayleigh: 0.69327378 loss Rician: 0.69305822   running time 12.574047088623047
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69331580 loss Rayleigh: 0.69326726 loss Rician: 0.69299809   running time 12.469843864440918
====> Test set BCE loss with SNR 0.0 for AWGN 0.6929086446762085 Custom Loss 0.6929086446762085 with ber  0.49574002623558044 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931878924369812 Custom Loss 0.6931878924369812 with ber  0.49838003516197205 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931182742118835 Custom Loss 0.6931182742118835 with ber  0.4990900158882141 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 78.74223113059998s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69317126 loss Rayleigh: 0.69313138 loss Rician: 0.69300987   running time 12.33644986152649
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69325116 loss Rayleigh: 0.69322525 loss Rician: 0.69300256   running time 12.502382755279541
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330553 loss Rayleigh: 0.69329106 loss Rician: 0.69288756   running time 12.166945219039917
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69321269 loss Rayleigh: 0.69315250 loss Rician: 0.69287384   running time 12.332649230957031
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330497 loss Rayleigh: 0.69329070 loss Rician: 0.69290990   running time 12.214089393615723
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69330441 loss Rayleigh: 0.69324237 loss Rician: 0.69292064   running time 12.257047891616821
====> Test set BCE loss with SNR 0.0 for AWGN 0.6925625205039978 Custom Loss 0.6925625205039978 with ber  0.4857200086116791 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930984854698181 Custom Loss 0.6930984854698181 with ber  0.4966999888420105 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.69302898645401 Custom Loss 0.69302898645401 with ber  0.4957500100135803 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.45515847206116s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69322930 loss Rayleigh: 0.69321800 loss Rician: 0.69284744   running time 12.227895021438599
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69323551 loss Rayleigh: 0.69323341 loss Rician: 0.69286390   running time 12.168907403945923
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69332342 loss Rayleigh: 0.69332212 loss Rician: 0.69306123   running time 12.418877124786377
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69324162 loss Rayleigh: 0.69322328 loss Rician: 0.69303810   running time 12.103132009506226
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69324877 loss Rayleigh: 0.69322224 loss Rician: 0.69283474   running time 12.308054447174072
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336267 loss Rayleigh: 0.69340478 loss Rician: 0.69297870   running time 12.205783367156982
====> Test set BCE loss with SNR 0.0 for AWGN 0.6928245425224304 Custom Loss 0.6928245425224304 with ber  0.4923200011253357 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931902170181274 Custom Loss 0.6931902170181274 with ber  0.4969300329685211 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6931717991828918 Custom Loss 0.6931717991828918 with ber  0.4954899847507477 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.19382119178772s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69337475 loss Rayleigh: 0.69339214 loss Rician: 0.69321465   running time 11.942585706710815
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335638 loss Rayleigh: 0.69327961 loss Rician: 0.69300594   running time 12.255466222763062
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334373 loss Rayleigh: 0.69333817 loss Rician: 0.69317729   running time 12.177554607391357
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69359558 loss Rayleigh: 0.69372275 loss Rician: 0.69329775   running time 12.420268774032593
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69344190 loss Rayleigh: 0.69345330 loss Rician: 0.69322341   running time 12.13844084739685
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69358215 loss Rayleigh: 0.69350495 loss Rician: 0.69312211   running time 12.316571712493896
====> Test set BCE loss with SNR 0.0 for AWGN 0.6933239698410034 Custom Loss 0.6933239698410034 with ber  0.4989200234413147 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6935219168663025 Custom Loss 0.6935219168663025 with ber  0.4979400038719177 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935153007507324 Custom Loss 0.6935153007507324 with ber  0.498259961605072 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.95729494094849s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5005699396133423 learn codes ber with rayleigh  0.5003799796104431 learn codes ber with rician  0.4997600018978119 ber with awgn  0.3742583333333333 ber with rayleigh  0.3976166666666666 ber with rician  0.39025833333333326
Test SNR 5 learn codes ber with awgn  0.5015000104904175 learn codes ber with rayleigh  0.5012499690055847 learn codes ber with rician  0.5012699961662292 ber with awgn  0.287225 ber with rayleigh  0.3079166666666667 ber with rician  0.2897666666666666
Test SNR 10 learn codes ber with awgn  0.5005300045013428 learn codes ber with rayleigh  0.49980002641677856 learn codes ber with rician  0.49977001547813416 ber with awgn  0.15711666666666668 ber with rayleigh  0.18469999999999998 ber with rician  0.1484
Test SNR 15 learn codes ber with awgn  0.49966007471084595 learn codes ber with rayleigh  0.49956995248794556 learn codes ber with rician  0.4992700219154358 ber with awgn  0.0374 ber with rayleigh  0.08188333333333334 ber with rician  0.045083333333333336
Test SNR 20 learn codes ber with awgn  0.4996200203895569 learn codes ber with rayleigh  0.49914002418518066 learn codes ber with rician  0.49848002195358276 ber with awgn  0.0007416666666666667 ber with rayleigh  0.030174999999999997 ber with rician  0.009016666666666668
Test SNR 25 learn codes ber with awgn  0.4995400011539459 learn codes ber with rayleigh  0.49869996309280396 learn codes ber with rician  0.4997599720954895 ber with awgn  0.0 ber with rayleigh  0.01055 ber with rician  0.002025
Test SNR 30 learn codes ber with awgn  0.4986000061035156 learn codes ber with rayleigh  0.49754995107650757 learn codes ber with rician  0.49724000692367554 ber with awgn  0.0 ber with rayleigh  0.0030583333333333335 ber with rician  0.0005666666666666666
Test SNR 35 learn codes ber with awgn  0.5005499720573425 learn codes ber with rayleigh  0.4996599555015564 learn codes ber with rician  0.4995099902153015 ber with awgn  0.0 ber with rayleigh  0.0010916666666666666 ber with rician  0.00011666666666666665
Test SNR 40 learn codes ber with awgn  0.5020899772644043 learn codes ber with rayleigh  0.5022000074386597 learn codes ber with rician  0.5010899901390076 ber with awgn  0.0 ber with rayleigh  0.00039166666666666663 ber with rician  5.833333333333334e-05
Test SNR 45 learn codes ber with awgn  0.5001400113105774 learn codes ber with rayleigh  0.4997600018978119 learn codes ber with rician  0.49914997816085815 ber with awgn  0.0 ber with rayleigh  0.0001 ber with rician  2.5e-05
Test SNR 50 learn codes ber with awgn  0.5022700428962708 learn codes ber with rayleigh  0.5010000467300415 learn codes ber with rician  0.501520037651062 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  8.333333333333334e-06
Test SNR 55 learn codes ber with awgn  0.5009700059890747 learn codes ber with rayleigh  0.5012200474739075 learn codes ber with rician  0.5003799200057983 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49866002798080444 learn codes ber with rayleigh  0.4993899464607239 learn codes ber with rician  0.49821001291275024 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5005300045013428 learn codes ber with rayleigh  0.5004900097846985 learn codes ber with rician  0.5001699924468994 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.499610036611557 learn codes ber with rayleigh  0.49876999855041504 learn codes ber with rician  0.4988199770450592 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5027999877929688 learn codes ber with rayleigh  0.5026500225067139 learn codes ber with rician  0.5024099946022034 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49647003412246704 learn codes ber with rayleigh  0.49570003151893616 learn codes ber with rician  0.49618998169898987 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4971500039100647 learn codes ber with rayleigh  0.4964599609375 learn codes ber with rician  0.49618998169898987 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49997997283935547 learn codes ber with rayleigh  0.5000500082969666 learn codes ber with rician  0.49886003136634827 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49907001852989197 learn codes ber with rayleigh  0.4986499845981598 learn codes ber with rician  0.4984799921512604 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5005699396133423, 0.5015000104904175, 0.5005300045013428, 0.49966007471084595, 0.4996200203895569, 0.4995400011539459, 0.4986000061035156, 0.5005499720573425, 0.5020899772644043, 0.5001400113105774, 0.5022700428962708, 0.5009700059890747, 0.49866002798080444, 0.5005300045013428, 0.499610036611557, 0.5027999877929688, 0.49647003412246704, 0.4971500039100647, 0.49997997283935547, 0.49907001852989197]
Learn Codes rayleigh [0.5003799796104431, 0.5012499690055847, 0.49980002641677856, 0.49956995248794556, 0.49914002418518066, 0.49869996309280396, 0.49754995107650757, 0.4996599555015564, 0.5022000074386597, 0.4997600018978119, 0.5010000467300415, 0.5012200474739075, 0.4993899464607239, 0.5004900097846985, 0.49876999855041504, 0.5026500225067139, 0.49570003151893616, 0.4964599609375, 0.5000500082969666, 0.4986499845981598]
Learn Codes rician [0.4997600018978119, 0.5012699961662292, 0.49977001547813416, 0.4992700219154358, 0.49848002195358276, 0.4997599720954895, 0.49724000692367554, 0.4995099902153015, 0.5010899901390076, 0.49914997816085815, 0.501520037651062, 0.5003799200057983, 0.49821001291275024, 0.5001699924468994, 0.4988199770450592, 0.5024099946022034, 0.49618998169898987, 0.49618998169898987, 0.49886003136634827, 0.4984799921512604]
AWGN [0.3742583333333333, 0.287225, 0.15711666666666668, 0.0374, 0.0007416666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3976166666666666, 0.3079166666666667, 0.18469999999999998, 0.08188333333333334, 0.030174999999999997, 0.01055, 0.0030583333333333335, 0.0010916666666666666, 0.00039166666666666663, 0.0001, 2.5e-05, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39025833333333326, 0.2897666666666666, 0.1484, 0.045083333333333336, 0.009016666666666668, 0.002025, 0.0005666666666666666, 0.00011666666666666665, 5.833333333333334e-05, 2.5e-05, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69363579 loss Rayleigh: 0.69363834 loss Rician: 0.69364164   running time 12.469664096832275
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71273162 loss Rayleigh: 0.70987527 loss Rician: 0.71162241   running time 12.808969736099243
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.72483526 loss Rayleigh: 0.70646505 loss Rician: 0.71353070   running time 12.602731227874756
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70528434 loss Rayleigh: 0.70158120 loss Rician: 0.70006896   running time 12.736583948135376
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69588176 loss Rayleigh: 0.69638184 loss Rician: 0.69539401   running time 12.6389479637146
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69377760 loss Rayleigh: 0.69372785 loss Rician: 0.69358587   running time 12.664115190505981
====> Test set BCE loss with SNR 0.0 for AWGN 0.6931704878807068 Custom Loss 0.6931704878807068 with ber  0.4978099763393402 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933935880661011 Custom Loss 0.6933935880661011 with ber  0.49903997778892517 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6932953000068665 Custom Loss 0.6932953000068665 with ber  0.4991599917411804 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.15684533119202s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328411 loss Rayleigh: 0.69326269 loss Rician: 0.69322044   running time 12.562561511993408
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331217 loss Rayleigh: 0.69326164 loss Rician: 0.69320155   running time 12.676226377487183
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328649 loss Rayleigh: 0.69326326 loss Rician: 0.69316602   running time 12.747631072998047
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69326057 loss Rayleigh: 0.69319484 loss Rician: 0.69307642   running time 12.562831163406372
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69334794 loss Rayleigh: 0.69325504 loss Rician: 0.69305419   running time 12.81028938293457
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69337115 loss Rayleigh: 0.69320669 loss Rician: 0.69287449   running time 12.576619148254395
====> Test set BCE loss with SNR 0.0 for AWGN 0.6917197108268738 Custom Loss 0.6917197108268738 with ber  0.47877001762390137 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930186748504639 Custom Loss 0.6930186748504639 with ber  0.49865999817848206 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6923681497573853 Custom Loss 0.6923681497573853 with ber  0.4874899983406067 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.15857601165771s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330301 loss Rayleigh: 0.69322870 loss Rician: 0.69278145   running time 12.551347255706787
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69331558 loss Rayleigh: 0.69313480 loss Rician: 0.69278148   running time 12.71622633934021
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332600 loss Rayleigh: 0.69308411 loss Rician: 0.69248540   running time 13.37101936340332
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69344122 loss Rayleigh: 0.69317451 loss Rician: 0.69235734   running time 12.61435866355896
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323685 loss Rayleigh: 0.69299004 loss Rician: 0.69227810   running time 12.827750444412231
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332706 loss Rayleigh: 0.69293211 loss Rician: 0.69188327   running time 12.523176670074463
====> Test set BCE loss with SNR 0.0 for AWGN 0.6889950037002563 Custom Loss 0.6889950037002563 with ber  0.4663199782371521 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692660927772522 Custom Loss 0.692660927772522 with ber  0.4915199875831604 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6903387904167175 Custom Loss 0.6903387904167175 with ber  0.46942001581192017 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.79647493362427s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69319704 loss Rayleigh: 0.69306794 loss Rician: 0.69145426   running time 12.489844799041748
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69338387 loss Rayleigh: 0.69304153 loss Rician: 0.69151088   running time 12.658598899841309
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69327477 loss Rayleigh: 0.69295222 loss Rician: 0.69176842   running time 12.846033811569214
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69332704 loss Rayleigh: 0.69299527 loss Rician: 0.69153972   running time 12.485419988632202
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69330742 loss Rayleigh: 0.69292485 loss Rician: 0.69119331   running time 12.768158674240112
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69321834 loss Rayleigh: 0.69279314 loss Rician: 0.69167634   running time 12.596524477005005
====> Test set BCE loss with SNR 0.0 for AWGN 0.6864708662033081 Custom Loss 0.6864708662033081 with ber  0.4543600082397461 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928406953811646 Custom Loss 0.6928406953811646 with ber  0.48997002840042114 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.688778281211853 Custom Loss 0.688778281211853 with ber  0.4642000198364258 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.109295129776s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69329445 loss Rayleigh: 0.69305301 loss Rician: 0.69081531   running time 12.653564929962158
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69339508 loss Rayleigh: 0.69288738 loss Rician: 0.69110168   running time 12.551109313964844
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69322972 loss Rayleigh: 0.69296556 loss Rician: 0.69102468   running time 12.700879573822021
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69341427 loss Rayleigh: 0.69302319 loss Rician: 0.69165081   running time 12.426095724105835
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332471 loss Rayleigh: 0.69280928 loss Rician: 0.69116846   running time 12.712082386016846
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69330466 loss Rayleigh: 0.69283730 loss Rician: 0.69107978   running time 12.646963119506836
====> Test set BCE loss with SNR 0.0 for AWGN 0.6888071894645691 Custom Loss 0.6888071894645691 with ber  0.4802300035953522 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929919123649597 Custom Loss 0.6929919123649597 with ber  0.4946099817752838 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.689440131187439 Custom Loss 0.689440131187439 with ber  0.48211002349853516 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 79.93067717552185s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69341243 loss Rayleigh: 0.69321433 loss Rician: 0.69170758   running time 12.522815942764282
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69326006 loss Rayleigh: 0.69272234 loss Rician: 0.69088348   running time 12.556622505187988
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69332209 loss Rayleigh: 0.69296669 loss Rician: 0.69123089   running time 12.868887901306152
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69319940 loss Rayleigh: 0.69268944 loss Rician: 0.69030183   running time 12.48036789894104
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69329154 loss Rayleigh: 0.69284886 loss Rician: 0.69107455   running time 12.778093099594116
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333824 loss Rayleigh: 0.69281114 loss Rician: 0.69057342   running time 12.641334295272827
====> Test set BCE loss with SNR 0.0 for AWGN 0.6888420581817627 Custom Loss 0.6888420581817627 with ber  0.47067004442214966 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926143765449524 Custom Loss 0.6926143765449524 with ber  0.4891200065612793 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6877085566520691 Custom Loss 0.6877085566520691 with ber  0.46504998207092285 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.05989265441895s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69319258 loss Rayleigh: 0.69298567 loss Rician: 0.69079522   running time 12.711050987243652
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329253 loss Rayleigh: 0.69246521 loss Rician: 0.69053650   running time 12.557120561599731
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329284 loss Rayleigh: 0.69295211 loss Rician: 0.69066710   running time 12.79198431968689
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69317917 loss Rayleigh: 0.69270597 loss Rician: 0.69018467   running time 12.640398263931274
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69337947 loss Rayleigh: 0.69288468 loss Rician: 0.69031747   running time 12.815563440322876
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329873 loss Rayleigh: 0.69283645 loss Rician: 0.69042696   running time 12.820940017700195
====> Test set BCE loss with SNR 0.0 for AWGN 0.6902095079421997 Custom Loss 0.6902095079421997 with ber  0.48030000925064087 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6923902034759521 Custom Loss 0.6923902034759521 with ber  0.48634999990463257 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6883760690689087 Custom Loss 0.6883760690689087 with ber  0.46557003259658813 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.44191265106201s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69331633 loss Rayleigh: 0.69279166 loss Rician: 0.69105883   running time 12.486875295639038
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69326605 loss Rayleigh: 0.69295042 loss Rician: 0.69065965   running time 12.514147281646729
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69328936 loss Rayleigh: 0.69271016 loss Rician: 0.69063982   running time 12.848968267440796
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335295 loss Rayleigh: 0.69283786 loss Rician: 0.69048312   running time 12.485492944717407
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335003 loss Rayleigh: 0.69280212 loss Rician: 0.69034307   running time 12.804619789123535
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69319339 loss Rayleigh: 0.69291788 loss Rician: 0.69048318   running time 12.59182858467102
====> Test set BCE loss with SNR 0.0 for AWGN 0.690324068069458 Custom Loss 0.690324068069458 with ber  0.48372000455856323 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929839253425598 Custom Loss 0.6929839253425598 with ber  0.4912000298500061 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6886495351791382 Custom Loss 0.6886495351791382 with ber  0.46672001481056213 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 79.82022190093994s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69355289 loss Rayleigh: 0.69291916 loss Rician: 0.69078947   running time 12.587167739868164
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69340438 loss Rayleigh: 0.69296637 loss Rician: 0.69037971   running time 12.617748260498047
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69325030 loss Rayleigh: 0.69295037 loss Rician: 0.69059070   running time 12.885433197021484
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329846 loss Rayleigh: 0.69275078 loss Rician: 0.69005340   running time 12.522525548934937
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330632 loss Rayleigh: 0.69295980 loss Rician: 0.69021579   running time 12.836993932723999
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69337360 loss Rayleigh: 0.69315972 loss Rician: 0.69059322   running time 12.730790853500366
====> Test set BCE loss with SNR 0.0 for AWGN 0.6954694390296936 Custom Loss 0.6954694390296936 with ber  0.4857400059700012 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6924794912338257 Custom Loss 0.6924794912338257 with ber  0.4867900013923645 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6880460977554321 Custom Loss 0.6880460977554321 with ber  0.4613800048828125 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.25614666938782s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69318795 loss Rayleigh: 0.69273725 loss Rician: 0.69037042   running time 12.749066591262817
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69325020 loss Rayleigh: 0.69271913 loss Rician: 0.69051590   running time 12.568561315536499
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328978 loss Rayleigh: 0.69274716 loss Rician: 0.69023431   running time 12.819496154785156
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336320 loss Rayleigh: 0.69277713 loss Rician: 0.69023839   running time 12.631923198699951
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69330976 loss Rayleigh: 0.69289101 loss Rician: 0.69044383   running time 12.679807186126709
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334800 loss Rayleigh: 0.69270527 loss Rician: 0.69024851   running time 12.901198625564575
====> Test set BCE loss with SNR 0.0 for AWGN 0.6885655522346497 Custom Loss 0.6885655522346497 with ber  0.4758000373840332 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927273869514465 Custom Loss 0.6927273869514465 with ber  0.48784002661705017 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6877724528312683 Custom Loss 0.6877724528312683 with ber  0.46230000257492065 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.46410322189331s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49891000986099243 learn codes ber with rayleigh  0.49004998803138733 learn codes ber with rician  0.47484999895095825 ber with awgn  0.43524166666666664 ber with rayleigh  0.45362500000000006 ber with rician  0.45243333333333335
Test SNR 5 learn codes ber with awgn  0.4982300400733948 learn codes ber with rayleigh  0.49031996726989746 learn codes ber with rician  0.4718700051307678 ber with awgn  0.38906666666666667 ber with rayleigh  0.4125916666666667 ber with rician  0.40388333333333337
Test SNR 10 learn codes ber with awgn  0.5006500482559204 learn codes ber with rayleigh  0.49334001541137695 learn codes ber with rician  0.4709300100803375 ber with awgn  0.31653333333333333 ber with rayleigh  0.33266666666666667 ber with rician  0.3220833333333334
Test SNR 15 learn codes ber with awgn  0.49935001134872437 learn codes ber with rayleigh  0.49184998869895935 learn codes ber with rician  0.4699699878692627 ber with awgn  0.19306666666666666 ber with rayleigh  0.21534166666666663 ber with rician  0.18337499999999998
Test SNR 20 learn codes ber with awgn  0.501240074634552 learn codes ber with rayleigh  0.4943699836730957 learn codes ber with rician  0.471780002117157 ber with awgn  0.061125 ber with rayleigh  0.10322499999999998 ber with rician  0.06286666666666667
Test SNR 25 learn codes ber with awgn  0.500249981880188 learn codes ber with rayleigh  0.4938700199127197 learn codes ber with rician  0.4692699909210205 ber with awgn  0.0032916666666666663 ber with rayleigh  0.03986666666666666 ber with rician  0.014141666666666667
Test SNR 30 learn codes ber with awgn  0.4977499842643738 learn codes ber with rayleigh  0.4918399751186371 learn codes ber with rician  0.4694799780845642 ber with awgn  0.0 ber with rayleigh  0.01308333333333333 ber with rician  0.0030583333333333335
Test SNR 35 learn codes ber with awgn  0.4996799826622009 learn codes ber with rayleigh  0.49421006441116333 learn codes ber with rician  0.47134003043174744 ber with awgn  0.0 ber with rayleigh  0.004191666666666667 ber with rician  0.0009
Test SNR 40 learn codes ber with awgn  0.5026300549507141 learn codes ber with rayleigh  0.49639996886253357 learn codes ber with rician  0.4717300534248352 ber with awgn  0.0 ber with rayleigh  0.00135 ber with rician  0.0002
Test SNR 45 learn codes ber with awgn  0.4983600080013275 learn codes ber with rayleigh  0.4925200343132019 learn codes ber with rician  0.46768999099731445 ber with awgn  0.0 ber with rayleigh  0.0004333333333333333 ber with rician  0.0001
Test SNR 50 learn codes ber with awgn  0.5016700029373169 learn codes ber with rayleigh  0.49406999349594116 learn codes ber with rician  0.47117000818252563 ber with awgn  0.0 ber with rayleigh  0.000175 ber with rician  1.6666666666666667e-05
Test SNR 55 learn codes ber with awgn  0.49810004234313965 learn codes ber with rayleigh  0.4923500120639801 learn codes ber with rician  0.4682699739933014 ber with awgn  0.0 ber with rayleigh  5.833333333333334e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4979499876499176 learn codes ber with rayleigh  0.4918299615383148 learn codes ber with rician  0.46995997428894043 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5005599856376648 learn codes ber with rayleigh  0.49500998854637146 learn codes ber with rician  0.4701000154018402 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.4997500479221344 learn codes ber with rayleigh  0.49309006333351135 learn codes ber with rician  0.4697199761867523 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5003100037574768 learn codes ber with rayleigh  0.49371999502182007 learn codes ber with rician  0.471530020236969 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4959799647331238 learn codes ber with rayleigh  0.4900999963283539 learn codes ber with rician  0.4688499867916107 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4994699954986572 learn codes ber with rayleigh  0.4915599822998047 learn codes ber with rician  0.46908003091812134 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49873003363609314 learn codes ber with rayleigh  0.4932500422000885 learn codes ber with rician  0.4685800075531006 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5008699893951416 learn codes ber with rayleigh  0.4928700029850006 learn codes ber with rician  0.47171998023986816 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49891000986099243, 0.4982300400733948, 0.5006500482559204, 0.49935001134872437, 0.501240074634552, 0.500249981880188, 0.4977499842643738, 0.4996799826622009, 0.5026300549507141, 0.4983600080013275, 0.5016700029373169, 0.49810004234313965, 0.4979499876499176, 0.5005599856376648, 0.4997500479221344, 0.5003100037574768, 0.4959799647331238, 0.4994699954986572, 0.49873003363609314, 0.5008699893951416]
Learn Codes rayleigh [0.49004998803138733, 0.49031996726989746, 0.49334001541137695, 0.49184998869895935, 0.4943699836730957, 0.4938700199127197, 0.4918399751186371, 0.49421006441116333, 0.49639996886253357, 0.4925200343132019, 0.49406999349594116, 0.4923500120639801, 0.4918299615383148, 0.49500998854637146, 0.49309006333351135, 0.49371999502182007, 0.4900999963283539, 0.4915599822998047, 0.4932500422000885, 0.4928700029850006]
Learn Codes rician [0.47484999895095825, 0.4718700051307678, 0.4709300100803375, 0.4699699878692627, 0.471780002117157, 0.4692699909210205, 0.4694799780845642, 0.47134003043174744, 0.4717300534248352, 0.46768999099731445, 0.47117000818252563, 0.4682699739933014, 0.46995997428894043, 0.4701000154018402, 0.4697199761867523, 0.471530020236969, 0.4688499867916107, 0.46908003091812134, 0.4685800075531006, 0.47171998023986816]
AWGN [0.43524166666666664, 0.38906666666666667, 0.31653333333333333, 0.19306666666666666, 0.061125, 0.0032916666666666663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45362500000000006, 0.4125916666666667, 0.33266666666666667, 0.21534166666666663, 0.10322499999999998, 0.03986666666666666, 0.01308333333333333, 0.004191666666666667, 0.00135, 0.0004333333333333333, 0.000175, 5.833333333333334e-05, 3.3333333333333335e-05, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45243333333333335, 0.40388333333333337, 0.3220833333333334, 0.18337499999999998, 0.06286666666666667, 0.014141666666666667, 0.0030583333333333335, 0.0009, 0.0002, 0.0001, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69374964 loss Rayleigh: 0.69374366 loss Rician: 0.69373528   running time 11.989237308502197
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71370423 loss Rayleigh: 0.70631385 loss Rician: 0.71077786   running time 12.344403266906738
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71570556 loss Rayleigh: 0.70673104 loss Rician: 0.71447989   running time 12.126624584197998
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.70369295 loss Rayleigh: 0.69955347 loss Rician: 0.69568373   running time 12.314569234848022
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69416277 loss Rayleigh: 0.69413459 loss Rician: 0.69398031   running time 12.25493311882019
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69346796 loss Rayleigh: 0.69340857 loss Rician: 0.69331939   running time 12.085400342941284
====> Test set BCE loss with SNR 0.0 for AWGN 0.6932541131973267 Custom Loss 0.6932541131973267 with ber  0.501042902469635 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6933831572532654 Custom Loss 0.6933831572532654 with ber  0.5008642673492432 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6933249235153198 Custom Loss 0.6933249235153198 with ber  0.5012357234954834 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.94350004196167s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69349307 loss Rayleigh: 0.69346618 loss Rician: 0.69343360   running time 12.220423936843872
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69335223 loss Rayleigh: 0.69333143 loss Rician: 0.69328400   running time 12.205751180648804
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69331998 loss Rayleigh: 0.69328043 loss Rician: 0.69322869   running time 12.30752182006836
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69327879 loss Rayleigh: 0.69324057 loss Rician: 0.69318126   running time 12.256620645523071
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69327669 loss Rayleigh: 0.69320117 loss Rician: 0.69310302   running time 12.154410362243652
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69318237 loss Rayleigh: 0.69305010 loss Rician: 0.69287720   running time 12.310499429702759
====> Test set BCE loss with SNR 0.0 for AWGN 0.6921784281730652 Custom Loss 0.6921784281730652 with ber  0.480264276266098 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.693130373954773 Custom Loss 0.693130373954773 with ber  0.4965071678161621 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6925662755966187 Custom Loss 0.6925662755966187 with ber  0.48408570885658264 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.18127608299255s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69333867 loss Rayleigh: 0.69310293 loss Rician: 0.69277375   running time 11.928839683532715
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69343413 loss Rayleigh: 0.69315142 loss Rician: 0.69281672   running time 12.271907329559326
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332590 loss Rayleigh: 0.69285356 loss Rician: 0.69216498   running time 12.25060486793518
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69332238 loss Rayleigh: 0.69276220 loss Rician: 0.69156851   running time 12.222797632217407
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69334710 loss Rayleigh: 0.69281890 loss Rician: 0.69154227   running time 12.323688745498657
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69343392 loss Rayleigh: 0.69287931 loss Rician: 0.69159214   running time 12.056884288787842
====> Test set BCE loss with SNR 0.0 for AWGN 0.6889735460281372 Custom Loss 0.6889735460281372 with ber  0.46461430191993713 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6923747658729553 Custom Loss 0.6923747658729553 with ber  0.48872143030166626 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6897817254066467 Custom Loss 0.6897817254066467 with ber  0.4642714560031891 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.94958090782166s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69349915 loss Rayleigh: 0.69270129 loss Rician: 0.69145578   running time 12.160544395446777
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69335451 loss Rayleigh: 0.69259198 loss Rician: 0.69128106   running time 12.249511241912842
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69328582 loss Rayleigh: 0.69248564 loss Rician: 0.69093336   running time 12.133025169372559
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69328511 loss Rayleigh: 0.69274992 loss Rician: 0.69101543   running time 12.22509241104126
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69342896 loss Rayleigh: 0.69257168 loss Rician: 0.69106421   running time 12.194483995437622
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69326324 loss Rayleigh: 0.69249868 loss Rician: 0.69068649   running time 12.296134233474731
====> Test set BCE loss with SNR 0.0 for AWGN 0.6889428496360779 Custom Loss 0.6889428496360779 with ber  0.47334998846054077 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692676305770874 Custom Loss 0.692676305770874 with ber  0.48946428298950195 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6888659596443176 Custom Loss 0.6888659596443176 with ber  0.470771461725235 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.95332884788513s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327714 loss Rayleigh: 0.69259840 loss Rician: 0.69102637   running time 12.211121797561646
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69336429 loss Rayleigh: 0.69254763 loss Rician: 0.69079104   running time 12.03359341621399
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69340019 loss Rayleigh: 0.69272503 loss Rician: 0.69066784   running time 12.149852514266968
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69325477 loss Rayleigh: 0.69262775 loss Rician: 0.69071897   running time 12.095278978347778
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69331284 loss Rayleigh: 0.69251610 loss Rician: 0.69044311   running time 12.242448091506958
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69327550 loss Rayleigh: 0.69270538 loss Rician: 0.69017854   running time 12.19237470626831
====> Test set BCE loss with SNR 0.0 for AWGN 0.6881149411201477 Custom Loss 0.6881149411201477 with ber  0.4674857258796692 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6920967698097229 Custom Loss 0.6920967698097229 with ber  0.485485702753067 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6881896257400513 Custom Loss 0.6881896257400513 with ber  0.4648071229457855 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.78209233283997s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69330391 loss Rayleigh: 0.69272989 loss Rician: 0.69034020   running time 11.938511371612549
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69337844 loss Rayleigh: 0.69264042 loss Rician: 0.69016349   running time 12.1388099193573
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69350582 loss Rayleigh: 0.69293153 loss Rician: 0.69077017   running time 12.089442014694214
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69346092 loss Rayleigh: 0.69292021 loss Rician: 0.69055008   running time 12.043565511703491
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69349775 loss Rayleigh: 0.69287104 loss Rician: 0.69101736   running time 12.402363538742065
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69337683 loss Rayleigh: 0.69277935 loss Rician: 0.69062971   running time 12.05472445487976
====> Test set BCE loss with SNR 0.0 for AWGN 0.6871968507766724 Custom Loss 0.6871968507766724 with ber  0.4561000466346741 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6922197937965393 Custom Loss 0.6922197937965393 with ber  0.48380714654922485 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6882134675979614 Custom Loss 0.6882134675979614 with ber  0.45862141251564026 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.58680939674377s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69340184 loss Rayleigh: 0.69249601 loss Rician: 0.69046552   running time 12.001981258392334
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69339977 loss Rayleigh: 0.69268993 loss Rician: 0.69051448   running time 12.214393854141235
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69332919 loss Rayleigh: 0.69271973 loss Rician: 0.69053568   running time 12.509018898010254
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329962 loss Rayleigh: 0.69269041 loss Rician: 0.69007692   running time 12.387306690216064
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329529 loss Rayleigh: 0.69275739 loss Rician: 0.69013004   running time 12.138696670532227
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336024 loss Rayleigh: 0.69262305 loss Rician: 0.69020861   running time 12.838922500610352
====> Test set BCE loss with SNR 0.0 for AWGN 0.6873718500137329 Custom Loss 0.6873718500137329 with ber  0.4629785418510437 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.692315399646759 Custom Loss 0.692315399646759 with ber  0.4872071146965027 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6879177093505859 Custom Loss 0.6879177093505859 with ber  0.46183571219444275 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_7_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.85336637496948s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69325992 loss Rayleigh: 0.69256247 loss Rician: 0.68999249   running time 12.112152576446533
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69336296 loss Rayleigh: 0.69249530 loss Rician: 0.69026288   running time 12.231988430023193
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69324895 loss Rayleigh: 0.69257565 loss Rician: 0.68971354   running time 12.235058546066284
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69334502 loss Rayleigh: 0.69281898 loss Rician: 0.69018061   running time 12.207815170288086
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69335954 loss Rayleigh: 0.69288274 loss Rician: 0.69043944   running time 12.408334255218506
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69337459 loss Rayleigh: 0.69265947 loss Rician: 0.69059375   running time 12.11440110206604
====> Test set BCE loss with SNR 0.0 for AWGN 0.6884555816650391 Custom Loss 0.6884555816650391 with ber  0.4721500277519226 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927648782730103 Custom Loss 0.6927648782730103 with ber  0.4885285794734955 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6881091594696045 Custom Loss 0.6881091594696045 with ber  0.4697071611881256 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_8_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.2178111076355s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330972 loss Rayleigh: 0.69264917 loss Rician: 0.69030909   running time 12.103782176971436
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69341170 loss Rayleigh: 0.69261024 loss Rician: 0.69008557   running time 12.18216323852539
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329532 loss Rayleigh: 0.69272181 loss Rician: 0.69030996   running time 12.056398868560791
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330732 loss Rayleigh: 0.69267148 loss Rician: 0.68957437   running time 12.347123146057129
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69334562 loss Rayleigh: 0.69277654 loss Rician: 0.68990876   running time 12.062528133392334
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336471 loss Rayleigh: 0.69277285 loss Rician: 0.68966940   running time 12.220109462738037
====> Test set BCE loss with SNR 0.0 for AWGN 0.6892308592796326 Custom Loss 0.6892308592796326 with ber  0.46996426582336426 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6926472783088684 Custom Loss 0.6926472783088684 with ber  0.4890356957912445 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6892654299736023 Custom Loss 0.6892654299736023 with ber  0.4674714505672455 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_9_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 76.7496612071991s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69325391 loss Rayleigh: 0.69279434 loss Rician: 0.69072834   running time 12.047281742095947
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69327843 loss Rayleigh: 0.69262893 loss Rician: 0.68982311   running time 12.197869300842285
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69335213 loss Rayleigh: 0.69273219 loss Rician: 0.68950949   running time 12.381831884384155
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69327903 loss Rayleigh: 0.69246335 loss Rician: 0.68973004   running time 12.259905576705933
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334731 loss Rayleigh: 0.69254747 loss Rician: 0.68966194   running time 12.192613124847412
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69330286 loss Rayleigh: 0.69269980 loss Rician: 0.69006782   running time 12.181741714477539
====> Test set BCE loss with SNR 0.0 for AWGN 0.6888681650161743 Custom Loss 0.6888681650161743 with ber  0.47145000100135803 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927403807640076 Custom Loss 0.6927403807640076 with ber  0.49302855134010315 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6887856125831604 Custom Loss 0.6887856125831604 with ber  0.4693428575992584 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
each epoch training time: 77.13552713394165s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49884286522865295 learn codes ber with rayleigh  0.4926000237464905 learn codes ber with rician  0.48042139410972595 ber with awgn  0.37525 ber with rayleigh  0.39520000000000005 ber with rician  0.3892812500000001
Test SNR 5 learn codes ber with awgn  0.5004785656929016 learn codes ber with rayleigh  0.49138569831848145 learn codes ber with rician  0.47687143087387085 ber with awgn  0.28661875 ber with rayleigh  0.30731249999999993 ber with rician  0.28495624999999997
Test SNR 10 learn codes ber with awgn  0.5023285150527954 learn codes ber with rayleigh  0.4919642508029938 learn codes ber with rician  0.47782859206199646 ber with awgn  0.15939375000000003 ber with rayleigh  0.18446875000000001 ber with rician  0.13956250000000003
Test SNR 15 learn codes ber with awgn  0.49967145919799805 learn codes ber with rayleigh  0.49253568053245544 learn codes ber with rician  0.4772857129573822 ber with awgn  0.0376625 ber with rayleigh  0.0852875 ber with rician  0.03380000000000001
Test SNR 20 learn codes ber with awgn  0.4981214106082916 learn codes ber with rayleigh  0.4905499815940857 learn codes ber with rician  0.47604283690452576 ber with awgn  0.0009249999999999999 ber with rayleigh  0.030731250000000005 ber with rician  0.004543750000000001
Test SNR 25 learn codes ber with awgn  0.4996214509010315 learn codes ber with rayleigh  0.49184998869895935 learn codes ber with rician  0.4781571328639984 ber with awgn  0.0 ber with rayleigh  0.01023125 ber with rician  0.0007562499999999999
Test SNR 30 learn codes ber with awgn  0.5004714727401733 learn codes ber with rayleigh  0.4933285713195801 learn codes ber with rician  0.47757142782211304 ber with awgn  0.0 ber with rayleigh  0.0033249999999999994 ber with rician  0.00011250000000000001
Test SNR 35 learn codes ber with awgn  0.501264214515686 learn codes ber with rayleigh  0.493628591299057 learn codes ber with rician  0.47819995880126953 ber with awgn  0.0 ber with rayleigh  0.00119375 ber with rician  1.8750000000000002e-05
Test SNR 40 learn codes ber with awgn  0.5019856691360474 learn codes ber with rayleigh  0.4954000413417816 learn codes ber with rician  0.47925716638565063 ber with awgn  0.0 ber with rayleigh  0.00034375000000000003 ber with rician  6.25e-06
Test SNR 45 learn codes ber with awgn  0.5002214312553406 learn codes ber with rayleigh  0.49272146821022034 learn codes ber with rician  0.4781143069267273 ber with awgn  0.0 ber with rayleigh  8.750000000000001e-05 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.5017000436782837 learn codes ber with rayleigh  0.4926428198814392 learn codes ber with rician  0.47657856345176697 ber with awgn  0.0 ber with rayleigh  3.7500000000000003e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.49611425399780273 learn codes ber with rayleigh  0.4895857274532318 learn codes ber with rician  0.47472143173217773 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5023642778396606 learn codes ber with rayleigh  0.4944428503513336 learn codes ber with rician  0.4777071475982666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5000214576721191 learn codes ber with rayleigh  0.4913643002510071 learn codes ber with rician  0.478128582239151 ber with awgn  0.0 ber with rayleigh  6.25e-06 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5018142461776733 learn codes ber with rayleigh  0.49462857842445374 learn codes ber with rician  0.4776071608066559 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49718576669692993 learn codes ber with rayleigh  0.4918572008609772 learn codes ber with rician  0.4761214256286621 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5013999342918396 learn codes ber with rayleigh  0.4944285452365875 learn codes ber with rician  0.4781142771244049 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49755001068115234 learn codes ber with rayleigh  0.49027857184410095 learn codes ber with rician  0.4768642783164978 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5012714266777039 learn codes ber with rayleigh  0.4925142824649811 learn codes ber with rician  0.4794500470161438 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.499357134103775 learn codes ber with rayleigh  0.4899786114692688 learn codes ber with rician  0.4771285653114319 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49884286522865295, 0.5004785656929016, 0.5023285150527954, 0.49967145919799805, 0.4981214106082916, 0.4996214509010315, 0.5004714727401733, 0.501264214515686, 0.5019856691360474, 0.5002214312553406, 0.5017000436782837, 0.49611425399780273, 0.5023642778396606, 0.5000214576721191, 0.5018142461776733, 0.49718576669692993, 0.5013999342918396, 0.49755001068115234, 0.5012714266777039, 0.499357134103775]
Learn Codes rayleigh [0.4926000237464905, 0.49138569831848145, 0.4919642508029938, 0.49253568053245544, 0.4905499815940857, 0.49184998869895935, 0.4933285713195801, 0.493628591299057, 0.4954000413417816, 0.49272146821022034, 0.4926428198814392, 0.4895857274532318, 0.4944428503513336, 0.4913643002510071, 0.49462857842445374, 0.4918572008609772, 0.4944285452365875, 0.49027857184410095, 0.4925142824649811, 0.4899786114692688]
Learn Codes rician [0.48042139410972595, 0.47687143087387085, 0.47782859206199646, 0.4772857129573822, 0.47604283690452576, 0.4781571328639984, 0.47757142782211304, 0.47819995880126953, 0.47925716638565063, 0.4781143069267273, 0.47657856345176697, 0.47472143173217773, 0.4777071475982666, 0.478128582239151, 0.4776071608066559, 0.4761214256286621, 0.4781142771244049, 0.4768642783164978, 0.4794500470161438, 0.4771285653114319]
AWGN [0.37525, 0.28661875, 0.15939375000000003, 0.0376625, 0.0009249999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39520000000000005, 0.30731249999999993, 0.18446875000000001, 0.0852875, 0.030731250000000005, 0.01023125, 0.0033249999999999994, 0.00119375, 0.00034375000000000003, 8.750000000000001e-05, 3.7500000000000003e-05, 2.5e-05, 0.0, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3892812500000001, 0.28495624999999997, 0.13956250000000003, 0.03380000000000001, 0.004543750000000001, 0.0007562499999999999, 0.00011250000000000001, 1.8750000000000002e-05, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69332764 loss Rayleigh: 0.69332101 loss Rician: 0.69331852   running time 12.568880319595337
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71223583 loss Rayleigh: 0.71818233 loss Rician: 0.70963285   running time 12.834194898605347
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.71086310 loss Rayleigh: 0.70381619 loss Rician: 0.70993084   running time 13.229571104049683
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69470317 loss Rayleigh: 0.69486122 loss Rician: 0.69445536   running time 12.902291536331177
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69351117 loss Rayleigh: 0.69347224 loss Rician: 0.69341394   running time 12.945533990859985
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69362260 loss Rayleigh: 0.69355536 loss Rician: 0.69345831   running time 12.813941478729248
====> Test set BCE loss with SNR 0.0 for AWGN 0.6935195326805115 Custom Loss 0.6935195326805115 with ber  0.5008214712142944 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6936128735542297 Custom Loss 0.6936128735542297 with ber  0.5002213716506958 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6935684084892273 Custom Loss 0.6935684084892273 with ber  0.4999571442604065 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.64628720283508s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69363982 loss Rayleigh: 0.69363250 loss Rician: 0.69362535   running time 12.725967407226562
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69340852 loss Rayleigh: 0.69335799 loss Rician: 0.69327451   running time 12.728649616241455
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69337389 loss Rayleigh: 0.69333566 loss Rician: 0.69328119   running time 12.84909200668335
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69328802 loss Rayleigh: 0.69324954 loss Rician: 0.69318845   running time 12.92270803451538
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69324926 loss Rayleigh: 0.69316077 loss Rician: 0.69307752   running time 12.650400638580322
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.69342571 loss Rayleigh: 0.69328019 loss Rician: 0.69309031   running time 12.955487966537476
====> Test set BCE loss with SNR 0.0 for AWGN 0.6923577189445496 Custom Loss 0.6923577189445496 with ber  0.49815717339515686 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931461095809937 Custom Loss 0.6931461095809937 with ber  0.5001500248908997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6926533579826355 Custom Loss 0.6926533579826355 with ber  0.4990714490413666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.19364094734192s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69330480 loss Rayleigh: 0.69319044 loss Rician: 0.69302488   running time 12.52906322479248
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336102 loss Rayleigh: 0.69317045 loss Rician: 0.69282388   running time 12.755999326705933
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69334508 loss Rayleigh: 0.69313849 loss Rician: 0.69255961   running time 12.713576316833496
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336193 loss Rayleigh: 0.69297096 loss Rician: 0.69205016   running time 12.81905198097229
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69336224 loss Rayleigh: 0.69304065 loss Rician: 0.69204080   running time 12.653737783432007
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.69323200 loss Rayleigh: 0.69298959 loss Rician: 0.69171330   running time 12.862614870071411
====> Test set BCE loss with SNR 0.0 for AWGN 0.6887989640235901 Custom Loss 0.6887989640235901 with ber  0.4728071689605713 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6927744746208191 Custom Loss 0.6927744746208191 with ber  0.4924356937408447 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6898144483566284 Custom Loss 0.6898144483566284 with ber  0.47128573060035706 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.81029605865479s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69325115 loss Rayleigh: 0.69298426 loss Rician: 0.69146528   running time 12.499871492385864
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69328023 loss Rayleigh: 0.69293051 loss Rician: 0.69165384   running time 12.982842683792114
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329972 loss Rayleigh: 0.69297416 loss Rician: 0.69118523   running time 12.669967889785767
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69334911 loss Rayleigh: 0.69301022 loss Rician: 0.69140456   running time 12.804890394210815
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69329464 loss Rayleigh: 0.69300283 loss Rician: 0.69135330   running time 12.94965410232544
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.69333844 loss Rayleigh: 0.69304092 loss Rician: 0.69110948   running time 12.61651611328125
====> Test set BCE loss with SNR 0.0 for AWGN 0.6917553544044495 Custom Loss 0.6917553544044495 with ber  0.4834499955177307 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930991411209106 Custom Loss 0.6930991411209106 with ber  0.4916857182979584 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6890027523040771 Custom Loss 0.6890027523040771 with ber  0.4715285897254944 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.95421242713928s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69331802 loss Rayleigh: 0.69294189 loss Rician: 0.69127453   running time 12.660809993743896
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332647 loss Rayleigh: 0.69289953 loss Rician: 0.69124132   running time 13.122350931167603
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69326209 loss Rayleigh: 0.69301457 loss Rician: 0.69125643   running time 12.763205289840698
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69334390 loss Rayleigh: 0.69307868 loss Rician: 0.69128073   running time 12.761253356933594
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69332640 loss Rayleigh: 0.69321437 loss Rician: 0.69149901   running time 12.81669282913208
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.69329193 loss Rayleigh: 0.69297982 loss Rician: 0.69101852   running time 12.632166147232056
====> Test set BCE loss with SNR 0.0 for AWGN 0.6903505325317383 Custom Loss 0.6903505325317383 with ber  0.47771430015563965 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6928930878639221 Custom Loss 0.6928930878639221 with ber  0.49267855286598206 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6888931393623352 Custom Loss 0.6888931393623352 with ber  0.4672214388847351 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.13348031044006s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69343032 loss Rayleigh: 0.69312229 loss Rician: 0.69115225   running time 12.610503673553467
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69328480 loss Rayleigh: 0.69298441 loss Rician: 0.69085414   running time 12.713643550872803
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69333664 loss Rayleigh: 0.69304286 loss Rician: 0.69115260   running time 12.876415729522705
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69343121 loss Rayleigh: 0.69311442 loss Rician: 0.69139588   running time 12.668750524520874
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69323108 loss Rayleigh: 0.69297979 loss Rician: 0.69090790   running time 12.975368976593018
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.69341037 loss Rayleigh: 0.69305499 loss Rician: 0.69106790   running time 12.847994804382324
====> Test set BCE loss with SNR 0.0 for AWGN 0.687157928943634 Custom Loss 0.687157928943634 with ber  0.469249963760376 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929146647453308 Custom Loss 0.6929146647453308 with ber  0.4937642514705658 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6890147924423218 Custom Loss 0.6890147924423218 with ber  0.4722856879234314 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.19594287872314s
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69327828 loss Rayleigh: 0.69301743 loss Rician: 0.69134595   running time 12.702193260192871
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69332439 loss Rayleigh: 0.69293849 loss Rician: 0.69089832   running time 12.715487718582153
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69336230 loss Rayleigh: 0.69297385 loss Rician: 0.69125879   running time 12.97062611579895
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69335889 loss Rayleigh: 0.69328123 loss Rician: 0.69115095   running time 12.994317770004272
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69329336 loss Rayleigh: 0.69308598 loss Rician: 0.69097750   running time 12.785395860671997
====> Epoch: 7 with snr 0.0 Average loss AWGN: 0.69330193 loss Rayleigh: 0.69278664 loss Rician: 0.69098966   running time 12.9322509765625
====> Test set BCE loss with SNR 0.0 for AWGN 0.6916646957397461 Custom Loss 0.6916646957397461 with ber  0.48780712485313416 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6929681897163391 Custom Loss 0.6929681897163391 with ber  0.49235716462135315 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6888899207115173 Custom Loss 0.6888899207115173 with ber  0.4694499969482422 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_7_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.61310362815857s
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69340477 loss Rayleigh: 0.69306102 loss Rician: 0.69108391   running time 12.586613416671753
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69339649 loss Rayleigh: 0.69312647 loss Rician: 0.69133770   running time 12.820857048034668
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69328343 loss Rayleigh: 0.69292769 loss Rician: 0.69107617   running time 12.73613429069519
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69336661 loss Rayleigh: 0.69290890 loss Rician: 0.69101952   running time 12.815277576446533
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69331768 loss Rayleigh: 0.69312481 loss Rician: 0.69120466   running time 12.740091800689697
====> Epoch: 8 with snr 0.0 Average loss AWGN: 0.69332547 loss Rayleigh: 0.69294689 loss Rician: 0.69096485   running time 12.800853490829468
====> Test set BCE loss with SNR 0.0 for AWGN 0.6947494745254517 Custom Loss 0.6947494745254517 with ber  0.4926857054233551 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930181384086609 Custom Loss 0.6930181384086609 with ber  0.49215713143348694 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6887978315353394 Custom Loss 0.6887978315353394 with ber  0.47537142038345337 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_8_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.8855574131012s
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69331672 loss Rayleigh: 0.69333807 loss Rician: 0.69120975   running time 12.506316661834717
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329897 loss Rayleigh: 0.69295056 loss Rician: 0.69089302   running time 12.914976596832275
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69336702 loss Rayleigh: 0.69312509 loss Rician: 0.69082929   running time 12.77879023551941
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69344935 loss Rayleigh: 0.69297703 loss Rician: 0.69078062   running time 12.716229438781738
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69330100 loss Rayleigh: 0.69293537 loss Rician: 0.69061451   running time 12.738594770431519
====> Epoch: 9 with snr 0.0 Average loss AWGN: 0.69329162 loss Rayleigh: 0.69301386 loss Rician: 0.69065351   running time 12.842941999435425
====> Test set BCE loss with SNR 0.0 for AWGN 0.6902948617935181 Custom Loss 0.6902948617935181 with ber  0.4790285527706146 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6931183338165283 Custom Loss 0.6931183338165283 with ber  0.4925857186317444 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6889702081680298 Custom Loss 0.6889702081680298 with ber  0.4663929045200348 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_9_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 80.9176115989685s
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69346417 loss Rayleigh: 0.69323237 loss Rician: 0.69067817   running time 12.649153470993042
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69334558 loss Rayleigh: 0.69313354 loss Rician: 0.69084892   running time 12.785869598388672
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329877 loss Rayleigh: 0.69302796 loss Rician: 0.69051603   running time 12.937897443771362
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69328353 loss Rayleigh: 0.69291590 loss Rician: 0.69075228   running time 12.678907632827759
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69336465 loss Rayleigh: 0.69302981 loss Rician: 0.69059590   running time 12.971351861953735
====> Epoch: 10 with snr 0.0 Average loss AWGN: 0.69329987 loss Rayleigh: 0.69303271 loss Rician: 0.69049156   running time 12.712604284286499
====> Test set BCE loss with SNR 0.0 for AWGN 0.6915547251701355 Custom Loss 0.6915547251701355 with ber  0.48351430892944336 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6930979490280151 Custom Loss 0.6930979490280151 with ber  0.4912071228027344 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6885038018226624 Custom Loss 0.6885038018226624 with ber  0.4691428542137146 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
each epoch training time: 81.10482382774353s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230515_193616\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_10_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230515_193616.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5000214576721191 learn codes ber with rayleigh  0.4927857518196106 learn codes ber with rician  0.47640714049339294 ber with awgn  0.4411625 ber with rayleigh  0.45574375 ber with rician  0.4499375
Test SNR 5 learn codes ber with awgn  0.4990714490413666 learn codes ber with rayleigh  0.49340716004371643 learn codes ber with rician  0.4767071604728699 ber with awgn  0.39479374999999994 ber with rayleigh  0.41161875000000003 ber with rician  0.40680625
Test SNR 10 learn codes ber with awgn  0.49894994497299194 learn codes ber with rayleigh  0.4937357008457184 learn codes ber with rician  0.47719287872314453 ber with awgn  0.31390625 ber with rayleigh  0.33281875000000005 ber with rician  0.31622500000000003
Test SNR 15 learn codes ber with awgn  0.4986642897129059 learn codes ber with rayleigh  0.49407142400741577 learn codes ber with rician  0.4778357148170471 ber with awgn  0.19310000000000002 ber with rayleigh  0.21390625000000002 ber with rician  0.17695
Test SNR 20 learn codes ber with awgn  0.4988214373588562 learn codes ber with rayleigh  0.4923642575740814 learn codes ber with rician  0.4770785868167877 ber with awgn  0.06155000000000001 ber with rayleigh  0.10434999999999998 ber with rician  0.051506249999999996
Test SNR 25 learn codes ber with awgn  0.502750039100647 learn codes ber with rayleigh  0.49739283323287964 learn codes ber with rician  0.4776071608066559 ber with awgn  0.0030499999999999998 ber with rayleigh  0.03914375 ber with rician  0.00803125
Test SNR 30 learn codes ber with awgn  0.5007642507553101 learn codes ber with rayleigh  0.4955499768257141 learn codes ber with rician  0.4798428416252136 ber with awgn  0.0 ber with rayleigh  0.013168750000000002 ber with rician  0.00105625
Test SNR 35 learn codes ber with awgn  0.49993571639060974 learn codes ber with rayleigh  0.4946642816066742 learn codes ber with rician  0.4767642915248871 ber with awgn  0.0 ber with rayleigh  0.004368749999999999 ber with rician  0.000175
Test SNR 40 learn codes ber with awgn  0.49888572096824646 learn codes ber with rayleigh  0.4936142861843109 learn codes ber with rician  0.4778357148170471 ber with awgn  0.0 ber with rayleigh  0.0014937499999999999 ber with rician  5e-05
Test SNR 45 learn codes ber with awgn  0.5019143223762512 learn codes ber with rayleigh  0.49612849950790405 learn codes ber with rician  0.47823572158813477 ber with awgn  0.0 ber with rayleigh  0.00038750000000000004 ber with rician  0.0
Test SNR 50 learn codes ber with awgn  0.49967139959335327 learn codes ber with rayleigh  0.49359288811683655 learn codes ber with rician  0.47902145981788635 ber with awgn  0.0 ber with rayleigh  0.0001 ber with rician  1.25e-05
Test SNR 55 learn codes ber with awgn  0.49919286370277405 learn codes ber with rayleigh  0.49413570761680603 learn codes ber with rician  0.4771142899990082 ber with awgn  0.0 ber with rayleigh  3.125e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.499828577041626 learn codes ber with rayleigh  0.49442142248153687 learn codes ber with rician  0.47842854261398315 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4979357123374939 learn codes ber with rayleigh  0.4934428632259369 learn codes ber with rician  0.4762214720249176 ber with awgn  0.0 ber with rayleigh  6.25e-06 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5001999735832214 learn codes ber with rayleigh  0.49475717544555664 learn codes ber with rician  0.47640714049339294 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5000428557395935 learn codes ber with rayleigh  0.4961143136024475 learn codes ber with rician  0.478128582239151 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4997785687446594 learn codes ber with rayleigh  0.49387145042419434 learn codes ber with rician  0.47649288177490234 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4981785714626312 learn codes ber with rayleigh  0.49259287118911743 learn codes ber with rician  0.47659286856651306 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5022356510162354 learn codes ber with rayleigh  0.4976928234100342 learn codes ber with rician  0.4803714156150818 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4998857080936432 learn codes ber with rayleigh  0.49467143416404724 learn codes ber with rician  0.47601428627967834 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5000214576721191, 0.4990714490413666, 0.49894994497299194, 0.4986642897129059, 0.4988214373588562, 0.502750039100647, 0.5007642507553101, 0.49993571639060974, 0.49888572096824646, 0.5019143223762512, 0.49967139959335327, 0.49919286370277405, 0.499828577041626, 0.4979357123374939, 0.5001999735832214, 0.5000428557395935, 0.4997785687446594, 0.4981785714626312, 0.5022356510162354, 0.4998857080936432]
Learn Codes rayleigh [0.4927857518196106, 0.49340716004371643, 0.4937357008457184, 0.49407142400741577, 0.4923642575740814, 0.49739283323287964, 0.4955499768257141, 0.4946642816066742, 0.4936142861843109, 0.49612849950790405, 0.49359288811683655, 0.49413570761680603, 0.49442142248153687, 0.4934428632259369, 0.49475717544555664, 0.4961143136024475, 0.49387145042419434, 0.49259287118911743, 0.4976928234100342, 0.49467143416404724]
Learn Codes rician [0.47640714049339294, 0.4767071604728699, 0.47719287872314453, 0.4778357148170471, 0.4770785868167877, 0.4776071608066559, 0.4798428416252136, 0.4767642915248871, 0.4778357148170471, 0.47823572158813477, 0.47902145981788635, 0.4771142899990082, 0.47842854261398315, 0.4762214720249176, 0.47640714049339294, 0.478128582239151, 0.47649288177490234, 0.47659286856651306, 0.4803714156150818, 0.47601428627967834]
AWGN [0.4411625, 0.39479374999999994, 0.31390625, 0.19310000000000002, 0.06155000000000001, 0.0030499999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45574375, 0.41161875000000003, 0.33281875000000005, 0.21390625000000002, 0.10434999999999998, 0.03914375, 0.013168750000000002, 0.004368749999999999, 0.0014937499999999999, 0.00038750000000000004, 0.0001, 3.125e-05, 2.5e-05, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4499375, 0.40680625, 0.31622500000000003, 0.17695, 0.051506249999999996, 0.00803125, 0.00105625, 0.000175, 5e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
