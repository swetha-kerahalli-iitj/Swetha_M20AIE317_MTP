Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=0.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', enc_rnn='gru', dec_rnn='gru', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=6, test_ratio=1, block_len=(10, 20), code_rate_k=(3, 5, 7), code_rate_n=(4, 6, 8), modtype=('QAM16', 'QAM64'), block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_211438\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_211438\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_211438\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\20230513_211438\\plot_faded')
use_cuda:  False

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69286225 loss Rayleigh: 0.69280478 loss Rician: 0.69274327   running time 5.660670757293701
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.68218597 loss Rayleigh: 0.68003153 loss Rician: 0.67575647   running time 5.274789333343506
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67639871 loss Rayleigh: 0.67061632 loss Rician: 0.66695260   running time 5.154820203781128
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66562722 loss Rayleigh: 0.66616256 loss Rician: 0.66231181   running time 20.377934217453003
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65418436 loss Rayleigh: 0.66449073 loss Rician: 0.65206985   running time 8.71144700050354
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64077332 loss Rayleigh: 0.65045227 loss Rician: 0.64143409   running time 6.719825744628906
====> Test set BCE loss with SNR 0.0 for AWGN 0.6330993175506592 Custom Loss 0.6330993175506592 with ber  0.4979333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6402866244316101 Custom Loss 0.6402866244316101 with ber  0.4979333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6335095167160034 Custom Loss 0.6335095167160034 with ber  0.4979333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 53.74040508270264s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59954998 loss Rayleigh: 0.61181548 loss Rician: 0.59949756   running time 5.88995099067688
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.57702973 loss Rayleigh: 0.59801597 loss Rician: 0.58289129   running time 6.084752321243286
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56750448 loss Rayleigh: 0.58751475 loss Rician: 0.57043542   running time 6.028835296630859
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56608160 loss Rayleigh: 0.58379453 loss Rician: 0.56805608   running time 6.032140254974365
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56957759 loss Rayleigh: 0.58702177 loss Rician: 0.57015555   running time 5.961551904678345
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55829652 loss Rayleigh: 0.57358605 loss Rician: 0.55940604   running time 5.963743686676025
====> Test set BCE loss with SNR 0.0 for AWGN 0.561421275138855 Custom Loss 0.561421275138855 with ber  0.5006333333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5743409991264343 Custom Loss 0.5743409991264343 with ber  0.5006333333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5596135258674622 Custom Loss 0.5596135258674622 with ber  0.5006333333333334 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.96768641471863s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.56067151 loss Rayleigh: 0.57249488 loss Rician: 0.56117715   running time 5.912954092025757
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54821225 loss Rayleigh: 0.56040249 loss Rician: 0.54842970   running time 5.995300531387329
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54824084 loss Rayleigh: 0.56330928 loss Rician: 0.54448479   running time 5.9572203159332275
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54612058 loss Rayleigh: 0.55986892 loss Rician: 0.54481175   running time 6.1681036949157715
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54804035 loss Rayleigh: 0.56186233 loss Rician: 0.54631883   running time 6.111804246902466
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.55251049 loss Rayleigh: 0.56314088 loss Rician: 0.54677846   running time 5.971404314041138
====> Test set BCE loss with SNR 0.0 for AWGN 0.5398241281509399 Custom Loss 0.5398241281509399 with ber  0.4986333333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5552436113357544 Custom Loss 0.5552436113357544 with ber  0.4986333333333334 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5370322465896606 Custom Loss 0.5370322465896606 with ber  0.4986333333333334 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.96236968040466s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53897913 loss Rayleigh: 0.55070462 loss Rician: 0.53597524   running time 6.105668544769287
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53703167 loss Rayleigh: 0.55122670 loss Rician: 0.53468577   running time 6.270336151123047
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.54108400 loss Rayleigh: 0.55079797 loss Rician: 0.53483129   running time 5.99266791343689
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53388293 loss Rayleigh: 0.54471998 loss Rician: 0.53099867   running time 5.96224570274353
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53127109 loss Rayleigh: 0.53868107 loss Rician: 0.52608725   running time 5.997396230697632
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53099928 loss Rayleigh: 0.54277604 loss Rician: 0.52809126   running time 6.133973121643066
====> Test set BCE loss with SNR 0.0 for AWGN 0.5330497026443481 Custom Loss 0.5330497026443481 with ber  0.5027 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.541233479976654 Custom Loss 0.541233479976654 with ber  0.5027 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5267914533615112 Custom Loss 0.5267914533615112 with ber  0.5027 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.375693798065186s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53486217 loss Rayleigh: 0.54120692 loss Rician: 0.52947441   running time 5.870174169540405
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53522086 loss Rayleigh: 0.54247349 loss Rician: 0.52752467   running time 5.981339454650879
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53194822 loss Rayleigh: 0.53880458 loss Rician: 0.52572030   running time 6.108729362487793
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53375182 loss Rayleigh: 0.54110060 loss Rician: 0.52555122   running time 6.028346300125122
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53189378 loss Rayleigh: 0.54016271 loss Rician: 0.52559222   running time 5.958039045333862
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.53130788 loss Rayleigh: 0.53581322 loss Rician: 0.52094340   running time 5.9381749629974365
====> Test set BCE loss with SNR 0.0 for AWGN 0.5267409682273865 Custom Loss 0.5267409682273865 with ber  0.5001666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.533938467502594 Custom Loss 0.533938467502594 with ber  0.5001666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5187225341796875 Custom Loss 0.5187225341796875 with ber  0.5001666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.88295531272888s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.53105922 loss Rayleigh: 0.53863217 loss Rician: 0.52350684   running time 6.002232074737549
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.52913922 loss Rayleigh: 0.53560706 loss Rician: 0.52246917   running time 6.025598049163818
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.52906109 loss Rayleigh: 0.53839204 loss Rician: 0.52437186   running time 5.984045505523682
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.52795349 loss Rayleigh: 0.53773865 loss Rician: 0.52167632   running time 5.992455959320068
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.53426566 loss Rayleigh: 0.53698199 loss Rician: 0.52266026   running time 6.125377178192139
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.52656698 loss Rayleigh: 0.53662976 loss Rician: 0.52132984   running time 6.0862367153167725
====> Test set BCE loss with SNR 0.0 for AWGN 0.526098370552063 Custom Loss 0.526098370552063 with ber  0.5029 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5322118997573853 Custom Loss 0.5322118997573853 with ber  0.5029 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5169390439987183 Custom Loss 0.5169390439987183 with ber  0.5029 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.056747913360596s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4997 learn codes ber with rayleigh  0.4997 learn codes ber with rician  0.4997 ber with awgn  0.3755 ber with rayleigh  0.400025 ber with rician  0.392675
Test SNR 5 learn codes ber with awgn  0.4950333333333334 learn codes ber with rayleigh  0.4950333333333334 learn codes ber with rician  0.4950333333333334 ber with awgn  0.28475 ber with rayleigh  0.30757500000000004 ber with rician  0.29422499999999996
Test SNR 10 learn codes ber with awgn  0.49413333333333326 learn codes ber with rayleigh  0.49413333333333326 learn codes ber with rician  0.49413333333333326 ber with awgn  0.157875 ber with rayleigh  0.1843 ber with rician  0.160225
Test SNR 15 learn codes ber with awgn  0.49176666666666663 learn codes ber with rayleigh  0.49176666666666663 learn codes ber with rician  0.49176666666666663 ber with awgn  0.035699999999999996 ber with rayleigh  0.0821 ber with rician  0.05320000000000001
Test SNR 20 learn codes ber with awgn  0.4991333333333333 learn codes ber with rayleigh  0.4991333333333333 learn codes ber with rician  0.4991333333333333 ber with awgn  0.0007250000000000002 ber with rayleigh  0.030900000000000004 ber with rician  0.015700000000000002
Test SNR 25 learn codes ber with awgn  0.5025666666666666 learn codes ber with rayleigh  0.5025666666666666 learn codes ber with rician  0.5025666666666666 ber with awgn  0.0 ber with rayleigh  0.010649999999999998 ber with rician  0.0041
Test SNR 30 learn codes ber with awgn  0.4972333333333333 learn codes ber with rayleigh  0.4972333333333333 learn codes ber with rician  0.4972333333333333 ber with awgn  0.0 ber with rayleigh  0.0036000000000000003 ber with rician  0.00125
Test SNR 35 learn codes ber with awgn  0.49490000000000006 learn codes ber with rayleigh  0.49490000000000006 learn codes ber with rician  0.49490000000000006 ber with awgn  0.0 ber with rayleigh  0.0010250000000000003 ber with rician  0.00045
Test SNR 40 learn codes ber with awgn  0.5015666666666667 learn codes ber with rayleigh  0.5015666666666667 learn codes ber with rician  0.5015666666666667 ber with awgn  0.0 ber with rayleigh  0.000175 ber with rician  0.000175
Test SNR 45 learn codes ber with awgn  0.4954666666666667 learn codes ber with rayleigh  0.4954666666666667 learn codes ber with rician  0.4954666666666667 ber with awgn  0.0 ber with rayleigh  7.500000000000001e-05 ber with rician  2.5e-05
Test SNR 50 learn codes ber with awgn  0.4923666666666667 learn codes ber with rayleigh  0.4923666666666667 learn codes ber with rician  0.4923666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.4982666666666667 learn codes ber with rayleigh  0.4982666666666667 learn codes ber with rician  0.4982666666666667 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49993333333333334 learn codes ber with rayleigh  0.49993333333333334 learn codes ber with rician  0.49993333333333334 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4988 learn codes ber with rayleigh  0.4988 learn codes ber with rician  0.4988 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5079666666666667 learn codes ber with rayleigh  0.5079666666666667 learn codes ber with rician  0.5079666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5009333333333333 learn codes ber with rayleigh  0.5009333333333333 learn codes ber with rician  0.5009333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5013333333333334 learn codes ber with rayleigh  0.5013333333333334 learn codes ber with rician  0.5013333333333334 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5016333333333333 learn codes ber with rayleigh  0.5016333333333333 learn codes ber with rician  0.5016333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49623333333333336 learn codes ber with rayleigh  0.49623333333333336 learn codes ber with rician  0.49623333333333336 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4973333333333333 learn codes ber with rayleigh  0.4973333333333333 learn codes ber with rician  0.4973333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4997, 0.4950333333333334, 0.49413333333333326, 0.49176666666666663, 0.4991333333333333, 0.5025666666666666, 0.4972333333333333, 0.49490000000000006, 0.5015666666666667, 0.4954666666666667, 0.4923666666666667, 0.4982666666666667, 0.49993333333333334, 0.4988, 0.5079666666666667, 0.5009333333333333, 0.5013333333333334, 0.5016333333333333, 0.49623333333333336, 0.4973333333333333]
Learn Codes rayleigh [0.4997, 0.4950333333333334, 0.49413333333333326, 0.49176666666666663, 0.4991333333333333, 0.5025666666666666, 0.4972333333333333, 0.49490000000000006, 0.5015666666666667, 0.4954666666666667, 0.4923666666666667, 0.4982666666666667, 0.49993333333333334, 0.4988, 0.5079666666666667, 0.5009333333333333, 0.5013333333333334, 0.5016333333333333, 0.49623333333333336, 0.4973333333333333]
Learn Codes rician [0.4997, 0.4950333333333334, 0.49413333333333326, 0.49176666666666663, 0.4991333333333333, 0.5025666666666666, 0.4972333333333333, 0.49490000000000006, 0.5015666666666667, 0.4954666666666667, 0.4923666666666667, 0.4982666666666667, 0.49993333333333334, 0.4988, 0.5079666666666667, 0.5009333333333333, 0.5013333333333334, 0.5016333333333333, 0.49623333333333336, 0.4973333333333333]
AWGN [0.3755, 0.28475, 0.157875, 0.035699999999999996, 0.0007250000000000002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.400025, 0.30757500000000004, 0.1843, 0.0821, 0.030900000000000004, 0.010649999999999998, 0.0036000000000000003, 0.0010250000000000003, 0.000175, 7.500000000000001e-05, 0.0, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.392675, 0.29422499999999996, 0.160225, 0.05320000000000001, 0.015700000000000002, 0.0041, 0.00125, 0.00045, 0.000175, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69352126 loss Rayleigh: 0.69351274 loss Rician: 0.69340288   running time 6.4415602684021
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67581223 loss Rayleigh: 0.68257371 loss Rician: 0.67083883   running time 5.994174003601074
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65815927 loss Rayleigh: 0.66686782 loss Rician: 0.65974250   running time 5.920572996139526
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64588339 loss Rayleigh: 0.65605530 loss Rician: 0.64729347   running time 5.9298789501190186
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.63911687 loss Rayleigh: 0.64826436 loss Rician: 0.64013731   running time 5.949892520904541
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64599140 loss Rayleigh: 0.65353895 loss Rician: 0.64354860   running time 6.153561353683472
====> Test set BCE loss with SNR 0.0 for AWGN 0.6483713984489441 Custom Loss 0.6483713984489441 with ber  0.5031000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6524381041526794 Custom Loss 0.6524381041526794 with ber  0.5031000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6495906114578247 Custom Loss 0.6495906114578247 with ber  0.5031000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.307799339294434s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63856775 loss Rayleigh: 0.64371372 loss Rician: 0.63845565   running time 5.78207540512085
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62129057 loss Rayleigh: 0.63440195 loss Rician: 0.61792026   running time 5.967608213424683
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63392025 loss Rayleigh: 0.63196265 loss Rician: 0.62505860   running time 6.022342205047607
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62179629 loss Rayleigh: 0.61431524 loss Rician: 0.62821633   running time 5.926137685775757
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.66880579 loss Rayleigh: 0.63556615 loss Rician: 0.65687771   running time 5.974328517913818
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59966761 loss Rayleigh: 0.61645868 loss Rician: 0.60164619   running time 5.937695503234863
====> Test set BCE loss with SNR 0.0 for AWGN 0.5954399108886719 Custom Loss 0.5954399108886719 with ber  0.49779999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6038554906845093 Custom Loss 0.6038554906845093 with ber  0.49779999999999996 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5925554037094116 Custom Loss 0.5925554037094116 with ber  0.49779999999999996 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 37.46894145011902s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.58265675 loss Rayleigh: 0.59312083 loss Rician: 0.57986269   running time 5.956693172454834
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.56114362 loss Rayleigh: 0.57087181 loss Rician: 0.55841331   running time 5.965166807174683
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.55215472 loss Rayleigh: 0.56141087 loss Rician: 0.54999834   running time 5.885455131530762
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.55157629 loss Rayleigh: 0.56232960 loss Rician: 0.54971158   running time 6.398583650588989
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.55196718 loss Rayleigh: 0.55932351 loss Rician: 0.54662625   running time 5.967131853103638
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54688812 loss Rayleigh: 0.55218858 loss Rician: 0.54094206   running time 6.045890808105469
====> Test set BCE loss with SNR 0.0 for AWGN 0.5461674928665161 Custom Loss 0.5461674928665161 with ber  0.5005333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5513870120048523 Custom Loss 0.5513870120048523 with ber  0.5005333333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.541336178779602 Custom Loss 0.541336178779602 with ber  0.5005333333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.2476065158844s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53955268 loss Rayleigh: 0.54632918 loss Rician: 0.53560716   running time 5.819477319717407
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53131834 loss Rayleigh: 0.53578202 loss Rician: 0.52315745   running time 6.027504205703735
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.53365403 loss Rayleigh: 0.54131394 loss Rician: 0.52387626   running time 6.070448398590088
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52943785 loss Rayleigh: 0.53808914 loss Rician: 0.52467128   running time 6.088325500488281
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52612570 loss Rayleigh: 0.53388193 loss Rician: 0.51797938   running time 5.939013242721558
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52664314 loss Rayleigh: 0.53155286 loss Rician: 0.51599170   running time 5.911661624908447
====> Test set BCE loss with SNR 0.0 for AWGN 0.5232928991317749 Custom Loss 0.5232928991317749 with ber  0.4993666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5279791355133057 Custom Loss 0.5279791355133057 with ber  0.4993666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5154721140861511 Custom Loss 0.5154721140861511 with ber  0.4993666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 37.8417387008667s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.51477610 loss Rayleigh: 0.52156287 loss Rician: 0.50363534   running time 6.141248941421509
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50334100 loss Rayleigh: 0.51441655 loss Rician: 0.49351141   running time 5.9576945304870605
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50787985 loss Rayleigh: 0.52137401 loss Rician: 0.50319828   running time 5.936212778091431
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50433540 loss Rayleigh: 0.51337275 loss Rician: 0.49462986   running time 5.854219675064087
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50363664 loss Rayleigh: 0.51268451 loss Rician: 0.49353393   running time 6.098301649093628
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.49986802 loss Rayleigh: 0.51013728 loss Rician: 0.48678506   running time 6.037546396255493
====> Test set BCE loss with SNR 0.0 for AWGN 0.5033837556838989 Custom Loss 0.5033837556838989 with ber  0.5016 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5069175362586975 Custom Loss 0.5069175362586975 with ber  0.5016 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.48881202936172485 Custom Loss 0.48881202936172485 with ber  0.5016 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 37.8556706905365s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49644007 loss Rayleigh: 0.50673445 loss Rician: 0.48192492   running time 5.8285768032073975
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49097453 loss Rayleigh: 0.49975694 loss Rician: 0.47724687   running time 6.044097900390625
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49160202 loss Rayleigh: 0.49676429 loss Rician: 0.47779961   running time 6.042126655578613
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48856622 loss Rayleigh: 0.49759889 loss Rician: 0.47822673   running time 5.928661108016968
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48498345 loss Rayleigh: 0.49486242 loss Rician: 0.47692623   running time 5.994006395339966
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48486487 loss Rayleigh: 0.49693018 loss Rician: 0.47256251   running time 5.956552267074585
====> Test set BCE loss with SNR 0.0 for AWGN 0.48520627617836 Custom Loss 0.48520627617836 with ber  0.4973000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.4910547137260437 Custom Loss 0.4910547137260437 with ber  0.4973000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.4698152542114258 Custom Loss 0.4698152542114258 with ber  0.4973000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 37.85300040245056s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4986 learn codes ber with rayleigh  0.4986 learn codes ber with rician  0.4986 ber with awgn  0.43895 ber with rayleigh  0.452875 ber with rician  0.4528
Test SNR 5 learn codes ber with awgn  0.4972666666666667 learn codes ber with rayleigh  0.4972666666666667 learn codes ber with rician  0.4972666666666667 ber with awgn  0.39287500000000003 ber with rayleigh  0.4096 ber with rician  0.40725
Test SNR 10 learn codes ber with awgn  0.5043333333333334 learn codes ber with rayleigh  0.5043333333333334 learn codes ber with rician  0.5043333333333334 ber with awgn  0.31462500000000004 ber with rayleigh  0.332575 ber with rician  0.32412500000000005
Test SNR 15 learn codes ber with awgn  0.4994666666666667 learn codes ber with rayleigh  0.4994666666666667 learn codes ber with rician  0.4994666666666667 ber with awgn  0.19477499999999998 ber with rayleigh  0.21647500000000003 ber with rician  0.196075
Test SNR 20 learn codes ber with awgn  0.49986666666666685 learn codes ber with rayleigh  0.49986666666666685 learn codes ber with rician  0.49986666666666685 ber with awgn  0.061575000000000005 ber with rayleigh  0.1066 ber with rician  0.07505
Test SNR 25 learn codes ber with awgn  0.4997666666666666 learn codes ber with rayleigh  0.4997666666666666 learn codes ber with rician  0.4997666666666666 ber with awgn  0.003075 ber with rayleigh  0.0411 ber with rician  0.021599999999999998
Test SNR 30 learn codes ber with awgn  0.4951 learn codes ber with rayleigh  0.4951 learn codes ber with rician  0.4951 ber with awgn  0.0 ber with rayleigh  0.013099999999999997 ber with rician  0.006775000000000001
Test SNR 35 learn codes ber with awgn  0.4991 learn codes ber with rayleigh  0.4991 learn codes ber with rician  0.4991 ber with awgn  0.0 ber with rayleigh  0.00355 ber with rician  0.0015
Test SNR 40 learn codes ber with awgn  0.5 learn codes ber with rayleigh  0.5 learn codes ber with rician  0.5 ber with awgn  0.0 ber with rayleigh  0.0013 ber with rician  0.00042500000000000003
Test SNR 45 learn codes ber with awgn  0.49139999999999995 learn codes ber with rayleigh  0.49139999999999995 learn codes ber with rician  0.49139999999999995 ber with awgn  0.0 ber with rayleigh  0.0005000000000000001 ber with rician  0.00025000000000000006
Test SNR 50 learn codes ber with awgn  0.5018 learn codes ber with rayleigh  0.5018 learn codes ber with rician  0.5018 ber with awgn  0.0 ber with rayleigh  0.000125 ber with rician  5e-05
Test SNR 55 learn codes ber with awgn  0.49733333333333335 learn codes ber with rayleigh  0.49733333333333335 learn codes ber with rician  0.49733333333333335 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  2.5e-05
Test SNR 60 learn codes ber with awgn  0.4971 learn codes ber with rayleigh  0.4971 learn codes ber with rician  0.4971 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5029666666666667 learn codes ber with rayleigh  0.5029666666666667 learn codes ber with rician  0.5029666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5013666666666666 learn codes ber with rayleigh  0.5013666666666666 learn codes ber with rician  0.5013666666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49820000000000003 learn codes ber with rayleigh  0.49820000000000003 learn codes ber with rician  0.49820000000000003 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5009666666666668 learn codes ber with rayleigh  0.5009666666666668 learn codes ber with rician  0.5009666666666668 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5025666666666667 learn codes ber with rayleigh  0.5025666666666667 learn codes ber with rician  0.5025666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5027666666666667 learn codes ber with rayleigh  0.5027666666666667 learn codes ber with rician  0.5027666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5004333333333333 learn codes ber with rayleigh  0.5004333333333333 learn codes ber with rician  0.5004333333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4986, 0.4972666666666667, 0.5043333333333334, 0.4994666666666667, 0.49986666666666685, 0.4997666666666666, 0.4951, 0.4991, 0.5, 0.49139999999999995, 0.5018, 0.49733333333333335, 0.4971, 0.5029666666666667, 0.5013666666666666, 0.49820000000000003, 0.5009666666666668, 0.5025666666666667, 0.5027666666666667, 0.5004333333333333]
Learn Codes rayleigh [0.4986, 0.4972666666666667, 0.5043333333333334, 0.4994666666666667, 0.49986666666666685, 0.4997666666666666, 0.4951, 0.4991, 0.5, 0.49139999999999995, 0.5018, 0.49733333333333335, 0.4971, 0.5029666666666667, 0.5013666666666666, 0.49820000000000003, 0.5009666666666668, 0.5025666666666667, 0.5027666666666667, 0.5004333333333333]
Learn Codes rician [0.4986, 0.4972666666666667, 0.5043333333333334, 0.4994666666666667, 0.49986666666666685, 0.4997666666666666, 0.4951, 0.4991, 0.5, 0.49139999999999995, 0.5018, 0.49733333333333335, 0.4971, 0.5029666666666667, 0.5013666666666666, 0.49820000000000003, 0.5009666666666668, 0.5025666666666667, 0.5027666666666667, 0.5004333333333333]
AWGN [0.43895, 0.39287500000000003, 0.31462500000000004, 0.19477499999999998, 0.061575000000000005, 0.003075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.452875, 0.4096, 0.332575, 0.21647500000000003, 0.1066, 0.0411, 0.013099999999999997, 0.00355, 0.0013, 0.0005000000000000001, 0.000125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4528, 0.40725, 0.32412500000000005, 0.196075, 0.07505, 0.021599999999999998, 0.006775000000000001, 0.0015, 0.00042500000000000003, 0.00025000000000000006, 5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69301874 loss Rayleigh: 0.69298073 loss Rician: 0.69298791   running time 5.972597599029541
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66572793 loss Rayleigh: 0.66443695 loss Rician: 0.65977041   running time 6.054439306259155
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65769702 loss Rayleigh: 0.66500089 loss Rician: 0.64548810   running time 5.944534778594971
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65738521 loss Rayleigh: 0.65930435 loss Rician: 0.65869557   running time 5.93444299697876
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.62895308 loss Rayleigh: 0.64086421 loss Rician: 0.62879769   running time 6.081458568572998
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.62648175 loss Rayleigh: 0.63478983 loss Rician: 0.62355118   running time 5.98853063583374
====> Test set BCE loss with SNR 0.0 for AWGN 0.6247528195381165 Custom Loss 0.6247528195381165 with ber  0.49802 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6345006227493286 Custom Loss 0.6345006227493286 with ber  0.49802 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6223961710929871 Custom Loss 0.6223961710929871 with ber  0.49802 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.79400157928467s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62467254 loss Rayleigh: 0.63156880 loss Rician: 0.62141609   running time 5.8309855461120605
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62003459 loss Rayleigh: 0.63012398 loss Rician: 0.61906983   running time 6.045546531677246
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62120495 loss Rayleigh: 0.62724152 loss Rician: 0.61851440   running time 5.968271970748901
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61939193 loss Rayleigh: 0.62654552 loss Rician: 0.61715401   running time 6.064071178436279
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61594931 loss Rayleigh: 0.62316681 loss Rician: 0.61464396   running time 5.95342755317688
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61768437 loss Rayleigh: 0.62413371 loss Rician: 0.61417100   running time 5.931688547134399
====> Test set BCE loss with SNR 0.0 for AWGN 0.6141597032546997 Custom Loss 0.6141597032546997 with ber  0.49788 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.620915412902832 Custom Loss 0.620915412902832 with ber  0.49788 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6105645298957825 Custom Loss 0.6105645298957825 with ber  0.49788 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.80848479270935s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.61506652 loss Rayleigh: 0.62101681 loss Rician: 0.61169321   running time 5.881544351577759
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60848475 loss Rayleigh: 0.61449965 loss Rician: 0.60607461   running time 5.9850914478302
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60651388 loss Rayleigh: 0.61364331 loss Rician: 0.60360799   running time 5.9425976276397705
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60575696 loss Rayleigh: 0.61128896 loss Rician: 0.60237561   running time 6.037450790405273
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60481979 loss Rayleigh: 0.61092852 loss Rician: 0.60109268   running time 6.019830226898193
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60461554 loss Rayleigh: 0.61002160 loss Rician: 0.60093591   running time 6.117898464202881
====> Test set BCE loss with SNR 0.0 for AWGN 0.6022168397903442 Custom Loss 0.6022168397903442 with ber  0.49778 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.606360137462616 Custom Loss 0.606360137462616 with ber  0.49778 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5975622534751892 Custom Loss 0.5975622534751892 with ber  0.49778 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.83582663536072s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59954423 loss Rayleigh: 0.60391375 loss Rician: 0.59670886   running time 5.855686187744141
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59210752 loss Rayleigh: 0.59872755 loss Rician: 0.58861687   running time 6.0816028118133545
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59143901 loss Rayleigh: 0.59731299 loss Rician: 0.58478066   running time 5.993579149246216
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59137623 loss Rayleigh: 0.59671823 loss Rician: 0.58609740   running time 5.904343605041504
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58530511 loss Rayleigh: 0.59444395 loss Rician: 0.57934827   running time 5.928014278411865
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58432564 loss Rayleigh: 0.59027264 loss Rician: 0.57687907   running time 6.017489671707153
====> Test set BCE loss with SNR 0.0 for AWGN 0.5868834853172302 Custom Loss 0.5868834853172302 with ber  0.5042000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5901972651481628 Custom Loss 0.5901972651481628 with ber  0.5042000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.580388069152832 Custom Loss 0.580388069152832 with ber  0.5042000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.828622341156006s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57488204 loss Rayleigh: 0.58042748 loss Rician: 0.56840467   running time 5.843950986862183
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.56492986 loss Rayleigh: 0.57424101 loss Rician: 0.55674683   running time 6.017773151397705
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.56613613 loss Rayleigh: 0.57477810 loss Rician: 0.55271698   running time 6.0219268798828125
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55952063 loss Rayleigh: 0.56964236 loss Rician: 0.54838330   running time 6.153995037078857
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55786627 loss Rayleigh: 0.56814574 loss Rician: 0.54873044   running time 6.058777332305908
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.56359762 loss Rayleigh: 0.56777846 loss Rician: 0.55063512   running time 6.018193244934082
====> Test set BCE loss with SNR 0.0 for AWGN 0.5612696409225464 Custom Loss 0.5612696409225464 with ber  0.5017 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5671752691268921 Custom Loss 0.5671752691268921 with ber  0.5017 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5508686304092407 Custom Loss 0.5508686304092407 with ber  0.5017 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.00842785835266s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56225432 loss Rayleigh: 0.56920332 loss Rician: 0.55341763   running time 5.970300674438477
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56092998 loss Rayleigh: 0.56488551 loss Rician: 0.54770980   running time 6.055516242980957
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55756617 loss Rayleigh: 0.56230546 loss Rician: 0.54322935   running time 5.9571404457092285
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56301535 loss Rayleigh: 0.56950591 loss Rician: 0.55032746   running time 5.9512553215026855
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56144723 loss Rayleigh: 0.56575193 loss Rician: 0.54308997   running time 5.952953100204468
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55772140 loss Rayleigh: 0.56108675 loss Rician: 0.54091755   running time 6.080173015594482
====> Test set BCE loss with SNR 0.0 for AWGN 0.5608636140823364 Custom Loss 0.5608636140823364 with ber  0.50302 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.560466468334198 Custom Loss 0.560466468334198 with ber  0.50302 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.542091965675354 Custom Loss 0.542091965675354 with ber  0.50302 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 37.87964582443237s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49892000000000003 learn codes ber with rayleigh  0.49892000000000003 learn codes ber with rician  0.49892000000000003 ber with awgn  0.37498333333333334 ber with rayleigh  0.3925333333333333 ber with rician  0.3936
Test SNR 5 learn codes ber with awgn  0.4986 learn codes ber with rayleigh  0.4986 learn codes ber with rician  0.4986 ber with awgn  0.28661666666666663 ber with rayleigh  0.3098666666666667 ber with rician  0.2863
Test SNR 10 learn codes ber with awgn  0.50166 learn codes ber with rayleigh  0.50166 learn codes ber with rician  0.50166 ber with awgn  0.15911666666666666 ber with rayleigh  0.18445 ber with rician  0.14676666666666666
Test SNR 15 learn codes ber with awgn  0.49806 learn codes ber with rayleigh  0.49806 learn codes ber with rician  0.49806 ber with awgn  0.03668333333333333 ber with rayleigh  0.08316666666666667 ber with rician  0.04605
Test SNR 20 learn codes ber with awgn  0.4969 learn codes ber with rayleigh  0.4969 learn codes ber with rician  0.4969 ber with awgn  0.0008333333333333335 ber with rayleigh  0.030466666666666663 ber with rician  0.0093
Test SNR 25 learn codes ber with awgn  0.5010199999999999 learn codes ber with rayleigh  0.5010199999999999 learn codes ber with rician  0.5010199999999999 ber with awgn  0.0 ber with rayleigh  0.0097 ber with rician  0.0024
Test SNR 30 learn codes ber with awgn  0.5001800000000001 learn codes ber with rayleigh  0.5001800000000001 learn codes ber with rician  0.5001800000000001 ber with awgn  0.0 ber with rayleigh  0.0031166666666666665 ber with rician  0.0008500000000000001
Test SNR 35 learn codes ber with awgn  0.49978 learn codes ber with rayleigh  0.49978 learn codes ber with rician  0.49978 ber with awgn  0.0 ber with rayleigh  0.0008333333333333335 ber with rician  0.0001
Test SNR 40 learn codes ber with awgn  0.50004 learn codes ber with rayleigh  0.50004 learn codes ber with rician  0.50004 ber with awgn  0.0 ber with rayleigh  0.00045 ber with rician  3.3333333333333335e-05
Test SNR 45 learn codes ber with awgn  0.4994200000000001 learn codes ber with rayleigh  0.4994200000000001 learn codes ber with rician  0.4994200000000001 ber with awgn  0.0 ber with rayleigh  0.00013333333333333334 ber with rician  3.3333333333333335e-05
Test SNR 50 learn codes ber with awgn  0.5003799999999999 learn codes ber with rayleigh  0.5003799999999999 learn codes ber with rician  0.5003799999999999 ber with awgn  0.0 ber with rayleigh  1.6666666666666667e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.4987399999999999 learn codes ber with rayleigh  0.4987399999999999 learn codes ber with rician  0.4987399999999999 ber with awgn  0.0 ber with rayleigh  1.6666666666666667e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49773999999999996 learn codes ber with rayleigh  0.49773999999999996 learn codes ber with rician  0.49773999999999996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.49868000000000007 learn codes ber with rayleigh  0.49868000000000007 learn codes ber with rician  0.49868000000000007 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49860000000000004 learn codes ber with rayleigh  0.49860000000000004 learn codes ber with rician  0.49860000000000004 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.4963 learn codes ber with rayleigh  0.4963 learn codes ber with rician  0.4963 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49846 learn codes ber with rayleigh  0.49846 learn codes ber with rician  0.49846 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49368 learn codes ber with rayleigh  0.49368 learn codes ber with rician  0.49368 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5002800000000001 learn codes ber with rayleigh  0.5002800000000001 learn codes ber with rician  0.5002800000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49948 learn codes ber with rayleigh  0.49948 learn codes ber with rician  0.49948 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49892000000000003, 0.4986, 0.50166, 0.49806, 0.4969, 0.5010199999999999, 0.5001800000000001, 0.49978, 0.50004, 0.4994200000000001, 0.5003799999999999, 0.4987399999999999, 0.49773999999999996, 0.49868000000000007, 0.49860000000000004, 0.4963, 0.49846, 0.49368, 0.5002800000000001, 0.49948]
Learn Codes rayleigh [0.49892000000000003, 0.4986, 0.50166, 0.49806, 0.4969, 0.5010199999999999, 0.5001800000000001, 0.49978, 0.50004, 0.4994200000000001, 0.5003799999999999, 0.4987399999999999, 0.49773999999999996, 0.49868000000000007, 0.49860000000000004, 0.4963, 0.49846, 0.49368, 0.5002800000000001, 0.49948]
Learn Codes rician [0.49892000000000003, 0.4986, 0.50166, 0.49806, 0.4969, 0.5010199999999999, 0.5001800000000001, 0.49978, 0.50004, 0.4994200000000001, 0.5003799999999999, 0.4987399999999999, 0.49773999999999996, 0.49868000000000007, 0.49860000000000004, 0.4963, 0.49846, 0.49368, 0.5002800000000001, 0.49948]
AWGN [0.37498333333333334, 0.28661666666666663, 0.15911666666666666, 0.03668333333333333, 0.0008333333333333335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3925333333333333, 0.3098666666666667, 0.18445, 0.08316666666666667, 0.030466666666666663, 0.0097, 0.0031166666666666665, 0.0008333333333333335, 0.00045, 0.00013333333333333334, 1.6666666666666667e-05, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3936, 0.2863, 0.14676666666666666, 0.04605, 0.0093, 0.0024, 0.0008500000000000001, 0.0001, 3.3333333333333335e-05, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69306485 loss Rayleigh: 0.69306366 loss Rician: 0.69303791   running time 5.883584499359131
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66292239 loss Rayleigh: 0.66652741 loss Rician: 0.65765768   running time 6.0298097133636475
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64012989 loss Rayleigh: 0.65202679 loss Rician: 0.63789917   running time 6.113197565078735
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64537565 loss Rayleigh: 0.65903677 loss Rician: 0.63179578   running time 6.0951337814331055
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64152664 loss Rayleigh: 0.64323162 loss Rician: 0.62852136   running time 5.981888771057129
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.62149646 loss Rayleigh: 0.63174997 loss Rician: 0.61894973   running time 6.048771619796753
====> Test set BCE loss with SNR 0.0 for AWGN 0.6235740184783936 Custom Loss 0.6235740184783936 with ber  0.50154 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6318349838256836 Custom Loss 0.6318349838256836 with ber  0.50154 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6238138675689697 Custom Loss 0.6238138675689697 with ber  0.50154 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.205859899520874s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62180404 loss Rayleigh: 0.62969579 loss Rician: 0.62150055   running time 6.016262531280518
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60703802 loss Rayleigh: 0.61825392 loss Rician: 0.60610353   running time 6.008058547973633
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60451172 loss Rayleigh: 0.61746672 loss Rician: 0.60446392   running time 5.943262338638306
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60668226 loss Rayleigh: 0.61665571 loss Rician: 0.60556465   running time 6.080286502838135
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60358410 loss Rayleigh: 0.61455919 loss Rician: 0.60269626   running time 6.039889335632324
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60191024 loss Rayleigh: 0.61283200 loss Rician: 0.60098207   running time 6.065874814987183
====> Test set BCE loss with SNR 0.0 for AWGN 0.6020299196243286 Custom Loss 0.6020299196243286 with ber  0.5026799999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6108938455581665 Custom Loss 0.6108938455581665 with ber  0.5026799999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6000259518623352 Custom Loss 0.6000259518623352 with ber  0.5026799999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.028964042663574s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59959217 loss Rayleigh: 0.60776327 loss Rician: 0.59811797   running time 5.956341505050659
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59471115 loss Rayleigh: 0.60640970 loss Rician: 0.59320859   running time 6.087255239486694
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59144601 loss Rayleigh: 0.60226285 loss Rician: 0.58797795   running time 6.098655462265015
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59345569 loss Rayleigh: 0.60308001 loss Rician: 0.59123710   running time 6.000133514404297
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.58919991 loss Rayleigh: 0.59869704 loss Rician: 0.58581203   running time 6.004701852798462
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59632994 loss Rayleigh: 0.60447778 loss Rician: 0.59243552   running time 6.16762638092041
====> Test set BCE loss with SNR 0.0 for AWGN 0.5920414924621582 Custom Loss 0.5920414924621582 with ber  0.4957999999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5980267524719238 Custom Loss 0.5980267524719238 with ber  0.4957999999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5879920125007629 Custom Loss 0.5879920125007629 with ber  0.4957999999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.24152612686157s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59322023 loss Rayleigh: 0.59910273 loss Rician: 0.58852139   running time 5.909611463546753
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58505167 loss Rayleigh: 0.59177892 loss Rician: 0.57951781   running time 5.985880136489868
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58343328 loss Rayleigh: 0.59086952 loss Rician: 0.57819065   running time 6.11974310874939
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58680298 loss Rayleigh: 0.59281112 loss Rician: 0.57933959   running time 6.098494052886963
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58807168 loss Rayleigh: 0.59581174 loss Rician: 0.58152351   running time 6.0342419147491455
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58817834 loss Rayleigh: 0.59588030 loss Rician: 0.58029480   running time 5.980886936187744
====> Test set BCE loss with SNR 0.0 for AWGN 0.5803161859512329 Custom Loss 0.5803161859512329 with ber  0.5007400000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5882287621498108 Custom Loss 0.5882287621498108 with ber  0.5007400000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5725682377815247 Custom Loss 0.5725682377815247 with ber  0.5007400000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.183369636535645s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57885163 loss Rayleigh: 0.58794099 loss Rician: 0.57058723   running time 6.012527227401733
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57652401 loss Rayleigh: 0.58708829 loss Rician: 0.56867610   running time 6.014093399047852
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58033016 loss Rayleigh: 0.58871861 loss Rician: 0.56866876   running time 6.008263826370239
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57164991 loss Rayleigh: 0.58151482 loss Rician: 0.55925824   running time 5.998360633850098
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57497552 loss Rayleigh: 0.58164009 loss Rician: 0.56247436   running time 6.191969394683838
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57404599 loss Rayleigh: 0.58032722 loss Rician: 0.56535242   running time 6.0437843799591064
====> Test set BCE loss with SNR 0.0 for AWGN 0.5658561587333679 Custom Loss 0.5658561587333679 with ber  0.49750000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5754636526107788 Custom Loss 0.5754636526107788 with ber  0.49750000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5540803074836731 Custom Loss 0.5540803074836731 with ber  0.49750000000000005 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.15187644958496s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56477952 loss Rayleigh: 0.57417169 loss Rician: 0.55269356   running time 5.869975328445435
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55700416 loss Rayleigh: 0.56859739 loss Rician: 0.54462071   running time 6.171543121337891
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55780308 loss Rayleigh: 0.56588557 loss Rician: 0.54296846   running time 6.062661647796631
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56503217 loss Rayleigh: 0.56927470 loss Rician: 0.54813426   running time 5.993185520172119
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55664926 loss Rayleigh: 0.56849725 loss Rician: 0.54193797   running time 5.99075984954834
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55165175 loss Rayleigh: 0.56004375 loss Rician: 0.53517109   running time 5.991376876831055
====> Test set BCE loss with SNR 0.0 for AWGN 0.560465931892395 Custom Loss 0.560465931892395 with ber  0.49766000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.567489743232727 Custom Loss 0.567489743232727 with ber  0.49766000000000005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5435630083084106 Custom Loss 0.5435630083084106 with ber  0.49766000000000005 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.15709948539734s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4985799999999999 learn codes ber with rayleigh  0.4985799999999999 learn codes ber with rician  0.4985799999999999 ber with awgn  0.43689999999999996 ber with rayleigh  0.45251666666666673 ber with rician  0.454
Test SNR 5 learn codes ber with awgn  0.50202 learn codes ber with rayleigh  0.50202 learn codes ber with rician  0.50202 ber with awgn  0.38616666666666666 ber with rayleigh  0.41285000000000005 ber with rician  0.4075666666666667
Test SNR 10 learn codes ber with awgn  0.50164 learn codes ber with rayleigh  0.50164 learn codes ber with rician  0.50164 ber with awgn  0.3112666666666667 ber with rayleigh  0.3383166666666667 ber with rician  0.31858333333333333
Test SNR 15 learn codes ber with awgn  0.49552000000000007 learn codes ber with rayleigh  0.49552000000000007 learn codes ber with rician  0.49552000000000007 ber with awgn  0.19391666666666665 ber with rayleigh  0.21486666666666668 ber with rician  0.1846833333333333
Test SNR 20 learn codes ber with awgn  0.5038199999999999 learn codes ber with rayleigh  0.5038199999999999 learn codes ber with rician  0.5038199999999999 ber with awgn  0.05934999999999999 ber with rayleigh  0.10226666666666666 ber with rician  0.06298333333333334
Test SNR 25 learn codes ber with awgn  0.50214 learn codes ber with rayleigh  0.50214 learn codes ber with rician  0.50214 ber with awgn  0.0030999999999999995 ber with rayleigh  0.040616666666666676 ber with rician  0.013866666666666666
Test SNR 30 learn codes ber with awgn  0.50206 learn codes ber with rayleigh  0.50206 learn codes ber with rician  0.50206 ber with awgn  0.0 ber with rayleigh  0.013099999999999997 ber with rician  0.0030499999999999998
Test SNR 35 learn codes ber with awgn  0.5 learn codes ber with rayleigh  0.5 learn codes ber with rician  0.5 ber with awgn  0.0 ber with rayleigh  0.004566666666666666 ber with rician  0.0009666666666666667
Test SNR 40 learn codes ber with awgn  0.50374 learn codes ber with rayleigh  0.50374 learn codes ber with rician  0.50374 ber with awgn  0.0 ber with rayleigh  0.00125 ber with rician  0.0001666666666666667
Test SNR 45 learn codes ber with awgn  0.50224 learn codes ber with rayleigh  0.50224 learn codes ber with rician  0.50224 ber with awgn  0.0 ber with rayleigh  0.0005833333333333333 ber with rician  6.666666666666667e-05
Test SNR 50 learn codes ber with awgn  0.50266 learn codes ber with rayleigh  0.50266 learn codes ber with rician  0.50266 ber with awgn  0.0 ber with rayleigh  0.0001 ber with rician  1.6666666666666667e-05
Test SNR 55 learn codes ber with awgn  0.49654 learn codes ber with rayleigh  0.49654 learn codes ber with rician  0.49654 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  1.6666666666666667e-05
Test SNR 60 learn codes ber with awgn  0.5058999999999999 learn codes ber with rayleigh  0.5058999999999999 learn codes ber with rician  0.5058999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5008999999999999 learn codes ber with rayleigh  0.5008999999999999 learn codes ber with rician  0.5008999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49978 learn codes ber with rayleigh  0.49978 learn codes ber with rician  0.49978 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  1.6666666666666667e-05
Test SNR 75 learn codes ber with awgn  0.49917999999999996 learn codes ber with rayleigh  0.49917999999999996 learn codes ber with rician  0.49917999999999996 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4964200000000001 learn codes ber with rayleigh  0.4964200000000001 learn codes ber with rician  0.4964200000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49670000000000003 learn codes ber with rayleigh  0.49670000000000003 learn codes ber with rician  0.49670000000000003 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.50102 learn codes ber with rayleigh  0.50102 learn codes ber with rician  0.50102 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.50256 learn codes ber with rayleigh  0.50256 learn codes ber with rician  0.50256 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4985799999999999, 0.50202, 0.50164, 0.49552000000000007, 0.5038199999999999, 0.50214, 0.50206, 0.5, 0.50374, 0.50224, 0.50266, 0.49654, 0.5058999999999999, 0.5008999999999999, 0.49978, 0.49917999999999996, 0.4964200000000001, 0.49670000000000003, 0.50102, 0.50256]
Learn Codes rayleigh [0.4985799999999999, 0.50202, 0.50164, 0.49552000000000007, 0.5038199999999999, 0.50214, 0.50206, 0.5, 0.50374, 0.50224, 0.50266, 0.49654, 0.5058999999999999, 0.5008999999999999, 0.49978, 0.49917999999999996, 0.4964200000000001, 0.49670000000000003, 0.50102, 0.50256]
Learn Codes rician [0.4985799999999999, 0.50202, 0.50164, 0.49552000000000007, 0.5038199999999999, 0.50214, 0.50206, 0.5, 0.50374, 0.50224, 0.50266, 0.49654, 0.5058999999999999, 0.5008999999999999, 0.49978, 0.49917999999999996, 0.4964200000000001, 0.49670000000000003, 0.50102, 0.50256]
AWGN [0.43689999999999996, 0.38616666666666666, 0.3112666666666667, 0.19391666666666665, 0.05934999999999999, 0.0030999999999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45251666666666673, 0.41285000000000005, 0.3383166666666667, 0.21486666666666668, 0.10226666666666666, 0.040616666666666676, 0.013099999999999997, 0.004566666666666666, 0.00125, 0.0005833333333333333, 0.0001, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.454, 0.4075666666666667, 0.31858333333333333, 0.1846833333333333, 0.06298333333333334, 0.013866666666666666, 0.0030499999999999998, 0.0009666666666666667, 0.0001666666666666667, 6.666666666666667e-05, 1.6666666666666667e-05, 1.6666666666666667e-05, 0.0, 0.0, 1.6666666666666667e-05, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69316590 loss Rayleigh: 0.69316989 loss Rician: 0.69309248   running time 6.083164215087891
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67964140 loss Rayleigh: 0.68091983 loss Rician: 0.67254660   running time 6.108497142791748
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66619291 loss Rayleigh: 0.66762215 loss Rician: 0.66257185   running time 6.088006496429443
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67053328 loss Rayleigh: 0.66975445 loss Rician: 0.66303178   running time 6.054661750793457
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65282680 loss Rayleigh: 0.66136921 loss Rician: 0.64968145   running time 6.079600811004639
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65182248 loss Rayleigh: 0.65861949 loss Rician: 0.64949331   running time 6.1072916984558105
====> Test set BCE loss with SNR 0.0 for AWGN 0.6485272645950317 Custom Loss 0.6485272645950317 with ber  0.5013714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6546998023986816 Custom Loss 0.6546998023986816 with ber  0.5013714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6472253203392029 Custom Loss 0.6472253203392029 with ber  0.5013714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.47911548614502s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.64717191 loss Rayleigh: 0.65155269 loss Rician: 0.64531276   running time 5.864360094070435
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.64282023 loss Rayleigh: 0.64952362 loss Rician: 0.63952071   running time 6.01784610748291
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63869860 loss Rayleigh: 0.64534567 loss Rician: 0.63610603   running time 6.134990215301514
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63799295 loss Rayleigh: 0.64367362 loss Rician: 0.63542145   running time 6.059817314147949
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63733495 loss Rayleigh: 0.64304656 loss Rician: 0.63459049   running time 6.04498553276062
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63852558 loss Rayleigh: 0.64277860 loss Rician: 0.63533694   running time 6.013181209564209
====> Test set BCE loss with SNR 0.0 for AWGN 0.6363345384597778 Custom Loss 0.6363345384597778 with ber  0.5029857142857141 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6425163745880127 Custom Loss 0.6425163745880127 with ber  0.5029857142857141 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6338362693786621 Custom Loss 0.6338362693786621 with ber  0.5029857142857141 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.131948947906494s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63552911 loss Rayleigh: 0.64013335 loss Rician: 0.63199039   running time 5.985668420791626
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63390391 loss Rayleigh: 0.63886023 loss Rician: 0.63013888   running time 6.347471714019775
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63384243 loss Rayleigh: 0.63849469 loss Rician: 0.62972002   running time 6.100306987762451
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63072540 loss Rayleigh: 0.63580364 loss Rician: 0.62821246   running time 6.115954637527466
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63164753 loss Rayleigh: 0.63571944 loss Rician: 0.62767602   running time 6.078418970108032
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.63162924 loss Rayleigh: 0.63555115 loss Rician: 0.62818471   running time 6.0717527866363525
====> Test set BCE loss with SNR 0.0 for AWGN 0.6321492195129395 Custom Loss 0.6321492195129395 with ber  0.5019142857142858 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6352235674858093 Custom Loss 0.6352235674858093 with ber  0.5019142857142858 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6273804306983948 Custom Loss 0.6273804306983948 with ber  0.5019142857142858 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.54418325424194s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.62635470 loss Rayleigh: 0.63071338 loss Rician: 0.62285033   running time 6.052891492843628
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.62236997 loss Rayleigh: 0.62666883 loss Rician: 0.61762422   running time 6.141817092895508
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.61841894 loss Rayleigh: 0.62559134 loss Rician: 0.61513355   running time 6.03562068939209
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.61959541 loss Rayleigh: 0.62571337 loss Rician: 0.61590018   running time 6.021705389022827
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.61814367 loss Rayleigh: 0.62233944 loss Rician: 0.61275626   running time 6.026621580123901
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.61879763 loss Rayleigh: 0.62437213 loss Rician: 0.61297413   running time 6.150010347366333
====> Test set BCE loss with SNR 0.0 for AWGN 0.6280667781829834 Custom Loss 0.6280667781829834 with ber  0.49667142857142854 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6332181096076965 Custom Loss 0.6332181096076965 with ber  0.49667142857142854 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6236159801483154 Custom Loss 0.6236159801483154 with ber  0.49667142857142854 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.39764046669006s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.62185222 loss Rayleigh: 0.62682369 loss Rician: 0.61623735   running time 5.878536224365234
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.60571417 loss Rayleigh: 0.61396979 loss Rician: 0.59760220   running time 5.990908145904541
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.60074024 loss Rayleigh: 0.61140912 loss Rician: 0.59224830   running time 6.208287000656128
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.59712027 loss Rayleigh: 0.60713266 loss Rician: 0.58720861   running time 6.037414789199829
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.59911476 loss Rayleigh: 0.60865700 loss Rician: 0.58790852   running time 5.984306573867798
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.59791384 loss Rayleigh: 0.60736260 loss Rician: 0.58965387   running time 6.003133296966553
====> Test set BCE loss with SNR 0.0 for AWGN 0.5989153981208801 Custom Loss 0.5989153981208801 with ber  0.4959571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6082433462142944 Custom Loss 0.6082433462142944 with ber  0.4959571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5899621248245239 Custom Loss 0.5899621248245239 with ber  0.4959571428571429 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.11659121513367s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.60001816 loss Rayleigh: 0.60967070 loss Rician: 0.59037918   running time 5.992979526519775
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59285281 loss Rayleigh: 0.60324873 loss Rician: 0.57996284   running time 6.061703443527222
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59071895 loss Rayleigh: 0.60150284 loss Rician: 0.57618276   running time 5.999298095703125
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58708148 loss Rayleigh: 0.59792085 loss Rician: 0.57156652   running time 5.988789319992065
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58565429 loss Rayleigh: 0.59729578 loss Rician: 0.56944400   running time 6.183191537857056
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58816895 loss Rayleigh: 0.59758535 loss Rician: 0.57560269   running time 6.119443416595459
====> Test set BCE loss with SNR 0.0 for AWGN 0.6006608605384827 Custom Loss 0.6006608605384827 with ber  0.5002142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6096999645233154 Custom Loss 0.6096999645233154 with ber  0.5002142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5854912996292114 Custom Loss 0.5854912996292114 with ber  0.5002142857142857 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 38.225170612335205s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5029142857142858 learn codes ber with rayleigh  0.5029142857142858 learn codes ber with rician  0.5029142857142858 ber with awgn  0.3769875 ber with rayleigh  0.39556250000000004 ber with rician  0.3879625
Test SNR 5 learn codes ber with awgn  0.49998571428571437 learn codes ber with rayleigh  0.49998571428571437 learn codes ber with rician  0.49998571428571437 ber with awgn  0.2884875 ber with rayleigh  0.307025 ber with rician  0.28361250000000005
Test SNR 10 learn codes ber with awgn  0.4992285714285713 learn codes ber with rayleigh  0.4992285714285713 learn codes ber with rician  0.4992285714285713 ber with awgn  0.1575125 ber with rayleigh  0.184775 ber with rician  0.1419875
Test SNR 15 learn codes ber with awgn  0.49994285714285713 learn codes ber with rayleigh  0.49994285714285713 learn codes ber with rician  0.49994285714285713 ber with awgn  0.038375 ber with rayleigh  0.0831875 ber with rician  0.03305
Test SNR 20 learn codes ber with awgn  0.4995142857142857 learn codes ber with rayleigh  0.4995142857142857 learn codes ber with rician  0.4995142857142857 ber with awgn  0.000825 ber with rayleigh  0.030912500000000002 ber with rician  0.0046375
Test SNR 25 learn codes ber with awgn  0.5002714285714286 learn codes ber with rayleigh  0.5002714285714286 learn codes ber with rician  0.5002714285714286 ber with awgn  0.0 ber with rayleigh  0.010849999999999997 ber with rician  0.0008125000000000001
Test SNR 30 learn codes ber with awgn  0.5009857142857143 learn codes ber with rayleigh  0.5009857142857143 learn codes ber with rician  0.5009857142857143 ber with awgn  0.0 ber with rayleigh  0.0034375000000000005 ber with rician  0.00013749999999999998
Test SNR 35 learn codes ber with awgn  0.5007142857142857 learn codes ber with rayleigh  0.5007142857142857 learn codes ber with rician  0.5007142857142857 ber with awgn  0.0 ber with rayleigh  0.0009125000000000001 ber with rician  3.7500000000000003e-05
Test SNR 40 learn codes ber with awgn  0.5018999999999999 learn codes ber with rayleigh  0.5018999999999999 learn codes ber with rician  0.5018999999999999 ber with awgn  0.0 ber with rayleigh  0.0002875 ber with rician  2.5e-05
Test SNR 45 learn codes ber with awgn  0.4996428571428571 learn codes ber with rayleigh  0.4996428571428571 learn codes ber with rician  0.4996428571428571 ber with awgn  0.0 ber with rayleigh  0.00015000000000000001 ber with rician  1.25e-05
Test SNR 50 learn codes ber with awgn  0.5011714285714285 learn codes ber with rayleigh  0.5011714285714285 learn codes ber with rician  0.5011714285714285 ber with awgn  0.0 ber with rayleigh  6.25e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5013142857142857 learn codes ber with rayleigh  0.5013142857142857 learn codes ber with rician  0.5013142857142857 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.5000571428571428 learn codes ber with rayleigh  0.5000571428571428 learn codes ber with rician  0.5000571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5047285714285714 learn codes ber with rayleigh  0.5047285714285714 learn codes ber with rician  0.5047285714285714 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49927142857142853 learn codes ber with rayleigh  0.49927142857142853 learn codes ber with rician  0.49927142857142853 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5005000000000001 learn codes ber with rayleigh  0.5005000000000001 learn codes ber with rician  0.5005000000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5012571428571428 learn codes ber with rayleigh  0.5012571428571428 learn codes ber with rician  0.5012571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.49607142857142855 learn codes ber with rayleigh  0.49607142857142855 learn codes ber with rician  0.49607142857142855 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5016571428571429 learn codes ber with rayleigh  0.5016571428571429 learn codes ber with rician  0.5016571428571429 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.4969428571428571 learn codes ber with rayleigh  0.4969428571428571 learn codes ber with rician  0.4969428571428571 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5029142857142858, 0.49998571428571437, 0.4992285714285713, 0.49994285714285713, 0.4995142857142857, 0.5002714285714286, 0.5009857142857143, 0.5007142857142857, 0.5018999999999999, 0.4996428571428571, 0.5011714285714285, 0.5013142857142857, 0.5000571428571428, 0.5047285714285714, 0.49927142857142853, 0.5005000000000001, 0.5012571428571428, 0.49607142857142855, 0.5016571428571429, 0.4969428571428571]
Learn Codes rayleigh [0.5029142857142858, 0.49998571428571437, 0.4992285714285713, 0.49994285714285713, 0.4995142857142857, 0.5002714285714286, 0.5009857142857143, 0.5007142857142857, 0.5018999999999999, 0.4996428571428571, 0.5011714285714285, 0.5013142857142857, 0.5000571428571428, 0.5047285714285714, 0.49927142857142853, 0.5005000000000001, 0.5012571428571428, 0.49607142857142855, 0.5016571428571429, 0.4969428571428571]
Learn Codes rician [0.5029142857142858, 0.49998571428571437, 0.4992285714285713, 0.49994285714285713, 0.4995142857142857, 0.5002714285714286, 0.5009857142857143, 0.5007142857142857, 0.5018999999999999, 0.4996428571428571, 0.5011714285714285, 0.5013142857142857, 0.5000571428571428, 0.5047285714285714, 0.49927142857142853, 0.5005000000000001, 0.5012571428571428, 0.49607142857142855, 0.5016571428571429, 0.4969428571428571]
AWGN [0.3769875, 0.2884875, 0.1575125, 0.038375, 0.000825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.39556250000000004, 0.307025, 0.184775, 0.0831875, 0.030912500000000002, 0.010849999999999997, 0.0034375000000000005, 0.0009125000000000001, 0.0002875, 0.00015000000000000001, 6.25e-05, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3879625, 0.28361250000000005, 0.1419875, 0.03305, 0.0046375, 0.0008125000000000001, 0.00013749999999999998, 3.7500000000000003e-05, 2.5e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 10 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69336003 loss Rayleigh: 0.69336305 loss Rician: 0.69327568   running time 5.999008655548096
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67978413 loss Rayleigh: 0.67729364 loss Rician: 0.67409202   running time 6.008056640625
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66493357 loss Rayleigh: 0.66707137 loss Rician: 0.66194187   running time 5.972426652908325
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.68150785 loss Rayleigh: 0.66857787 loss Rician: 0.66416476   running time 5.976154804229736
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65840383 loss Rayleigh: 0.66803098 loss Rician: 0.64877869   running time 6.168628454208374
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64363919 loss Rayleigh: 0.65217554 loss Rician: 0.63987739   running time 6.067476749420166
====> Test set BCE loss with SNR 0.0 for AWGN 0.6377070546150208 Custom Loss 0.6377070546150208 with ber  0.4979 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6458973288536072 Custom Loss 0.6458973288536072 with ber  0.4979 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6360699534416199 Custom Loss 0.6360699534416199 with ber  0.4979 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.05544924736023s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63815147 loss Rayleigh: 0.64543381 loss Rician: 0.63589703   running time 5.85970664024353
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62926328 loss Rayleigh: 0.63689663 loss Rician: 0.62664063   running time 6.178141117095947
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62240723 loss Rayleigh: 0.63053007 loss Rician: 0.62022325   running time 6.131789922714233
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61875147 loss Rayleigh: 0.62660655 loss Rician: 0.61637709   running time 6.022094964981079
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61932998 loss Rayleigh: 0.62674722 loss Rician: 0.61546230   running time 5.9844372272491455
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62245632 loss Rayleigh: 0.62962822 loss Rician: 0.61882812   running time 6.204893112182617
====> Test set BCE loss with SNR 0.0 for AWGN 0.623394787311554 Custom Loss 0.623394787311554 with ber  0.49720000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6305988430976868 Custom Loss 0.6305988430976868 with ber  0.49720000000000003 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6208887100219727 Custom Loss 0.6208887100219727 with ber  0.49720000000000003 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.33320140838623s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.62290107 loss Rayleigh: 0.62913776 loss Rician: 0.61992126   running time 5.896833658218384
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.61263331 loss Rayleigh: 0.62177732 loss Rician: 0.60747616   running time 6.041693449020386
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60832694 loss Rayleigh: 0.61905826 loss Rician: 0.60236522   running time 6.210124731063843
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60250175 loss Rayleigh: 0.61475283 loss Rician: 0.59461650   running time 6.132491111755371
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60023346 loss Rayleigh: 0.61053640 loss Rician: 0.59287847   running time 6.0568764209747314
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59896819 loss Rayleigh: 0.61130778 loss Rician: 0.59105301   running time 6.011598825454712
====> Test set BCE loss with SNR 0.0 for AWGN 0.5973385572433472 Custom Loss 0.5973385572433472 with ber  0.5021571428571427 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.606223464012146 Custom Loss 0.606223464012146 with ber  0.5021571428571427 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.586718738079071 Custom Loss 0.586718738079071 with ber  0.5021571428571427 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.39711856842041s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59469411 loss Rayleigh: 0.60455602 loss Rician: 0.58348773   running time 5.985363483428955
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59477036 loss Rayleigh: 0.60455173 loss Rician: 0.58033522   running time 5.929773569107056
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59098520 loss Rayleigh: 0.60371504 loss Rician: 0.58067069   running time 6.034246444702148
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58712231 loss Rayleigh: 0.59467874 loss Rician: 0.57437248   running time 5.990163087844849
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58215017 loss Rayleigh: 0.59183364 loss Rician: 0.56975636   running time 6.197936534881592
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58482260 loss Rayleigh: 0.59496834 loss Rician: 0.57052963   running time 6.131982088088989
====> Test set BCE loss with SNR 0.0 for AWGN 0.5791982412338257 Custom Loss 0.5791982412338257 with ber  0.5011857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5918033719062805 Custom Loss 0.5918033719062805 with ber  0.5011857142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5668914914131165 Custom Loss 0.5668914914131165 with ber  0.5011857142857143 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.16345691680908s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58027766 loss Rayleigh: 0.59261742 loss Rician: 0.56684241   running time 5.939750909805298
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.57995951 loss Rayleigh: 0.58992600 loss Rician: 0.56452614   running time 6.2290074825286865
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58326671 loss Rayleigh: 0.59199967 loss Rician: 0.56593723   running time 6.106024503707886
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58855345 loss Rayleigh: 0.59682176 loss Rician: 0.57393826   running time 6.015091419219971
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58601590 loss Rayleigh: 0.59191286 loss Rician: 0.56761929   running time 6.042790412902832
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58417678 loss Rayleigh: 0.59066634 loss Rician: 0.56620315   running time 6.187790155410767
====> Test set BCE loss with SNR 0.0 for AWGN 0.5798991918563843 Custom Loss 0.5798991918563843 with ber  0.4998571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5881749391555786 Custom Loss 0.5881749391555786 with ber  0.4998571428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5619905591011047 Custom Loss 0.5619905591011047 with ber  0.4998571428571429 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.49279570579529s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.57763752 loss Rayleigh: 0.58713249 loss Rician: 0.56137433   running time 5.830598592758179
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58105703 loss Rayleigh: 0.58710399 loss Rician: 0.56228195   running time 6.026949405670166
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58142486 loss Rayleigh: 0.58584776 loss Rician: 0.56338295   running time 6.145972967147827
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58351848 loss Rayleigh: 0.58803537 loss Rician: 0.56521252   running time 6.0528929233551025
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58171589 loss Rayleigh: 0.58751591 loss Rician: 0.56539673   running time 6.024395942687988
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58061186 loss Rayleigh: 0.58564352 loss Rician: 0.56241252   running time 6.004069566726685
====> Test set BCE loss with SNR 0.0 for AWGN 0.5769029855728149 Custom Loss 0.5769029855728149 with ber  0.49848571428571437 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5799983739852905 Custom Loss 0.5799983739852905 with ber  0.49848571428571437 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5594841241836548 Custom Loss 0.5594841241836548 with ber  0.49848571428571437 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 38.09102988243103s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_10__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_10__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.504 learn codes ber with rayleigh  0.504 learn codes ber with rician  0.504 ber with awgn  0.4408 ber with rayleigh  0.45662499999999995 ber with rician  0.4505625000000001
Test SNR 5 learn codes ber with awgn  0.4974857142857143 learn codes ber with rayleigh  0.4974857142857143 learn codes ber with rician  0.4974857142857143 ber with awgn  0.3908625 ber with rayleigh  0.4094125 ber with rician  0.40322499999999994
Test SNR 10 learn codes ber with awgn  0.4997285714285714 learn codes ber with rayleigh  0.4997285714285714 learn codes ber with rician  0.4997285714285714 ber with awgn  0.31124999999999997 ber with rayleigh  0.32958750000000003 ber with rician  0.31456249999999997
Test SNR 15 learn codes ber with awgn  0.503842857142857 learn codes ber with rayleigh  0.503842857142857 learn codes ber with rician  0.503842857142857 ber with awgn  0.1901 ber with rayleigh  0.21666249999999998 ber with rician  0.17604999999999998
Test SNR 20 learn codes ber with awgn  0.49722857142857146 learn codes ber with rayleigh  0.49722857142857146 learn codes ber with rician  0.49722857142857146 ber with awgn  0.06219999999999999 ber with rayleigh  0.10221250000000001 ber with rician  0.05243749999999999
Test SNR 25 learn codes ber with awgn  0.4984571428571429 learn codes ber with rayleigh  0.4984571428571429 learn codes ber with rician  0.4984571428571429 ber with awgn  0.0031375 ber with rayleigh  0.039325 ber with rician  0.0076375
Test SNR 30 learn codes ber with awgn  0.4996714285714286 learn codes ber with rayleigh  0.4996714285714286 learn codes ber with rician  0.4996714285714286 ber with awgn  0.0 ber with rayleigh  0.012662499999999998 ber with rician  0.0009875
Test SNR 35 learn codes ber with awgn  0.5018714285714286 learn codes ber with rayleigh  0.5018714285714286 learn codes ber with rician  0.5018714285714286 ber with awgn  0.0 ber with rayleigh  0.0044 ber with rician  0.00026250000000000004
Test SNR 40 learn codes ber with awgn  0.4962142857142856 learn codes ber with rayleigh  0.4962142857142856 learn codes ber with rician  0.4962142857142856 ber with awgn  0.0 ber with rayleigh  0.001225 ber with rician  2.5e-05
Test SNR 45 learn codes ber with awgn  0.4981714285714286 learn codes ber with rayleigh  0.4981714285714286 learn codes ber with rician  0.4981714285714286 ber with awgn  0.0 ber with rayleigh  0.00037500000000000006 ber with rician  3.7500000000000003e-05
Test SNR 50 learn codes ber with awgn  0.5027285714285714 learn codes ber with rayleigh  0.5027285714285714 learn codes ber with rician  0.5027285714285714 ber with awgn  0.0 ber with rayleigh  0.00012500000000000003 ber with rician  2.5e-05
Test SNR 55 learn codes ber with awgn  0.5003428571428572 learn codes ber with rayleigh  0.5003428571428572 learn codes ber with rician  0.5003428571428572 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.49820000000000003 learn codes ber with rayleigh  0.49820000000000003 learn codes ber with rician  0.49820000000000003 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.49607142857142855 learn codes ber with rayleigh  0.49607142857142855 learn codes ber with rician  0.49607142857142855 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5000142857142856 learn codes ber with rayleigh  0.5000142857142856 learn codes ber with rician  0.5000142857142856 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5003 learn codes ber with rayleigh  0.5003 learn codes ber with rician  0.5003 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4978857142857144 learn codes ber with rayleigh  0.4978857142857144 learn codes ber with rician  0.4978857142857144 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4996142857142857 learn codes ber with rayleigh  0.4996142857142857 learn codes ber with rician  0.4996142857142857 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5031857142857142 learn codes ber with rayleigh  0.5031857142857142 learn codes ber with rician  0.5031857142857142 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5013 learn codes ber with rayleigh  0.5013 learn codes ber with rician  0.5013 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.504, 0.4974857142857143, 0.4997285714285714, 0.503842857142857, 0.49722857142857146, 0.4984571428571429, 0.4996714285714286, 0.5018714285714286, 0.4962142857142856, 0.4981714285714286, 0.5027285714285714, 0.5003428571428572, 0.49820000000000003, 0.49607142857142855, 0.5000142857142856, 0.5003, 0.4978857142857144, 0.4996142857142857, 0.5031857142857142, 0.5013]
Learn Codes rayleigh [0.504, 0.4974857142857143, 0.4997285714285714, 0.503842857142857, 0.49722857142857146, 0.4984571428571429, 0.4996714285714286, 0.5018714285714286, 0.4962142857142856, 0.4981714285714286, 0.5027285714285714, 0.5003428571428572, 0.49820000000000003, 0.49607142857142855, 0.5000142857142856, 0.5003, 0.4978857142857144, 0.4996142857142857, 0.5031857142857142, 0.5013]
Learn Codes rician [0.504, 0.4974857142857143, 0.4997285714285714, 0.503842857142857, 0.49722857142857146, 0.4984571428571429, 0.4996714285714286, 0.5018714285714286, 0.4962142857142856, 0.4981714285714286, 0.5027285714285714, 0.5003428571428572, 0.49820000000000003, 0.49607142857142855, 0.5000142857142856, 0.5003, 0.4978857142857144, 0.4996142857142857, 0.5031857142857142, 0.5013]
AWGN [0.4408, 0.3908625, 0.31124999999999997, 0.1901, 0.06219999999999999, 0.0031375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45662499999999995, 0.4094125, 0.32958750000000003, 0.21666249999999998, 0.10221250000000001, 0.039325, 0.012662499999999998, 0.0044, 0.001225, 0.00037500000000000006, 0.00012500000000000003, 5e-05, 1.25e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.4505625000000001, 0.40322499999999994, 0.31456249999999997, 0.17604999999999998, 0.05243749999999999, 0.0076375, 0.0009875, 0.00026250000000000004, 2.5e-05, 3.7500000000000003e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69330741 loss Rayleigh: 0.69332638 loss Rician: 0.69326540   running time 13.796282529830933
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64852774 loss Rayleigh: 0.65740693 loss Rician: 0.64644733   running time 14.043377876281738
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.60426930 loss Rayleigh: 0.62185677 loss Rician: 0.61992276   running time 14.0900137424469
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.58234226 loss Rayleigh: 0.60330641 loss Rician: 0.58741308   running time 14.104506015777588
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.57758400 loss Rayleigh: 0.59620082 loss Rician: 0.57898543   running time 14.026936531066895
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.57577200 loss Rayleigh: 0.59156728 loss Rician: 0.57802732   running time 13.95665693283081
====> Test set BCE loss with SNR 0.0 for AWGN 0.5653153657913208 Custom Loss 0.5653153657913208 with ber  0.5006666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.577349066734314 Custom Loss 0.577349066734314 with ber  0.5006666666666667 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.565337061882019 Custom Loss 0.565337061882019 with ber  0.5006666666666667 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 87.88818883895874s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56396691 loss Rayleigh: 0.57591079 loss Rician: 0.56296570   running time 13.943739891052246
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56223668 loss Rayleigh: 0.57554213 loss Rician: 0.56073550   running time 14.122156620025635
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55551819 loss Rayleigh: 0.57202631 loss Rician: 0.55602685   running time 14.134944677352905
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.54891209 loss Rayleigh: 0.56123398 loss Rician: 0.54923952   running time 14.11313247680664
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.54641950 loss Rayleigh: 0.55766470 loss Rician: 0.54500915   running time 14.090053796768188
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.54632917 loss Rayleigh: 0.55830051 loss Rician: 0.54335726   running time 14.070137739181519
====> Test set BCE loss with SNR 0.0 for AWGN 0.5468485355377197 Custom Loss 0.5468485355377197 with ber  0.49960000000000004 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5554355382919312 Custom Loss 0.5554355382919312 with ber  0.49960000000000004 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5430493354797363 Custom Loss 0.5430493354797363 with ber  0.49960000000000004 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.4083640575409s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54892616 loss Rayleigh: 0.56019126 loss Rician: 0.54608410   running time 13.893803358078003
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53831684 loss Rayleigh: 0.55467671 loss Rician: 0.53625602   running time 14.006649732589722
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53378637 loss Rayleigh: 0.54608876 loss Rician: 0.53016474   running time 13.989843368530273
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53508105 loss Rayleigh: 0.54580076 loss Rician: 0.53186262   running time 14.039652109146118
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53425367 loss Rayleigh: 0.54367875 loss Rician: 0.52930658   running time 14.096482992172241
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53183543 loss Rayleigh: 0.54346475 loss Rician: 0.52760271   running time 13.953560590744019
====> Test set BCE loss with SNR 0.0 for AWGN 0.531169056892395 Custom Loss 0.531169056892395 with ber  0.49949999999999994 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5397263169288635 Custom Loss 0.5397263169288635 with ber  0.49949999999999994 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5247328877449036 Custom Loss 0.5247328877449036 with ber  0.49949999999999994 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 87.72275137901306s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52857429 loss Rayleigh: 0.53813879 loss Rician: 0.52386868   running time 14.140052318572998
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52098466 loss Rayleigh: 0.53522967 loss Rician: 0.51401401   running time 14.16059947013855
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52231116 loss Rayleigh: 0.53604167 loss Rician: 0.51557999   running time 14.053604364395142
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52026732 loss Rayleigh: 0.53264019 loss Rician: 0.51386501   running time 14.08182144165039
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52456802 loss Rayleigh: 0.53412713 loss Rician: 0.51703678   running time 14.06498122215271
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52120727 loss Rayleigh: 0.53219240 loss Rician: 0.51158368   running time 14.097399234771729
====> Test set BCE loss with SNR 0.0 for AWGN 0.5168591141700745 Custom Loss 0.5168591141700745 with ber  0.49651666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5250547528266907 Custom Loss 0.5250547528266907 with ber  0.49651666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5070196986198425 Custom Loss 0.5070196986198425 with ber  0.49651666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.53433752059937s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.51313110 loss Rayleigh: 0.52072948 loss Rician: 0.50179015   running time 14.025773048400879
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50682595 loss Rayleigh: 0.51722810 loss Rician: 0.49317571   running time 14.138712406158447
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50369573 loss Rayleigh: 0.51249078 loss Rician: 0.48994422   running time 14.053287982940674
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50099237 loss Rayleigh: 0.50754784 loss Rician: 0.48879798   running time 13.985395669937134
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50117932 loss Rayleigh: 0.51203558 loss Rician: 0.49075647   running time 14.198204517364502
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.49938079 loss Rayleigh: 0.50703028 loss Rician: 0.48376860   running time 14.115178346633911
====> Test set BCE loss with SNR 0.0 for AWGN 0.4935646653175354 Custom Loss 0.4935646653175354 with ber  0.49923333333333336 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.49821940064430237 Custom Loss 0.49821940064430237 with ber  0.49923333333333336 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.47716274857521057 Custom Loss 0.47716274857521057 with ber  0.49923333333333336 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.8285014629364s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49287739 loss Rayleigh: 0.49976179 loss Rician: 0.47953790   running time 13.9303617477417
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49174727 loss Rayleigh: 0.50249390 loss Rician: 0.48081499   running time 13.879276275634766
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49537082 loss Rayleigh: 0.50435750 loss Rician: 0.48111783   running time 14.030407428741455
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49881391 loss Rayleigh: 0.50730469 loss Rician: 0.48525171   running time 14.091734886169434
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49309487 loss Rayleigh: 0.50334505 loss Rician: 0.48221171   running time 14.057213068008423
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49475280 loss Rayleigh: 0.49838921 loss Rician: 0.47989440   running time 13.969814538955688
====> Test set BCE loss with SNR 0.0 for AWGN 0.49304184317588806 Custom Loss 0.49304184317588806 with ber  0.49855 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.4994214177131653 Custom Loss 0.4994214177131653 with ber  0.49855 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.4797650873661041 Custom Loss 0.4797650873661041 with ber  0.49855 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 87.7881166934967s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.5043 learn codes ber with rayleigh  0.5043 learn codes ber with rician  0.5043 ber with awgn  0.3748250000000001 ber with rayleigh  0.3971625 ber with rician  0.39245
Test SNR 5 learn codes ber with awgn  0.4989833333333332 learn codes ber with rayleigh  0.4989833333333332 learn codes ber with rician  0.4989833333333332 ber with awgn  0.2864 ber with rayleigh  0.30538750000000003 ber with rician  0.2936625
Test SNR 10 learn codes ber with awgn  0.4985666666666667 learn codes ber with rayleigh  0.4985666666666667 learn codes ber with rician  0.4985666666666667 ber with awgn  0.15972499999999998 ber with rayleigh  0.18616250000000004 ber with rician  0.15882500000000002
Test SNR 15 learn codes ber with awgn  0.5005166666666667 learn codes ber with rayleigh  0.5005166666666667 learn codes ber with rician  0.5005166666666667 ber with awgn  0.0362 ber with rayleigh  0.08267500000000001 ber with rician  0.05626250000000001
Test SNR 20 learn codes ber with awgn  0.5015333333333333 learn codes ber with rayleigh  0.5015333333333333 learn codes ber with rician  0.5015333333333333 ber with awgn  0.0008125000000000001 ber with rayleigh  0.03025 ber with rician  0.016275
Test SNR 25 learn codes ber with awgn  0.5039333333333332 learn codes ber with rayleigh  0.5039333333333332 learn codes ber with rician  0.5039333333333332 ber with awgn  0.0 ber with rayleigh  0.010562499999999997 ber with rician  0.0043375
Test SNR 30 learn codes ber with awgn  0.5006 learn codes ber with rayleigh  0.5006 learn codes ber with rician  0.5006 ber with awgn  0.0 ber with rayleigh  0.0031625 ber with rician  0.0013625
Test SNR 35 learn codes ber with awgn  0.5034833333333333 learn codes ber with rayleigh  0.5034833333333333 learn codes ber with rician  0.5034833333333333 ber with awgn  0.0 ber with rayleigh  0.0010000000000000002 ber with rician  0.000525
Test SNR 40 learn codes ber with awgn  0.4990499999999999 learn codes ber with rayleigh  0.4990499999999999 learn codes ber with rician  0.4990499999999999 ber with awgn  0.0 ber with rayleigh  0.0003375 ber with rician  0.0002
Test SNR 45 learn codes ber with awgn  0.4978000000000001 learn codes ber with rayleigh  0.4978000000000001 learn codes ber with rician  0.4978000000000001 ber with awgn  0.0 ber with rayleigh  0.00011250000000000001 ber with rician  5e-05
Test SNR 50 learn codes ber with awgn  0.5010833333333333 learn codes ber with rayleigh  0.5010833333333333 learn codes ber with rician  0.5010833333333333 ber with awgn  0.0 ber with rayleigh  5e-05 ber with rician  5e-05
Test SNR 55 learn codes ber with awgn  0.5 learn codes ber with rayleigh  0.5 learn codes ber with rician  0.5 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4980666666666667 learn codes ber with rayleigh  0.4980666666666667 learn codes ber with rician  0.4980666666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4995 learn codes ber with rayleigh  0.4995 learn codes ber with rician  0.4995 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5000833333333334 learn codes ber with rayleigh  0.5000833333333334 learn codes ber with rician  0.5000833333333334 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5022166666666668 learn codes ber with rayleigh  0.5022166666666668 learn codes ber with rician  0.5022166666666668 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.4989 learn codes ber with rayleigh  0.4989 learn codes ber with rician  0.4989 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5026833333333334 learn codes ber with rayleigh  0.5026833333333334 learn codes ber with rician  0.5026833333333334 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.49828333333333336 learn codes ber with rayleigh  0.49828333333333336 learn codes ber with rician  0.49828333333333336 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5006999999999999 learn codes ber with rayleigh  0.5006999999999999 learn codes ber with rician  0.5006999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.5043, 0.4989833333333332, 0.4985666666666667, 0.5005166666666667, 0.5015333333333333, 0.5039333333333332, 0.5006, 0.5034833333333333, 0.4990499999999999, 0.4978000000000001, 0.5010833333333333, 0.5, 0.4980666666666667, 0.4995, 0.5000833333333334, 0.5022166666666668, 0.4989, 0.5026833333333334, 0.49828333333333336, 0.5006999999999999]
Learn Codes rayleigh [0.5043, 0.4989833333333332, 0.4985666666666667, 0.5005166666666667, 0.5015333333333333, 0.5039333333333332, 0.5006, 0.5034833333333333, 0.4990499999999999, 0.4978000000000001, 0.5010833333333333, 0.5, 0.4980666666666667, 0.4995, 0.5000833333333334, 0.5022166666666668, 0.4989, 0.5026833333333334, 0.49828333333333336, 0.5006999999999999]
Learn Codes rician [0.5043, 0.4989833333333332, 0.4985666666666667, 0.5005166666666667, 0.5015333333333333, 0.5039333333333332, 0.5006, 0.5034833333333333, 0.4990499999999999, 0.4978000000000001, 0.5010833333333333, 0.5, 0.4980666666666667, 0.4995, 0.5000833333333334, 0.5022166666666668, 0.4989, 0.5026833333333334, 0.49828333333333336, 0.5006999999999999]
AWGN [0.3748250000000001, 0.2864, 0.15972499999999998, 0.0362, 0.0008125000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3971625, 0.30538750000000003, 0.18616250000000004, 0.08267500000000001, 0.03025, 0.010562499999999997, 0.0031625, 0.0010000000000000002, 0.0003375, 0.00011250000000000001, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39245, 0.2936625, 0.15882500000000002, 0.05626250000000001, 0.016275, 0.0043375, 0.0013625, 0.000525, 0.0002, 5e-05, 5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 3 coderate_n => 4 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(3, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(4, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=3, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69303108 loss Rayleigh: 0.69303662 loss Rician: 0.69298311   running time 13.894882202148438
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65160910 loss Rayleigh: 0.66432731 loss Rician: 0.65912358   running time 13.992863416671753
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.62030234 loss Rayleigh: 0.63870919 loss Rician: 0.62231492   running time 14.08545446395874
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64502034 loss Rayleigh: 0.63876400 loss Rician: 0.62122191   running time 13.935544490814209
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.63366936 loss Rayleigh: 0.63370398 loss Rician: 0.63646473   running time 13.91817331314087
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.57571130 loss Rayleigh: 0.59241809 loss Rician: 0.57869463   running time 14.036826133728027
====> Test set BCE loss with SNR 0.0 for AWGN 0.5615620017051697 Custom Loss 0.5615620017051697 with ber  0.5009666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5776470899581909 Custom Loss 0.5776470899581909 with ber  0.5009666666666666 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5627065896987915 Custom Loss 0.5627065896987915 with ber  0.5009666666666666 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 87.84508228302002s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55976396 loss Rayleigh: 0.57642213 loss Rician: 0.56174171   running time 14.011407136917114
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56919692 loss Rayleigh: 0.58623811 loss Rician: 0.56894549   running time 14.05845594406128
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.56125847 loss Rayleigh: 0.57400039 loss Rician: 0.55854376   running time 14.077756643295288
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55328350 loss Rayleigh: 0.56695480 loss Rician: 0.55284238   running time 14.041562557220459
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55284740 loss Rayleigh: 0.56603490 loss Rician: 0.55065920   running time 14.096388578414917
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.55347369 loss Rayleigh: 0.56418040 loss Rician: 0.54987924   running time 14.216998815536499
====> Test set BCE loss with SNR 0.0 for AWGN 0.5517308115959167 Custom Loss 0.5517308115959167 with ber  0.4984 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5604861378669739 Custom Loss 0.5604861378669739 with ber  0.4984 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5459705591201782 Custom Loss 0.5459705591201782 with ber  0.4984 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.33538627624512s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.54650193 loss Rayleigh: 0.55724150 loss Rician: 0.54065793   running time 13.981333494186401
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53724212 loss Rayleigh: 0.54726569 loss Rician: 0.53185661   running time 14.012243509292603
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53321607 loss Rayleigh: 0.54345695 loss Rician: 0.52949718   running time 14.109736919403076
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53749600 loss Rayleigh: 0.54749370 loss Rician: 0.53041028   running time 14.062236070632935
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53916292 loss Rayleigh: 0.54815970 loss Rician: 0.53080714   running time 14.135270833969116
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.53493056 loss Rayleigh: 0.54607908 loss Rician: 0.52640986   running time 14.075936079025269
====> Test set BCE loss with SNR 0.0 for AWGN 0.5283365249633789 Custom Loss 0.5283365249633789 with ber  0.5013833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5350679159164429 Custom Loss 0.5350679159164429 with ber  0.5013833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5181463360786438 Custom Loss 0.5181463360786438 with ber  0.5013833333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.159015417099s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.52845351 loss Rayleigh: 0.53413447 loss Rician: 0.51932794   running time 14.050072193145752
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.51411009 loss Rayleigh: 0.52858839 loss Rician: 0.50884064   running time 14.163641214370728
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.50922759 loss Rayleigh: 0.52322767 loss Rician: 0.50005856   running time 14.134978294372559
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.50730264 loss Rayleigh: 0.52016976 loss Rician: 0.49634809   running time 13.966324806213379
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.51329497 loss Rayleigh: 0.52113655 loss Rician: 0.49666538   running time 13.973728895187378
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.50517744 loss Rayleigh: 0.51167145 loss Rician: 0.49383098   running time 14.986344575881958
====> Test set BCE loss with SNR 0.0 for AWGN 0.502818763256073 Custom Loss 0.502818763256073 with ber  0.5008 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5096007585525513 Custom Loss 0.5096007585525513 with ber  0.5008 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.489558607339859 Custom Loss 0.489558607339859 with ber  0.5008 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.2174813747406s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.50301793 loss Rayleigh: 0.50892226 loss Rician: 0.48635944   running time 14.044128894805908
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.49127116 loss Rayleigh: 0.49796137 loss Rician: 0.47803681   running time 14.332083463668823
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.49001423 loss Rayleigh: 0.49656416 loss Rician: 0.47439198   running time 14.343708038330078
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.48875444 loss Rayleigh: 0.49442464 loss Rician: 0.47339254   running time 14.193564176559448
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.48739132 loss Rayleigh: 0.49620652 loss Rician: 0.47115488   running time 14.01986312866211
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.48649473 loss Rayleigh: 0.49416101 loss Rician: 0.47430931   running time 14.167232275009155
====> Test set BCE loss with SNR 0.0 for AWGN 0.4870803952217102 Custom Loss 0.4870803952217102 with ber  0.4967833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.49256452918052673 Custom Loss 0.49256452918052673 with ber  0.4967833333333333 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.4690491259098053 Custom Loss 0.4690491259098053 with ber  0.4967833333333333 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.03418684005737s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48896994 loss Rayleigh: 0.49566724 loss Rician: 0.47041931   running time 14.067806720733643
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48949606 loss Rayleigh: 0.49049386 loss Rician: 0.46694717   running time 14.026421308517456
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49168456 loss Rayleigh: 0.49298424 loss Rician: 0.47253246   running time 14.091099500656128
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.49072458 loss Rayleigh: 0.49346492 loss Rician: 0.47318318   running time 14.084084033966064
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48766164 loss Rayleigh: 0.49148161 loss Rician: 0.46438377   running time 14.136482000350952
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.48934884 loss Rayleigh: 0.49705122 loss Rician: 0.46852893   running time 14.150273323059082
====> Test set BCE loss with SNR 0.0 for AWGN 0.4864532947540283 Custom Loss 0.4864532947540283 with ber  0.49908333333333327 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.4901241660118103 Custom Loss 0.4901241660118103 with ber  0.49908333333333327 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.46796125173568726 Custom Loss 0.46796125173568726 with ber  0.49908333333333327 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.37097144126892s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_3_n_4_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_3_n_4_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49688333333333323 learn codes ber with rayleigh  0.49688333333333323 learn codes ber with rician  0.49688333333333323 ber with awgn  0.43842499999999995 ber with rayleigh  0.4573500000000001 ber with rician  0.45220000000000005
Test SNR 5 learn codes ber with awgn  0.5008166666666667 learn codes ber with rayleigh  0.5008166666666667 learn codes ber with rician  0.5008166666666667 ber with awgn  0.3928125 ber with rayleigh  0.41175000000000006 ber with rician  0.41023750000000003
Test SNR 10 learn codes ber with awgn  0.49943333333333334 learn codes ber with rayleigh  0.49943333333333334 learn codes ber with rician  0.49943333333333334 ber with awgn  0.3113625 ber with rayleigh  0.33356250000000004 ber with rician  0.3257625
Test SNR 15 learn codes ber with awgn  0.49824999999999997 learn codes ber with rayleigh  0.49824999999999997 learn codes ber with rician  0.49824999999999997 ber with awgn  0.19212500000000005 ber with rayleigh  0.21155 ber with rician  0.19545000000000004
Test SNR 20 learn codes ber with awgn  0.49671666666666664 learn codes ber with rayleigh  0.49671666666666664 learn codes ber with rician  0.49671666666666664 ber with awgn  0.061162499999999995 ber with rayleigh  0.10558749999999999 ber with rician  0.076375
Test SNR 25 learn codes ber with awgn  0.4990833333333334 learn codes ber with rayleigh  0.4990833333333334 learn codes ber with rician  0.4990833333333334 ber with awgn  0.003025 ber with rayleigh  0.0392 ber with rician  0.022275000000000003
Test SNR 30 learn codes ber with awgn  0.4973666666666666 learn codes ber with rayleigh  0.4973666666666666 learn codes ber with rician  0.4973666666666666 ber with awgn  0.0 ber with rayleigh  0.013525 ber with rician  0.005974999999999999
Test SNR 35 learn codes ber with awgn  0.49948333333333333 learn codes ber with rayleigh  0.49948333333333333 learn codes ber with rician  0.49948333333333333 ber with awgn  0.0 ber with rayleigh  0.0042 ber with rician  0.0019
Test SNR 40 learn codes ber with awgn  0.4991833333333333 learn codes ber with rayleigh  0.4991833333333333 learn codes ber with rician  0.4991833333333333 ber with awgn  0.0 ber with rayleigh  0.001375 ber with rician  0.000675
Test SNR 45 learn codes ber with awgn  0.49816666666666665 learn codes ber with rayleigh  0.49816666666666665 learn codes ber with rician  0.49816666666666665 ber with awgn  0.0 ber with rayleigh  0.00043750000000000006 ber with rician  0.00022500000000000002
Test SNR 50 learn codes ber with awgn  0.49908333333333343 learn codes ber with rayleigh  0.49908333333333343 learn codes ber with rician  0.49908333333333343 ber with awgn  0.0 ber with rayleigh  0.00016250000000000002 ber with rician  5e-05
Test SNR 55 learn codes ber with awgn  0.5000000000000001 learn codes ber with rayleigh  0.5000000000000001 learn codes ber with rician  0.5000000000000001 ber with awgn  0.0 ber with rayleigh  3.7500000000000003e-05 ber with rician  2.5e-05
Test SNR 60 learn codes ber with awgn  0.4980833333333334 learn codes ber with rayleigh  0.4980833333333334 learn codes ber with rician  0.4980833333333334 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  2.5e-05
Test SNR 65 learn codes ber with awgn  0.5037 learn codes ber with rayleigh  0.5037 learn codes ber with rician  0.5037 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5011166666666667 learn codes ber with rayleigh  0.5011166666666667 learn codes ber with rician  0.5011166666666667 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5025999999999999 learn codes ber with rayleigh  0.5025999999999999 learn codes ber with rician  0.5025999999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5006833333333333 learn codes ber with rayleigh  0.5006833333333333 learn codes ber with rician  0.5006833333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4988666666666666 learn codes ber with rayleigh  0.4988666666666666 learn codes ber with rician  0.4988666666666666 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5031833333333333 learn codes ber with rayleigh  0.5031833333333333 learn codes ber with rician  0.5031833333333333 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.50145 learn codes ber with rayleigh  0.50145 learn codes ber with rician  0.50145 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49688333333333323, 0.5008166666666667, 0.49943333333333334, 0.49824999999999997, 0.49671666666666664, 0.4990833333333334, 0.4973666666666666, 0.49948333333333333, 0.4991833333333333, 0.49816666666666665, 0.49908333333333343, 0.5000000000000001, 0.4980833333333334, 0.5037, 0.5011166666666667, 0.5025999999999999, 0.5006833333333333, 0.4988666666666666, 0.5031833333333333, 0.50145]
Learn Codes rayleigh [0.49688333333333323, 0.5008166666666667, 0.49943333333333334, 0.49824999999999997, 0.49671666666666664, 0.4990833333333334, 0.4973666666666666, 0.49948333333333333, 0.4991833333333333, 0.49816666666666665, 0.49908333333333343, 0.5000000000000001, 0.4980833333333334, 0.5037, 0.5011166666666667, 0.5025999999999999, 0.5006833333333333, 0.4988666666666666, 0.5031833333333333, 0.50145]
Learn Codes rician [0.49688333333333323, 0.5008166666666667, 0.49943333333333334, 0.49824999999999997, 0.49671666666666664, 0.4990833333333334, 0.4973666666666666, 0.49948333333333333, 0.4991833333333333, 0.49816666666666665, 0.49908333333333343, 0.5000000000000001, 0.4980833333333334, 0.5037, 0.5011166666666667, 0.5025999999999999, 0.5006833333333333, 0.4988666666666666, 0.5031833333333333, 0.50145]
AWGN [0.43842499999999995, 0.3928125, 0.3113625, 0.19212500000000005, 0.061162499999999995, 0.003025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.4573500000000001, 0.41175000000000006, 0.33356250000000004, 0.21155, 0.10558749999999999, 0.0392, 0.013525, 0.0042, 0.001375, 0.00043750000000000006, 0.00016250000000000002, 3.7500000000000003e-05, 1.25e-05, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45220000000000005, 0.41023750000000003, 0.3257625, 0.19545000000000004, 0.076375, 0.022275000000000003, 0.005974999999999999, 0.0019, 0.000675, 0.00022500000000000002, 5e-05, 2.5e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69348344 loss Rayleigh: 0.69348848 loss Rician: 0.69344787   running time 14.112318754196167
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65929554 loss Rayleigh: 0.66599805 loss Rician: 0.66195089   running time 14.247546911239624
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64543818 loss Rayleigh: 0.64551194 loss Rician: 0.64349583   running time 14.354153633117676
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65279800 loss Rayleigh: 0.65222183 loss Rician: 0.64833121   running time 14.28047251701355
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64767827 loss Rayleigh: 0.64806967 loss Rician: 0.65590268   running time 14.172947645187378
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.61976558 loss Rayleigh: 0.63226913 loss Rician: 0.61811520   running time 14.388631582260132
====> Test set BCE loss with SNR 0.0 for AWGN 0.6114883422851562 Custom Loss 0.6114883422851562 with ber  0.49768999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6201008558273315 Custom Loss 0.6201008558273315 with ber  0.49768999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6094976663589478 Custom Loss 0.6094976663589478 with ber  0.49768999999999997 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 89.38228583335876s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60932235 loss Rayleigh: 0.61969290 loss Rician: 0.60808992   running time 14.022789716720581
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59953610 loss Rayleigh: 0.61146016 loss Rician: 0.59816751   running time 14.759790420532227
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59690610 loss Rayleigh: 0.60802312 loss Rician: 0.59627077   running time 14.22959041595459
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59538515 loss Rayleigh: 0.60757669 loss Rician: 0.59477708   running time 14.151710510253906
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59464090 loss Rayleigh: 0.60462547 loss Rician: 0.59171680   running time 14.15425968170166
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.59072645 loss Rayleigh: 0.60007297 loss Rician: 0.58841748   running time 14.089961528778076
====> Test set BCE loss with SNR 0.0 for AWGN 0.5893527269363403 Custom Loss 0.5893527269363403 with ber  0.50138 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.597439169883728 Custom Loss 0.597439169883728 with ber  0.50138 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5844853520393372 Custom Loss 0.5844853520393372 with ber  0.50138 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 89.41406965255737s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.58000454 loss Rayleigh: 0.58862702 loss Rician: 0.57511857   running time 14.071159839630127
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.57124220 loss Rayleigh: 0.58494444 loss Rician: 0.56751741   running time 14.140371322631836
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.57876333 loss Rayleigh: 0.59516091 loss Rician: 0.57126552   running time 14.017213821411133
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.57130377 loss Rayleigh: 0.58272777 loss Rician: 0.56332890   running time 14.139166355133057
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.56813278 loss Rayleigh: 0.58077472 loss Rician: 0.56102597   running time 14.095935821533203
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.57511596 loss Rayleigh: 0.58717879 loss Rician: 0.56684517   running time 14.143747568130493
====> Test set BCE loss with SNR 0.0 for AWGN 0.5672269463539124 Custom Loss 0.5672269463539124 with ber  0.4975300000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5789389610290527 Custom Loss 0.5789389610290527 with ber  0.4975300000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5598466396331787 Custom Loss 0.5598466396331787 with ber  0.4975300000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.54639768600464s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.56434361 loss Rayleigh: 0.57693008 loss Rician: 0.55751610   running time 13.901013374328613
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.56622019 loss Rayleigh: 0.57690927 loss Rician: 0.55376866   running time 14.0646071434021
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.56417534 loss Rayleigh: 0.57696604 loss Rician: 0.55313384   running time 14.060341119766235
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.55973703 loss Rayleigh: 0.56956418 loss Rician: 0.54922873   running time 14.198915243148804
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.56197655 loss Rayleigh: 0.56973427 loss Rician: 0.54861660   running time 14.134677410125732
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.56169271 loss Rayleigh: 0.57098478 loss Rician: 0.54858496   running time 14.250742673873901
====> Test set BCE loss with SNR 0.0 for AWGN 0.5554940700531006 Custom Loss 0.5554940700531006 with ber  0.50181 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5645729899406433 Custom Loss 0.5645729899406433 with ber  0.50181 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5423069596290588 Custom Loss 0.5423069596290588 with ber  0.50181 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.53645133972168s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55632631 loss Rayleigh: 0.56588145 loss Rician: 0.54411923   running time 13.855947971343994
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55612789 loss Rayleigh: 0.56357129 loss Rician: 0.54169902   running time 14.297975778579712
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55424243 loss Rayleigh: 0.56078713 loss Rician: 0.54068061   running time 14.174102306365967
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55606944 loss Rayleigh: 0.56524296 loss Rician: 0.54082818   running time 14.142865657806396
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55225581 loss Rayleigh: 0.55757814 loss Rician: 0.53613998   running time 14.14867091178894
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.55763402 loss Rayleigh: 0.56367069 loss Rician: 0.53984796   running time 14.111860990524292
====> Test set BCE loss with SNR 0.0 for AWGN 0.5523198843002319 Custom Loss 0.5523198843002319 with ber  0.49763 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5610159039497375 Custom Loss 0.5610159039497375 with ber  0.49763 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5376224517822266 Custom Loss 0.5376224517822266 with ber  0.49763 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.62894868850708s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55467552 loss Rayleigh: 0.56326061 loss Rician: 0.54089161   running time 14.092504501342773
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.56091422 loss Rayleigh: 0.56633705 loss Rician: 0.54528309   running time 14.284231185913086
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55658082 loss Rayleigh: 0.56126214 loss Rician: 0.54154044   running time 14.18909502029419
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55728123 loss Rayleigh: 0.55967348 loss Rician: 0.54006635   running time 14.079060077667236
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55749912 loss Rayleigh: 0.56257460 loss Rician: 0.54244121   running time 14.072326898574829
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.55812403 loss Rayleigh: 0.56341710 loss Rician: 0.54280278   running time 14.038172006607056
====> Test set BCE loss with SNR 0.0 for AWGN 0.5636440515518188 Custom Loss 0.5636440515518188 with ber  0.50093 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.566932201385498 Custom Loss 0.566932201385498 with ber  0.50093 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.546993613243103 Custom Loss 0.546993613243103 with ber  0.50093 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.74641489982605s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49973 learn codes ber with rayleigh  0.49973 learn codes ber with rician  0.49973 ber with awgn  0.3758583333333333 ber with rayleigh  0.398175 ber with rician  0.39096666666666663
Test SNR 5 learn codes ber with awgn  0.50194 learn codes ber with rayleigh  0.50194 learn codes ber with rician  0.50194 ber with awgn  0.28637499999999994 ber with rayleigh  0.30664166666666665 ber with rician  0.28984166666666666
Test SNR 10 learn codes ber with awgn  0.49826999999999994 learn codes ber with rayleigh  0.49826999999999994 learn codes ber with rician  0.49826999999999994 ber with awgn  0.15880833333333333 ber with rayleigh  0.18320833333333333 ber with rician  0.150225
Test SNR 15 learn codes ber with awgn  0.49944 learn codes ber with rayleigh  0.49944 learn codes ber with rician  0.49944 ber with awgn  0.03820833333333333 ber with rayleigh  0.08363333333333334 ber with rician  0.04418333333333333
Test SNR 20 learn codes ber with awgn  0.49945000000000006 learn codes ber with rayleigh  0.49945000000000006 learn codes ber with rician  0.49945000000000006 ber with awgn  0.000825 ber with rayleigh  0.03161666666666666 ber with rician  0.009191666666666667
Test SNR 25 learn codes ber with awgn  0.5012299999999998 learn codes ber with rayleigh  0.5012299999999998 learn codes ber with rician  0.5012299999999998 ber with awgn  0.0 ber with rayleigh  0.009525 ber with rician  0.002241666666666666
Test SNR 30 learn codes ber with awgn  0.5012999999999999 learn codes ber with rayleigh  0.5012999999999999 learn codes ber with rician  0.5012999999999999 ber with awgn  0.0 ber with rayleigh  0.0035750000000000005 ber with rician  0.0007833333333333335
Test SNR 35 learn codes ber with awgn  0.49998 learn codes ber with rayleigh  0.49998 learn codes ber with rician  0.49998 ber with awgn  0.0 ber with rayleigh  0.0009833333333333332 ber with rician  0.00020833333333333332
Test SNR 40 learn codes ber with awgn  0.49765999999999994 learn codes ber with rayleigh  0.49765999999999994 learn codes ber with rician  0.49765999999999994 ber with awgn  0.0 ber with rayleigh  0.0004333333333333334 ber with rician  5.833333333333334e-05
Test SNR 45 learn codes ber with awgn  0.5004 learn codes ber with rayleigh  0.5004 learn codes ber with rician  0.5004 ber with awgn  0.0 ber with rayleigh  8.333333333333333e-05 ber with rician  3.3333333333333335e-05
Test SNR 50 learn codes ber with awgn  0.49960999999999994 learn codes ber with rayleigh  0.49960999999999994 learn codes ber with rician  0.49960999999999994 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.50081 learn codes ber with rayleigh  0.50081 learn codes ber with rician  0.50081 ber with awgn  0.0 ber with rayleigh  8.333333333333334e-06 ber with rician  0.0
Test SNR 60 learn codes ber with awgn  0.4992 learn codes ber with rayleigh  0.4992 learn codes ber with rician  0.4992 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.50265 learn codes ber with rayleigh  0.50265 learn codes ber with rician  0.50265 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.49962 learn codes ber with rayleigh  0.49962 learn codes ber with rician  0.49962 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5023500000000001 learn codes ber with rayleigh  0.5023500000000001 learn codes ber with rician  0.5023500000000001 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5008 learn codes ber with rayleigh  0.5008 learn codes ber with rician  0.5008 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.50229 learn codes ber with rayleigh  0.50229 learn codes ber with rician  0.50229 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5013 learn codes ber with rayleigh  0.5013 learn codes ber with rician  0.5013 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.49816000000000005 learn codes ber with rayleigh  0.49816000000000005 learn codes ber with rician  0.49816000000000005 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49973, 0.50194, 0.49826999999999994, 0.49944, 0.49945000000000006, 0.5012299999999998, 0.5012999999999999, 0.49998, 0.49765999999999994, 0.5004, 0.49960999999999994, 0.50081, 0.4992, 0.50265, 0.49962, 0.5023500000000001, 0.5008, 0.50229, 0.5013, 0.49816000000000005]
Learn Codes rayleigh [0.49973, 0.50194, 0.49826999999999994, 0.49944, 0.49945000000000006, 0.5012299999999998, 0.5012999999999999, 0.49998, 0.49765999999999994, 0.5004, 0.49960999999999994, 0.50081, 0.4992, 0.50265, 0.49962, 0.5023500000000001, 0.5008, 0.50229, 0.5013, 0.49816000000000005]
Learn Codes rician [0.49973, 0.50194, 0.49826999999999994, 0.49944, 0.49945000000000006, 0.5012299999999998, 0.5012999999999999, 0.49998, 0.49765999999999994, 0.5004, 0.49960999999999994, 0.50081, 0.4992, 0.50265, 0.49962, 0.5023500000000001, 0.5008, 0.50229, 0.5013, 0.49816000000000005]
AWGN [0.3758583333333333, 0.28637499999999994, 0.15880833333333333, 0.03820833333333333, 0.000825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.398175, 0.30664166666666665, 0.18320833333333333, 0.08363333333333334, 0.03161666666666666, 0.009525, 0.0035750000000000005, 0.0009833333333333332, 0.0004333333333333334, 8.333333333333333e-05, 3.3333333333333335e-05, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.39096666666666663, 0.28984166666666666, 0.150225, 0.04418333333333333, 0.009191666666666667, 0.002241666666666666, 0.0007833333333333335, 0.00020833333333333332, 5.833333333333334e-05, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 5 coderate_n => 6 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(5, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(6, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=5, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69286333 loss Rayleigh: 0.69282126 loss Rician: 0.69275851   running time 13.887423992156982
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.68592289 loss Rayleigh: 0.68833033 loss Rician: 0.68772786   running time 14.215880155563354
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.67501257 loss Rayleigh: 0.67127619 loss Rician: 0.65399917   running time 14.109281063079834
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.62879903 loss Rayleigh: 0.64373897 loss Rician: 0.62887875   running time 14.182830572128296
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.61156189 loss Rayleigh: 0.62540478 loss Rician: 0.61175125   running time 14.18748664855957
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.61032120 loss Rayleigh: 0.62127712 loss Rician: 0.61029221   running time 14.130216836929321
====> Test set BCE loss with SNR 0.0 for AWGN 0.6097084283828735 Custom Loss 0.6097084283828735 with ber  0.50139 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6201378703117371 Custom Loss 0.6201378703117371 with ber  0.50139 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6090470552444458 Custom Loss 0.6090470552444458 with ber  0.50139 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.63964772224426s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60857754 loss Rayleigh: 0.62025126 loss Rician: 0.60745770   running time 15.549093246459961
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60639862 loss Rayleigh: 0.61680147 loss Rician: 0.60524892   running time 14.258973836898804
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60380355 loss Rayleigh: 0.61480726 loss Rician: 0.60218434   running time 14.12571120262146
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60519508 loss Rayleigh: 0.61467776 loss Rician: 0.60348829   running time 14.259360313415527
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60263757 loss Rayleigh: 0.61189785 loss Rician: 0.60091083   running time 14.17686939239502
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60332854 loss Rayleigh: 0.61084858 loss Rician: 0.60111251   running time 14.113529920578003
====> Test set BCE loss with SNR 0.0 for AWGN 0.6077356338500977 Custom Loss 0.6077356338500977 with ber  0.4992599999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6153780221939087 Custom Loss 0.6153780221939087 with ber  0.4992599999999999 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6037506461143494 Custom Loss 0.6037506461143494 with ber  0.4992599999999999 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 90.36044239997864s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60679157 loss Rayleigh: 0.61521328 loss Rician: 0.60362718   running time 14.134752988815308
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59736097 loss Rayleigh: 0.60686665 loss Rician: 0.59510523   running time 14.268184661865234
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60360739 loss Rayleigh: 0.61184798 loss Rician: 0.59892868   running time 14.158070087432861
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60100579 loss Rayleigh: 0.60863419 loss Rician: 0.59946939   running time 14.457556962966919
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59825758 loss Rayleigh: 0.60512092 loss Rician: 0.59491416   running time 14.208285570144653
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59714059 loss Rayleigh: 0.60288510 loss Rician: 0.59373652   running time 14.085481405258179
====> Test set BCE loss with SNR 0.0 for AWGN 0.5960033535957336 Custom Loss 0.5960033535957336 with ber  0.5003900000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6024069786071777 Custom Loss 0.6024069786071777 with ber  0.5003900000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5922755599021912 Custom Loss 0.5922755599021912 with ber  0.5003900000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.30137324333191s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59608332 loss Rayleigh: 0.60228208 loss Rician: 0.59242912   running time 13.94850206375122
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59022297 loss Rayleigh: 0.59838122 loss Rician: 0.58763759   running time 14.186197757720947
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58885521 loss Rayleigh: 0.59542217 loss Rician: 0.58379880   running time 14.100094318389893
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58831176 loss Rayleigh: 0.59419433 loss Rician: 0.58248486   running time 14.195634841918945
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59019290 loss Rayleigh: 0.59668247 loss Rician: 0.58473729   running time 14.089401960372925
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59027940 loss Rayleigh: 0.59722821 loss Rician: 0.58597374   running time 14.24840235710144
====> Test set BCE loss with SNR 0.0 for AWGN 0.5933383107185364 Custom Loss 0.5933383107185364 with ber  0.50096 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5989754796028137 Custom Loss 0.5989754796028137 with ber  0.50096 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5866955518722534 Custom Loss 0.5866955518722534 with ber  0.50096 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.80090379714966s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58960716 loss Rayleigh: 0.59574313 loss Rician: 0.58368406   running time 14.619138479232788
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58824353 loss Rayleigh: 0.59348637 loss Rician: 0.58184319   running time 14.198066473007202
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58723539 loss Rayleigh: 0.59244887 loss Rician: 0.58057747   running time 14.516958713531494
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58611927 loss Rayleigh: 0.59241666 loss Rician: 0.58124391   running time 14.172794580459595
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58464786 loss Rayleigh: 0.58979076 loss Rician: 0.57672920   running time 14.111012935638428
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58409361 loss Rayleigh: 0.58960292 loss Rician: 0.57748839   running time 14.061115503311157
====> Test set BCE loss with SNR 0.0 for AWGN 0.5830875635147095 Custom Loss 0.5830875635147095 with ber  0.50005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5893176198005676 Custom Loss 0.5893176198005676 with ber  0.50005 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5763177871704102 Custom Loss 0.5763177871704102 with ber  0.50005 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.67653322219849s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58154965 loss Rayleigh: 0.58849310 loss Rician: 0.57457439   running time 13.986989974975586
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58290227 loss Rayleigh: 0.58946817 loss Rician: 0.57687318   running time 14.052059888839722
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58229524 loss Rayleigh: 0.58593929 loss Rician: 0.57489785   running time 14.034765243530273
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58044703 loss Rayleigh: 0.58509970 loss Rician: 0.57299275   running time 14.142797231674194
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.57711850 loss Rayleigh: 0.58299520 loss Rician: 0.56912642   running time 14.079297542572021
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.57598537 loss Rayleigh: 0.58107135 loss Rician: 0.56849246   running time 14.131279230117798
====> Test set BCE loss with SNR 0.0 for AWGN 0.5754667520523071 Custom Loss 0.5754667520523071 with ber  0.5014000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5804524421691895 Custom Loss 0.5804524421691895 with ber  0.5014000000000001 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5699008107185364 Custom Loss 0.5699008107185364 with ber  0.5014000000000001 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 88.32880878448486s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_5_n_6_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_5_n_6_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.50144 learn codes ber with rayleigh  0.50144 learn codes ber with rician  0.50144 ber with awgn  0.43843333333333334 ber with rayleigh  0.45509166666666667 ber with rician  0.45183333333333336
Test SNR 5 learn codes ber with awgn  0.49807999999999997 learn codes ber with rayleigh  0.49807999999999997 learn codes ber with rician  0.49807999999999997 ber with awgn  0.39063333333333333 ber with rayleigh  0.4115333333333332 ber with rician  0.40713333333333335
Test SNR 10 learn codes ber with awgn  0.5010899999999999 learn codes ber with rayleigh  0.5010899999999999 learn codes ber with rician  0.5010899999999999 ber with awgn  0.31429999999999997 ber with rayleigh  0.33214166666666667 ber with rician  0.32045
Test SNR 15 learn codes ber with awgn  0.49871 learn codes ber with rayleigh  0.49871 learn codes ber with rician  0.49871 ber with awgn  0.19188333333333335 ber with rayleigh  0.2159333333333333 ber with rician  0.18592499999999998
Test SNR 20 learn codes ber with awgn  0.5037299999999999 learn codes ber with rayleigh  0.5037299999999999 learn codes ber with rician  0.5037299999999999 ber with awgn  0.0622 ber with rayleigh  0.10440833333333335 ber with rician  0.06213333333333333
Test SNR 25 learn codes ber with awgn  0.50012 learn codes ber with rayleigh  0.50012 learn codes ber with rician  0.50012 ber with awgn  0.003241666666666666 ber with rayleigh  0.040325 ber with rician  0.014108333333333334
Test SNR 30 learn codes ber with awgn  0.49846 learn codes ber with rayleigh  0.49846 learn codes ber with rician  0.49846 ber with awgn  0.0 ber with rayleigh  0.013091666666666668 ber with rician  0.003133333333333333
Test SNR 35 learn codes ber with awgn  0.4997299999999999 learn codes ber with rayleigh  0.4997299999999999 learn codes ber with rician  0.4997299999999999 ber with awgn  0.0 ber with rayleigh  0.004575000000000001 ber with rician  0.0008583333333333333
Test SNR 40 learn codes ber with awgn  0.49903999999999993 learn codes ber with rayleigh  0.49903999999999993 learn codes ber with rician  0.49903999999999993 ber with awgn  0.0 ber with rayleigh  0.001566666666666667 ber with rician  0.000275
Test SNR 45 learn codes ber with awgn  0.49839 learn codes ber with rayleigh  0.49839 learn codes ber with rician  0.49839 ber with awgn  0.0 ber with rayleigh  0.0005083333333333334 ber with rician  9.166666666666668e-05
Test SNR 50 learn codes ber with awgn  0.49975 learn codes ber with rayleigh  0.49975 learn codes ber with rician  0.49975 ber with awgn  0.0 ber with rayleigh  0.00014166666666666665 ber with rician  1.6666666666666667e-05
Test SNR 55 learn codes ber with awgn  0.4993600000000001 learn codes ber with rayleigh  0.4993600000000001 learn codes ber with rician  0.4993600000000001 ber with awgn  0.0 ber with rayleigh  3.3333333333333335e-05 ber with rician  8.333333333333334e-06
Test SNR 60 learn codes ber with awgn  0.50073 learn codes ber with rayleigh  0.50073 learn codes ber with rician  0.50073 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  8.333333333333334e-06
Test SNR 65 learn codes ber with awgn  0.4988099999999999 learn codes ber with rayleigh  0.4988099999999999 learn codes ber with rician  0.4988099999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.50153 learn codes ber with rayleigh  0.50153 learn codes ber with rician  0.50153 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.50023 learn codes ber with rayleigh  0.50023 learn codes ber with rician  0.50023 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49842 learn codes ber with rayleigh  0.49842 learn codes ber with rician  0.49842 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.50234 learn codes ber with rayleigh  0.50234 learn codes ber with rician  0.50234 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.50112 learn codes ber with rayleigh  0.50112 learn codes ber with rician  0.50112 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5020899999999999 learn codes ber with rayleigh  0.5020899999999999 learn codes ber with rician  0.5020899999999999 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.50144, 0.49807999999999997, 0.5010899999999999, 0.49871, 0.5037299999999999, 0.50012, 0.49846, 0.4997299999999999, 0.49903999999999993, 0.49839, 0.49975, 0.4993600000000001, 0.50073, 0.4988099999999999, 0.50153, 0.50023, 0.49842, 0.50234, 0.50112, 0.5020899999999999]
Learn Codes rayleigh [0.50144, 0.49807999999999997, 0.5010899999999999, 0.49871, 0.5037299999999999, 0.50012, 0.49846, 0.4997299999999999, 0.49903999999999993, 0.49839, 0.49975, 0.4993600000000001, 0.50073, 0.4988099999999999, 0.50153, 0.50023, 0.49842, 0.50234, 0.50112, 0.5020899999999999]
Learn Codes rician [0.50144, 0.49807999999999997, 0.5010899999999999, 0.49871, 0.5037299999999999, 0.50012, 0.49846, 0.4997299999999999, 0.49903999999999993, 0.49839, 0.49975, 0.4993600000000001, 0.50073, 0.4988099999999999, 0.50153, 0.50023, 0.49842, 0.50234, 0.50112, 0.5020899999999999]
AWGN [0.43843333333333334, 0.39063333333333333, 0.31429999999999997, 0.19188333333333335, 0.0622, 0.003241666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45509166666666667, 0.4115333333333332, 0.33214166666666667, 0.2159333333333333, 0.10440833333333335, 0.040325, 0.013091666666666668, 0.004575000000000001, 0.001566666666666667, 0.0005083333333333334, 0.00014166666666666665, 3.3333333333333335e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.45183333333333336, 0.40713333333333335, 0.32045, 0.18592499999999998, 0.06213333333333333, 0.014108333333333334, 0.003133333333333333, 0.0008583333333333333, 0.000275, 9.166666666666668e-05, 1.6666666666666667e-05, 8.333333333333334e-06, 8.333333333333334e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM16
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69295255 loss Rayleigh: 0.69295475 loss Rician: 0.69290922   running time 14.136596202850342
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.68552625 loss Rayleigh: 0.68166105 loss Rician: 0.67799776   running time 14.142230749130249
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66534262 loss Rayleigh: 0.67837917 loss Rician: 0.65731300   running time 14.189738273620605
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66291848 loss Rayleigh: 0.66716254 loss Rician: 0.65204977   running time 14.084797143936157
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64679679 loss Rayleigh: 0.65610093 loss Rician: 0.64374033   running time 14.0719473361969
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.64119409 loss Rayleigh: 0.64823020 loss Rician: 0.63889385   running time 14.232844591140747
====> Test set BCE loss with SNR 0.0 for AWGN 0.6417040228843689 Custom Loss 0.6417040228843689 with ber  0.4994714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6476452350616455 Custom Loss 0.6476452350616455 with ber  0.4994714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6396601796150208 Custom Loss 0.6396601796150208 with ber  0.4994714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.84084177017212s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.63730933 loss Rayleigh: 0.64236161 loss Rician: 0.63420042   running time 14.022546529769897
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62498701 loss Rayleigh: 0.63380634 loss Rician: 0.62331484   running time 14.062550783157349
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62858462 loss Rayleigh: 0.63824044 loss Rician: 0.62723910   running time 14.054415464401245
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62520768 loss Rayleigh: 0.63364878 loss Rician: 0.62216533   running time 14.115286827087402
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62109485 loss Rayleigh: 0.62868384 loss Rician: 0.61895582   running time 14.250434637069702
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62151440 loss Rayleigh: 0.62821838 loss Rician: 0.61831266   running time 14.15042519569397
====> Test set BCE loss with SNR 0.0 for AWGN 0.619019627571106 Custom Loss 0.619019627571106 with ber  0.4999071428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6262180805206299 Custom Loss 0.6262180805206299 with ber  0.4999071428571429 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6151891946792603 Custom Loss 0.6151891946792603 with ber  0.4999071428571429 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.54097485542297s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.61523285 loss Rayleigh: 0.62271271 loss Rician: 0.61142038   running time 14.008453130722046
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60930406 loss Rayleigh: 0.61803873 loss Rician: 0.60398980   running time 14.066146612167358
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60644715 loss Rayleigh: 0.61939589 loss Rician: 0.60017560   running time 14.19073224067688
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.61017658 loss Rayleigh: 0.62613937 loss Rician: 0.60020681   running time 14.1239595413208
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60881850 loss Rayleigh: 0.62026656 loss Rician: 0.60029155   running time 14.16486406326294
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60692871 loss Rayleigh: 0.61714303 loss Rician: 0.59738073   running time 14.137139797210693
====> Test set BCE loss with SNR 0.0 for AWGN 0.6010969281196594 Custom Loss 0.6010969281196594 with ber  0.5003142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.609054446220398 Custom Loss 0.609054446220398 with ber  0.5003142857142857 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5938603281974792 Custom Loss 0.5938603281974792 with ber  0.5003142857142857 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.561927318573s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59815862 loss Rayleigh: 0.60727792 loss Rician: 0.59044423   running time 14.219257593154907
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59575223 loss Rayleigh: 0.60828347 loss Rician: 0.58868007   running time 14.17311716079712
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59528908 loss Rayleigh: 0.60655129 loss Rician: 0.58774539   running time 14.079323291778564
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59399641 loss Rayleigh: 0.60260023 loss Rician: 0.58631625   running time 14.156325340270996
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59338463 loss Rayleigh: 0.60244774 loss Rician: 0.58261906   running time 14.087217092514038
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59058142 loss Rayleigh: 0.59933848 loss Rician: 0.58120539   running time 14.028151512145996
====> Test set BCE loss with SNR 0.0 for AWGN 0.5923662185668945 Custom Loss 0.5923662185668945 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5997952222824097 Custom Loss 0.5997952222824097 with ber  0.4991 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5828172564506531 Custom Loss 0.5828172564506531 with ber  0.4991 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.76381421089172s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.59355159 loss Rayleigh: 0.60080215 loss Rician: 0.58431452   running time 14.014495611190796
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58700611 loss Rayleigh: 0.59629942 loss Rician: 0.57673618   running time 14.23175597190857
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58359625 loss Rayleigh: 0.59303126 loss Rician: 0.57281271   running time 14.184468030929565
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58209510 loss Rayleigh: 0.59119017 loss Rician: 0.57022766   running time 14.078057289123535
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58498200 loss Rayleigh: 0.59141777 loss Rician: 0.57248237   running time 14.007283210754395
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58633324 loss Rayleigh: 0.59195342 loss Rician: 0.57339944   running time 14.127877950668335
====> Test set BCE loss with SNR 0.0 for AWGN 0.5812963247299194 Custom Loss 0.5812963247299194 with ber  0.5002785714285715 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5894731283187866 Custom Loss 0.5894731283187866 with ber  0.5002785714285715 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5690050721168518 Custom Loss 0.5690050721168518 with ber  0.5002785714285715 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.6166820526123s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58311719 loss Rayleigh: 0.59094719 loss Rician: 0.57165337   running time 13.947298765182495
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58145008 loss Rayleigh: 0.58884762 loss Rician: 0.57019381   running time 14.080419778823853
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58096317 loss Rayleigh: 0.58699704 loss Rician: 0.56801067   running time 14.068176746368408
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58081363 loss Rayleigh: 0.58779225 loss Rician: 0.56823415   running time 14.127999305725098
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58535750 loss Rayleigh: 0.59111962 loss Rician: 0.57081696   running time 14.10230565071106
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58126137 loss Rayleigh: 0.58735924 loss Rician: 0.56777270   running time 14.216623544692993
====> Test set BCE loss with SNR 0.0 for AWGN 0.5832447409629822 Custom Loss 0.5832447409629822 with ber  0.4995357142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5863357782363892 Custom Loss 0.5863357782363892 with ber  0.4995357142857143 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5690096616744995 Custom Loss 0.5690096616744995 with ber  0.4995357142857143 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
each epoch training time: 88.50282621383667s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM16\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM16_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.4986499999999999 learn codes ber with rayleigh  0.4986499999999999 learn codes ber with rician  0.4986499999999999 ber with awgn  0.37561875 ber with rayleigh  0.3977125 ber with rician  0.3892375
Test SNR 5 learn codes ber with awgn  0.5012428571428572 learn codes ber with rayleigh  0.5012428571428572 learn codes ber with rician  0.5012428571428572 ber with awgn  0.28714999999999996 ber with rayleigh  0.30547500000000005 ber with rician  0.2878625
Test SNR 10 learn codes ber with awgn  0.5011142857142857 learn codes ber with rayleigh  0.5011142857142857 learn codes ber with rician  0.5011142857142857 ber with awgn  0.1608875 ber with rayleigh  0.18451875 ber with rician  0.14103749999999998
Test SNR 15 learn codes ber with awgn  0.4983000000000001 learn codes ber with rayleigh  0.4983000000000001 learn codes ber with rician  0.4983000000000001 ber with awgn  0.037774999999999996 ber with rayleigh  0.083875 ber with rician  0.034431250000000004
Test SNR 20 learn codes ber with awgn  0.5007357142857143 learn codes ber with rayleigh  0.5007357142857143 learn codes ber with rician  0.5007357142857143 ber with awgn  0.0008500000000000001 ber with rayleigh  0.029775000000000003 ber with rician  0.00453125
Test SNR 25 learn codes ber with awgn  0.4985214285714286 learn codes ber with rayleigh  0.4985214285714286 learn codes ber with rician  0.4985214285714286 ber with awgn  0.0 ber with rayleigh  0.01004375 ber with rician  0.000675
Test SNR 30 learn codes ber with awgn  0.5016 learn codes ber with rayleigh  0.5016 learn codes ber with rician  0.5016 ber with awgn  0.0 ber with rayleigh  0.0032562499999999996 ber with rician  0.0001875
Test SNR 35 learn codes ber with awgn  0.5009714285714285 learn codes ber with rayleigh  0.5009714285714285 learn codes ber with rician  0.5009714285714285 ber with awgn  0.0 ber with rayleigh  0.0009437500000000001 ber with rician  2.5e-05
Test SNR 40 learn codes ber with awgn  0.5006357142857143 learn codes ber with rayleigh  0.5006357142857143 learn codes ber with rician  0.5006357142857143 ber with awgn  0.0 ber with rayleigh  0.0002812499999999999 ber with rician  6.25e-06
Test SNR 45 learn codes ber with awgn  0.49803571428571425 learn codes ber with rayleigh  0.49803571428571425 learn codes ber with rician  0.49803571428571425 ber with awgn  0.0 ber with rayleigh  0.00010625000000000001 ber with rician  6.25e-06
Test SNR 50 learn codes ber with awgn  0.5020928571428571 learn codes ber with rayleigh  0.5020928571428571 learn codes ber with rician  0.5020928571428571 ber with awgn  0.0 ber with rayleigh  1.8750000000000002e-05 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5000928571428572 learn codes ber with rayleigh  0.5000928571428572 learn codes ber with rician  0.5000928571428572 ber with awgn  0.0 ber with rayleigh  2.5e-05 ber with rician  6.25e-06
Test SNR 60 learn codes ber with awgn  0.5005428571428571 learn codes ber with rayleigh  0.5005428571428571 learn codes ber with rician  0.5005428571428571 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.4997571428571428 learn codes ber with rayleigh  0.4997571428571428 learn codes ber with rician  0.4997571428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.4997071428571429 learn codes ber with rayleigh  0.4997071428571429 learn codes ber with rician  0.4997071428571429 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.5002214285714285 learn codes ber with rayleigh  0.5002214285714285 learn codes ber with rician  0.5002214285714285 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.49867857142857136 learn codes ber with rayleigh  0.49867857142857136 learn codes ber with rician  0.49867857142857136 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.5014928571428572 learn codes ber with rayleigh  0.5014928571428572 learn codes ber with rician  0.5014928571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5003428571428572 learn codes ber with rayleigh  0.5003428571428572 learn codes ber with rician  0.5003428571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5013071428571428 learn codes ber with rayleigh  0.5013071428571428 learn codes ber with rician  0.5013071428571428 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.4986499999999999, 0.5012428571428572, 0.5011142857142857, 0.4983000000000001, 0.5007357142857143, 0.4985214285714286, 0.5016, 0.5009714285714285, 0.5006357142857143, 0.49803571428571425, 0.5020928571428571, 0.5000928571428572, 0.5005428571428571, 0.4997571428571428, 0.4997071428571429, 0.5002214285714285, 0.49867857142857136, 0.5014928571428572, 0.5003428571428572, 0.5013071428571428]
Learn Codes rayleigh [0.4986499999999999, 0.5012428571428572, 0.5011142857142857, 0.4983000000000001, 0.5007357142857143, 0.4985214285714286, 0.5016, 0.5009714285714285, 0.5006357142857143, 0.49803571428571425, 0.5020928571428571, 0.5000928571428572, 0.5005428571428571, 0.4997571428571428, 0.4997071428571429, 0.5002214285714285, 0.49867857142857136, 0.5014928571428572, 0.5003428571428572, 0.5013071428571428]
Learn Codes rician [0.4986499999999999, 0.5012428571428572, 0.5011142857142857, 0.4983000000000001, 0.5007357142857143, 0.4985214285714286, 0.5016, 0.5009714285714285, 0.5006357142857143, 0.49803571428571425, 0.5020928571428571, 0.5000928571428572, 0.5005428571428571, 0.4997571428571428, 0.4997071428571429, 0.5002214285714285, 0.49867857142857136, 0.5014928571428572, 0.5003428571428572, 0.5013071428571428]
AWGN [0.37561875, 0.28714999999999996, 0.1608875, 0.037774999999999996, 0.0008500000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.3977125, 0.30547500000000005, 0.18451875, 0.083875, 0.029775000000000003, 0.01004375, 0.0032562499999999996, 0.0009437500000000001, 0.0002812499999999999, 0.00010625000000000001, 1.8750000000000002e-05, 2.5e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.3892375, 0.2878625, 0.14103749999999998, 0.034431250000000004, 0.00453125, 0.000675, 0.0001875, 2.5e-05, 6.25e-06, 6.25e-06, 0.0, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 
 ###############################################################################################
Training Model for : block length => 20 coderate_k => 7 coderate_n => 8 modulation_type => QAM64
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(7, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=1, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(8, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=7, bias=True)
  )
)
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.69328667 loss Rayleigh: 0.69332452 loss Rician: 0.69323031   running time 14.047913312911987
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.68366556 loss Rayleigh: 0.68337655 loss Rician: 0.68365281   running time 14.18308973312378
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.66401605 loss Rayleigh: 0.66951167 loss Rician: 0.66118020   running time 14.136998176574707
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.65293807 loss Rayleigh: 0.66840693 loss Rician: 0.64722785   running time 14.180810689926147
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.63682742 loss Rayleigh: 0.64835722 loss Rician: 0.63430419   running time 14.697290182113647
====> Epoch: 1 with snr 0.0 Average loss AWGN: 0.63233876 loss Rayleigh: 0.64296319 loss Rician: 0.63040088   running time 14.062802076339722
====> Test set BCE loss with SNR 0.0 for AWGN 0.6318560242652893 Custom Loss 0.6318560242652893 with ber  0.4982714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6424965262413025 Custom Loss 0.6424965262413025 with ber  0.4982714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.6292130351066589 Custom Loss 0.6292130351066589 with ber  0.4982714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_1_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.37075161933899s
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.62847252 loss Rayleigh: 0.63727439 loss Rician: 0.62490043   running time 14.119267702102661
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.61156932 loss Rayleigh: 0.62325187 loss Rician: 0.60756430   running time 14.233155965805054
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60452801 loss Rayleigh: 0.61897926 loss Rician: 0.60146365   running time 14.241718053817749
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60258596 loss Rayleigh: 0.61515729 loss Rician: 0.59795582   running time 14.143643140792847
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60157149 loss Rayleigh: 0.61369283 loss Rician: 0.59740034   running time 14.03585696220398
====> Epoch: 2 with snr 0.0 Average loss AWGN: 0.60223046 loss Rayleigh: 0.61241463 loss Rician: 0.59471909   running time 14.37341833114624
====> Test set BCE loss with SNR 0.0 for AWGN 0.599967360496521 Custom Loss 0.599967360496521 with ber  0.49900714285714276 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.6086694002151489 Custom Loss 0.6086694002151489 with ber  0.49900714285714276 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5937721729278564 Custom Loss 0.5937721729278564 with ber  0.49900714285714276 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_2_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.23733186721802s
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.60062937 loss Rayleigh: 0.60909436 loss Rician: 0.59665738   running time 14.176241636276245
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59353189 loss Rayleigh: 0.60230386 loss Rician: 0.58900104   running time 14.245410442352295
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59531842 loss Rayleigh: 0.60414430 loss Rician: 0.59035614   running time 14.156002044677734
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59284824 loss Rayleigh: 0.60250954 loss Rician: 0.58705091   running time 14.08270812034607
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.59152600 loss Rayleigh: 0.59848916 loss Rician: 0.58595219   running time 31.561836004257202
====> Epoch: 3 with snr 0.0 Average loss AWGN: 0.58984895 loss Rayleigh: 0.59711966 loss Rician: 0.58460129   running time 14.77614140510559
====> Test set BCE loss with SNR 0.0 for AWGN 0.5898028016090393 Custom Loss 0.5898028016090393 with ber  0.5004428571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5969002842903137 Custom Loss 0.5969002842903137 with ber  0.5004428571428571 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5832453370094299 Custom Loss 0.5832453370094299 with ber  0.5004428571428571 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_3_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 107.03106427192688s
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59058766 loss Rayleigh: 0.59749794 loss Rician: 0.58326742   running time 14.026737928390503
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58868865 loss Rayleigh: 0.59748340 loss Rician: 0.58115830   running time 14.328774213790894
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59084358 loss Rayleigh: 0.59911820 loss Rician: 0.58298978   running time 14.293782472610474
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.59156799 loss Rayleigh: 0.60102374 loss Rician: 0.58416172   running time 14.369674682617188
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58999442 loss Rayleigh: 0.59661663 loss Rician: 0.58165185   running time 14.306712627410889
====> Epoch: 4 with snr 0.0 Average loss AWGN: 0.58864294 loss Rayleigh: 0.59595093 loss Rician: 0.58054773   running time 14.231704950332642
====> Test set BCE loss with SNR 0.0 for AWGN 0.5881751775741577 Custom Loss 0.5881751775741577 with ber  0.4989357142857142 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5943640470504761 Custom Loss 0.5943640470504761 with ber  0.4989357142857142 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5808190107345581 Custom Loss 0.5808190107345581 with ber  0.4989357142857142 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_4_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.46603274345398s
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58593251 loss Rayleigh: 0.59343519 loss Rician: 0.57849153   running time 14.240411281585693
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58961602 loss Rayleigh: 0.59801186 loss Rician: 0.57926964   running time 14.345324516296387
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58940719 loss Rayleigh: 0.59814355 loss Rician: 0.57947513   running time 14.35213565826416
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58861517 loss Rayleigh: 0.59987580 loss Rician: 0.57893051   running time 14.33212661743164
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58689334 loss Rayleigh: 0.59491596 loss Rician: 0.57741523   running time 14.142271757125854
====> Epoch: 5 with snr 0.0 Average loss AWGN: 0.58501912 loss Rayleigh: 0.59129150 loss Rician: 0.57543691   running time 14.308102130889893
====> Test set BCE loss with SNR 0.0 for AWGN 0.586950421333313 Custom Loss 0.586950421333313 with ber  0.49929999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.5921155214309692 Custom Loss 0.5921155214309692 with ber  0.49929999999999997 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.5772258043289185 Custom Loss 0.5772258043289185 with ber  0.49929999999999997 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_5_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.63060164451599s
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58781086 loss Rayleigh: 0.59386232 loss Rician: 0.57906498   running time 14.298696279525757
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.58699288 loss Rayleigh: 0.59444128 loss Rician: 0.57515934   running time 14.334750652313232
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59198025 loss Rayleigh: 0.59730754 loss Rician: 0.57906630   running time 14.2749183177948
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59453399 loss Rayleigh: 0.60226657 loss Rician: 0.57850137   running time 14.270348310470581
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59314395 loss Rayleigh: 0.60386291 loss Rician: 0.58169150   running time 14.128123760223389
====> Epoch: 6 with snr 0.0 Average loss AWGN: 0.59399217 loss Rayleigh: 0.59981745 loss Rician: 0.57919305   running time 14.376787185668945
====> Test set BCE loss with SNR 0.0 for AWGN 0.5941582918167114 Custom Loss 0.5941582918167114 with ber  0.5013714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rayleigh 0.600774884223938 Custom Loss 0.600774884223938 with ber  0.5013714285714286 with bler  1.0
====> Test set BCE loss with SNR 0.0 for Rician 0.581282377243042 Custom Loss 0.581282377243042 with ber  0.5013714285714286 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
each epoch training time: 89.68747472763062s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\20230513_211438\model_faded\bl_20__k_7_n_8_mod_QAM64\attention_model_6_awgn_lr_0.01_D1bl_20__k_7_n_8_mod_QAM64_1000_20230513_211438.pt
SNRS [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Test SNR 0 learn codes ber with awgn  0.49944285714285713 learn codes ber with rayleigh  0.49944285714285713 learn codes ber with rician  0.49944285714285713 ber with awgn  0.4408125 ber with rayleigh  0.45385 ber with rician  0.44947499999999996
Test SNR 5 learn codes ber with awgn  0.4986857142857142 learn codes ber with rayleigh  0.4986857142857142 learn codes ber with rician  0.4986857142857142 ber with awgn  0.3921 ber with rayleigh  0.41084375000000006 ber with rician  0.40436249999999996
Test SNR 10 learn codes ber with awgn  0.5000571428571428 learn codes ber with rayleigh  0.5000571428571428 learn codes ber with rician  0.5000571428571428 ber with awgn  0.3146375 ber with rayleigh  0.331 ber with rician  0.3155
Test SNR 15 learn codes ber with awgn  0.5010571428571429 learn codes ber with rayleigh  0.5010571428571429 learn codes ber with rician  0.5010571428571429 ber with awgn  0.1917875 ber with rayleigh  0.2143875 ber with rician  0.176475
Test SNR 20 learn codes ber with awgn  0.5001 learn codes ber with rayleigh  0.5001 learn codes ber with rician  0.5001 ber with awgn  0.0616 ber with rayleigh  0.10326874999999999 ber with rician  0.051831249999999995
Test SNR 25 learn codes ber with awgn  0.5015428571428573 learn codes ber with rayleigh  0.5015428571428573 learn codes ber with rician  0.5015428571428573 ber with awgn  0.00326875 ber with rayleigh  0.03988124999999999 ber with rician  0.007287500000000001
Test SNR 30 learn codes ber with awgn  0.5004928571428572 learn codes ber with rayleigh  0.5004928571428572 learn codes ber with rician  0.5004928571428572 ber with awgn  0.0 ber with rayleigh  0.013368749999999999 ber with rician  0.0011812499999999998
Test SNR 35 learn codes ber with awgn  0.5029928571428571 learn codes ber with rayleigh  0.5029928571428571 learn codes ber with rician  0.5029928571428571 ber with awgn  0.0 ber with rayleigh  0.00455 ber with rician  0.00023124999999999998
Test SNR 40 learn codes ber with awgn  0.5007357142857143 learn codes ber with rayleigh  0.5007357142857143 learn codes ber with rician  0.5007357142857143 ber with awgn  0.0 ber with rayleigh  0.0013687499999999997 ber with rician  6.250000000000001e-05
Test SNR 45 learn codes ber with awgn  0.5021857142857142 learn codes ber with rayleigh  0.5021857142857142 learn codes ber with rician  0.5021857142857142 ber with awgn  0.0 ber with rayleigh  0.0004 ber with rician  6.25e-06
Test SNR 50 learn codes ber with awgn  0.5010071428571429 learn codes ber with rayleigh  0.5010071428571429 learn codes ber with rician  0.5010071428571429 ber with awgn  0.0 ber with rayleigh  0.00015 ber with rician  0.0
Test SNR 55 learn codes ber with awgn  0.5014428571428571 learn codes ber with rayleigh  0.5014428571428571 learn codes ber with rician  0.5014428571428571 ber with awgn  0.0 ber with rayleigh  6.875000000000002e-05 ber with rician  6.25e-06
Test SNR 60 learn codes ber with awgn  0.49919285714285716 learn codes ber with rayleigh  0.49919285714285716 learn codes ber with rician  0.49919285714285716 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 65 learn codes ber with awgn  0.5010428571428572 learn codes ber with rayleigh  0.5010428571428572 learn codes ber with rician  0.5010428571428572 ber with awgn  0.0 ber with rayleigh  1.25e-05 ber with rician  0.0
Test SNR 70 learn codes ber with awgn  0.5010928571428572 learn codes ber with rayleigh  0.5010928571428572 learn codes ber with rician  0.5010928571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 75 learn codes ber with awgn  0.49855 learn codes ber with rayleigh  0.49855 learn codes ber with rician  0.49855 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 80 learn codes ber with awgn  0.5000785714285715 learn codes ber with rayleigh  0.5000785714285715 learn codes ber with rician  0.5000785714285715 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 85 learn codes ber with awgn  0.4985428571428572 learn codes ber with rayleigh  0.4985428571428572 learn codes ber with rician  0.4985428571428572 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 90 learn codes ber with awgn  0.5000071428571429 learn codes ber with rayleigh  0.5000071428571429 learn codes ber with rician  0.5000071428571429 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
Test SNR 95 learn codes ber with awgn  0.5011285714285714 learn codes ber with rayleigh  0.5011285714285714 learn codes ber with rician  0.5011285714285714 ber with awgn  0.0 ber with rayleigh  0.0 ber with rician  0.0
final results on SNRs  [ 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95]
Learn Codes AWGN [0.49944285714285713, 0.4986857142857142, 0.5000571428571428, 0.5010571428571429, 0.5001, 0.5015428571428573, 0.5004928571428572, 0.5029928571428571, 0.5007357142857143, 0.5021857142857142, 0.5010071428571429, 0.5014428571428571, 0.49919285714285716, 0.5010428571428572, 0.5010928571428572, 0.49855, 0.5000785714285715, 0.4985428571428572, 0.5000071428571429, 0.5011285714285714]
Learn Codes rayleigh [0.49944285714285713, 0.4986857142857142, 0.5000571428571428, 0.5010571428571429, 0.5001, 0.5015428571428573, 0.5004928571428572, 0.5029928571428571, 0.5007357142857143, 0.5021857142857142, 0.5010071428571429, 0.5014428571428571, 0.49919285714285716, 0.5010428571428572, 0.5010928571428572, 0.49855, 0.5000785714285715, 0.4985428571428572, 0.5000071428571429, 0.5011285714285714]
Learn Codes rician [0.49944285714285713, 0.4986857142857142, 0.5000571428571428, 0.5010571428571429, 0.5001, 0.5015428571428573, 0.5004928571428572, 0.5029928571428571, 0.5007357142857143, 0.5021857142857142, 0.5010071428571429, 0.5014428571428571, 0.49919285714285716, 0.5010428571428572, 0.5010928571428572, 0.49855, 0.5000785714285715, 0.4985428571428572, 0.5000071428571429, 0.5011285714285714]
AWGN [0.4408125, 0.3921, 0.3146375, 0.1917875, 0.0616, 0.00326875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rayleigh [0.45385, 0.41084375000000006, 0.331, 0.2143875, 0.10326874999999999, 0.03988124999999999, 0.013368749999999999, 0.00455, 0.0013687499999999997, 0.0004, 0.00015, 6.875000000000002e-05, 0.0, 1.25e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
rician [0.44947499999999996, 0.40436249999999996, 0.3155, 0.176475, 0.051831249999999995, 0.007287500000000001, 0.0011812499999999998, 0.00023124999999999998, 6.250000000000001e-05, 6.25e-06, 0.0, 6.25e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
