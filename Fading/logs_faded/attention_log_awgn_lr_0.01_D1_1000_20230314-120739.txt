Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=2.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=3, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\plots_faded')
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69356085  running time 100.18400645256042
====> Epoch: 1 Average loss: 0.77011236  running time 99.83127665519714
====> Epoch: 1 Average loss: 0.61806937  running time 100.76046538352966
====> Epoch: 1 Average loss: 0.58388786  running time 100.10551857948303
====> Epoch: 1 Average loss: 0.57262872  running time 99.35665488243103
====> Epoch: 1 Average loss: 0.56714863  running time 100.5203914642334
====> Test set BCE loss 0.5605038404464722 Custom Loss 0.5605038404464722 with ber  0.29802995920181274 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_1_awgn_lr_0.01_D1_1000_20230314-120739.pt
each epoch training time: 608.6671693325043s
====> Epoch: 2 Average loss: 0.56280175  running time 99.72579789161682
====> Epoch: 2 Average loss: 0.56206808  running time 99.05752277374268
====> Epoch: 2 Average loss: 0.54910519  running time 98.39979028701782
====> Epoch: 2 Average loss: 0.54347953  running time 99.52686333656311
====> Epoch: 2 Average loss: 0.54351875  running time 99.09208273887634
====> Epoch: 2 Average loss: 0.54218514  running time 99.9726333618164
====> Test set BCE loss 0.5420482754707336 Custom Loss 0.5420482754707336 with ber  0.29099997878074646 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_2_awgn_lr_0.01_D1_1000_20230314-120739.pt
each epoch training time: 603.7813243865967s
====> Epoch: 3 Average loss: 0.53510838  running time 99.6111056804657
====> Epoch: 3 Average loss: 0.52854646  running time 98.97459030151367
====> Epoch: 3 Average loss: 0.52560843  running time 99.19604420661926
====> Epoch: 3 Average loss: 0.52629594  running time 101.05816221237183
====> Epoch: 3 Average loss: 0.52452412  running time 99.55777287483215
====> Epoch: 3 Average loss: 0.51884802  running time 100.69621634483337
====> Test set BCE loss 0.5221611857414246 Custom Loss 0.5221611857414246 with ber  0.2843100130558014 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_3_awgn_lr_0.01_D1_1000_20230314-120739.pt
each epoch training time: 607.1718873977661s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_awgn_lr_0.01_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.27584001421928406 with awgn ber  0.34057000000000004 with rayleigh ber  0.23125999999999997 with bler 1.0
Test SNR -1.0 with ber  0.2757999897003174 with awgn ber  0.33428 with rayleigh ber  0.19838999999999998 with bler 1.0
Test SNR -0.5 with ber  0.29378002882003784 with awgn ber  0.32182 with rayleigh ber  0.15143999999999996 with bler 1.0
Test SNR 0.0 with ber  0.3209099769592285 with awgn ber  0.31173 with rayleigh ber  0.09239 with bler 1.0
Test SNR 0.5 with ber  0.29329997301101685 with awgn ber  0.30144000000000004 with rayleigh ber  0.15188000000000001 with bler 1.0
Test SNR 1.0 with ber  0.27889999747276306 with awgn ber  0.2907 with rayleigh ber  0.19896 with bler 1.0
Test SNR 1.5 with ber  0.27849000692367554 with awgn ber  0.28068 with rayleigh ber  0.23192 with bler 1.0
Test SNR 2.0 with ber  0.28468000888824463 with awgn ber  0.26966999999999997 with rayleigh ber  0.25002 with bler 1.0
Test SNR 2.5 with ber  0.29381000995635986 with awgn ber  0.25975000000000004 with rayleigh ber  0.25634999999999997 with bler 1.0
Test SNR 3.0 with ber  0.3095499873161316 with awgn ber  0.24725999999999998 with rayleigh ber  0.25754 with bler 1.0
Test SNR 3.5 with ber  0.32732000946998596 with awgn ber  0.23842000000000002 with rayleigh ber  0.25954 with bler 1.0
Test SNR 4.0 with ber  0.34536999464035034 with awgn ber  0.22976000000000002 with rayleigh ber  0.26005999999999996 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.27584001421928406, 0.2757999897003174, 0.29378002882003784, 0.3209099769592285, 0.29329997301101685, 0.27889999747276306, 0.27849000692367554, 0.28468000888824463, 0.29381000995635986, 0.3095499873161316, 0.32732000946998596, 0.34536999464035034]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
