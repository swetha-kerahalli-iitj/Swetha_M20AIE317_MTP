Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=0.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=2, enc_rnn='rnn', dec_rnn='rnn', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=5, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\plots_faded')
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): RNN(1, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=2, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): RNN(2, 100, num_layers=3, batch_first=True)
    (dec2_rnns): RNN(2, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69223706  running time 86.74068307876587
====> Epoch: 1 Average loss: 0.49004000  running time 87.01182055473328
====> Epoch: 1 Average loss: 0.27517981  running time 86.79310631752014
====> Epoch: 1 Average loss: 0.25924059  running time 87.12427163124084
====> Epoch: 1 Average loss: 0.25260477  running time 88.51669931411743
====> Epoch: 1 Average loss: 0.25007743  running time 86.86595511436462
====> Test set BCE loss 0.2480306327342987 Custom Loss 0.2480306327342987 with ber  0.09324000775814056 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_1_awgn_lr_0.01_D1_1000_20230315-195257.pt
each epoch training time: 525.7079725265503s
====> Epoch: 2 Average loss: 0.24793003  running time 86.41774797439575
====> Epoch: 2 Average loss: 0.23520851  running time 86.23836851119995
====> Epoch: 2 Average loss: 0.22927653  running time 86.84800887107849
====> Epoch: 2 Average loss: 0.22733021  running time 87.04898881912231
====> Epoch: 2 Average loss: 0.22206070  running time 86.3851854801178
====> Epoch: 2 Average loss: 0.22470370  running time 86.44610357284546
====> Test set BCE loss 0.2229708880186081 Custom Loss 0.2229708880186081 with ber  0.0895099937915802 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_2_awgn_lr_0.01_D1_1000_20230315-195257.pt
each epoch training time: 521.8730492591858s
====> Epoch: 3 Average loss: 0.21136486  running time 86.39415454864502
====> Epoch: 3 Average loss: 0.20397316  running time 86.54979014396667
====> Epoch: 3 Average loss: 0.20257475  running time 86.75341820716858
====> Epoch: 3 Average loss: 0.20050810  running time 86.49007630348206
====> Epoch: 3 Average loss: 0.19551411  running time 86.37831401824951
====> Epoch: 3 Average loss: 0.19960440  running time 86.39467906951904
====> Test set BCE loss 0.20067016780376434 Custom Loss 0.20067016780376434 with ber  0.08062000572681427 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_3_awgn_lr_0.01_D1_1000_20230315-195257.pt
each epoch training time: 521.4541943073273s
====> Epoch: 4 Average loss: 0.19936851  running time 86.35123610496521
====> Epoch: 4 Average loss: 0.19603669  running time 86.3867769241333
====> Epoch: 4 Average loss: 0.19559153  running time 86.19122505187988
====> Epoch: 4 Average loss: 0.19788987  running time 86.53009057044983
====> Epoch: 4 Average loss: 0.19486998  running time 86.32462000846863
====> Epoch: 4 Average loss: 0.19252827  running time 86.26757454872131
====> Test set BCE loss 0.1935567557811737 Custom Loss 0.1935567557811737 with ber  0.07681000232696533 with bler  0.999
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_4_awgn_lr_0.01_D1_1000_20230315-195257.pt
each epoch training time: 520.6312830448151s
====> Epoch: 5 Average loss: 0.19374772  running time 86.57697033882141
====> Epoch: 5 Average loss: 0.19113865  running time 86.81831669807434
====> Epoch: 5 Average loss: 0.19393015  running time 86.49952101707458
====> Epoch: 5 Average loss: 0.19506789  running time 86.38571381568909
====> Epoch: 5 Average loss: 0.19234637  running time 86.19654321670532
====> Epoch: 5 Average loss: 0.18939480  running time 86.39667439460754
====> Test set BCE loss 0.18621809780597687 Custom Loss 0.18621809780597687 with ber  0.07336000353097916 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_5_awgn_lr_0.01_D1_1000_20230315-195257.pt
each epoch training time: 521.6171789169312s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_awgn_lr_0.01_D1_1000.pt
SNRS [-2.   0.2  2.4  4.6  6.8  9.  11.2 13.4 15.6 17.8 20. ]
Test SNR -2.0 with ber  0.09533999860286713 with awgn ber  0.750595 with rayleigh ber  0.9583600000000001 with bler 1.0
Test SNR 0.20000000000000018 with ber  0.0732399970293045 with awgn ber  0.5482250000000001 with rayleigh ber  0.7765499999999999 with bler 1.0
Test SNR 2.4000000000000004 with ber  0.057999998331069946 with awgn ber  0.35774500000000004 with rayleigh ber  0.5945849999999999 with bler 0.992
Test SNR 4.6000000000000005 with ber  0.044600002467632294 with awgn ber  0.193765 with rayleigh ber  0.4361149999999999 with bler 0.9890000000000001
Test SNR 6.800000000000001 with ber  0.03720000013709068 with awgn ber  0.075715 with rayleigh ber  0.30859 with bler 0.977
Test SNR 9.0 with ber  0.03128000348806381 with awgn ber  0.017625000000000002 with rayleigh ber  0.20675 with bler 0.9639999999999999
Test SNR 11.200000000000001 with ber  0.02718999981880188 with awgn ber  0.00184 with rayleigh ber  0.133205 with bler 0.932
Test SNR 13.400000000000002 with ber  0.023410001769661903 with awgn ber  4.000000000000001e-05 with rayleigh ber  0.08438999999999999 with bler 0.905
Test SNR 15.600000000000001 with ber  0.021970000118017197 with awgn ber  0.0 with rayleigh ber  0.051745 with bler 0.882
Test SNR 17.8 with ber  0.020270001143217087 with awgn ber  0.0 with rayleigh ber  0.031795000000000004 with bler 0.865
Test SNR 20.0 with ber  0.0188400000333786 with awgn ber  0.0 with rayleigh ber  0.019565 with bler 0.852
final results on SNRs  [-2.   0.2  2.4  4.6  6.8  9.  11.2 13.4 15.6 17.8 20. ]
BER [0.09533999860286713, 0.0732399970293045, 0.057999998331069946, 0.044600002467632294, 0.03720000013709068, 0.03128000348806381, 0.02718999981880188, 0.023410001769661903, 0.021970000118017197, 0.020270001143217087, 0.0188400000333786]
BLER [1.0, 1.0, 0.992, 0.9890000000000001, 0.977, 0.9639999999999999, 0.932, 0.905, 0.882, 0.865, 0.852]
encoder power is 1.0
adjusted SNR should be [-2.000000180303801, 0.19999996779759982, 2.399999883308927, 4.60000017244041, 6.799999760125526, 8.99999981157327, 11.199999975432803, 13.399999824531744, 15.600000161235467, 17.80000039812418, 19.999999870570157]
