Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=1.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=3, enc_rnn='gru', dec_rnn='gru', enc_num_layer=2, dec_num_layer=2, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=5, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.001, enc_lr=0.001, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\plots_faded')
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=2, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=3, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec2_rnns): GRU(3, 100, num_layers=2, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69349160  running time 91.5037784576416
====> Epoch: 1 Average loss: 0.69357274  running time 90.99382328987122
====> Epoch: 1 Average loss: 0.69350773  running time 91.10244655609131
====> Epoch: 1 Average loss: 0.69337955  running time 91.69020104408264
====> Epoch: 1 Average loss: 0.69321608  running time 90.49011945724487
====> Epoch: 1 Average loss: 0.69329153  running time 90.445307970047
====> Test set BCE loss 0.6932882070541382 Custom Loss 0.6932882070541382 with ber  0.4998200535774231 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_1_awgn_lr_0.001_D1_1000_20230311-210221.pt
each epoch training time: 551.5946702957153s
====> Epoch: 2 Average loss: 0.69320897  running time 90.52856516838074
====> Epoch: 2 Average loss: 0.69322711  running time 90.64981365203857
====> Epoch: 2 Average loss: 0.69317719  running time 90.52776026725769
====> Epoch: 2 Average loss: 0.69301503  running time 90.73129510879517
====> Epoch: 2 Average loss: 0.69313217  running time 90.54349899291992
====> Epoch: 2 Average loss: 0.69303777  running time 90.54125022888184
====> Test set BCE loss 0.6931382417678833 Custom Loss 0.6931382417678833 with ber  0.49418002367019653 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_2_awgn_lr_0.001_D1_1000_20230311-210221.pt
each epoch training time: 549.0156252384186s
====> Epoch: 3 Average loss: 0.69286081  running time 90.57972550392151
====> Epoch: 3 Average loss: 0.69023753  running time 91.0141179561615
====> Epoch: 3 Average loss: 0.69072669  running time 90.64190101623535
====> Epoch: 3 Average loss: 0.68935190  running time 90.63383054733276
====> Epoch: 3 Average loss: 0.68940925  running time 90.80877566337585
====> Epoch: 3 Average loss: 0.68949240  running time 90.67910122871399
====> Test set BCE loss 0.6878973841667175 Custom Loss 0.6878973841667175 with ber  0.45893996953964233 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_3_awgn_lr_0.001_D1_1000_20230311-210221.pt
each epoch training time: 549.870313167572s
====> Epoch: 4 Average loss: 0.68350299  running time 91.88502645492554
====> Epoch: 4 Average loss: 0.67759781  running time 90.69943380355835
====> Epoch: 4 Average loss: 0.67565746  running time 97.74565696716309
====> Epoch: 4 Average loss: 0.67530903  running time 91.03585600852966
====> Epoch: 4 Average loss: 0.67532946  running time 90.61796045303345
====> Epoch: 4 Average loss: 0.67524671  running time 91.65329098701477
====> Test set BCE loss 0.6727520227432251 Custom Loss 0.6727520227432251 with ber  0.4172299802303314 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_4_awgn_lr_0.001_D1_1000_20230311-210221.pt
each epoch training time: 559.0712671279907s
====> Epoch: 5 Average loss: 0.67494047  running time 92.3479917049408
====> Epoch: 5 Average loss: 0.67136009  running time 92.1998872756958
====> Epoch: 5 Average loss: 0.67252958  running time 91.22321772575378
====> Epoch: 5 Average loss: 0.67162852  running time 90.86038875579834
====> Epoch: 5 Average loss: 0.67396017  running time 90.6457085609436
====> Epoch: 5 Average loss: 0.67282318  running time 90.50526118278503
====> Test set BCE loss 0.6692336797714233 Custom Loss 0.6692336797714233 with ber  0.4110700190067291 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_5_awgn_lr_0.001_D1_1000_20230311-210221.pt
each epoch training time: 553.3444604873657s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_awgn_lr_0.001_D1_1000.pt
SNRS [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
Test SNR -1.5 with ber  0.42579999566078186 with bler 1.0
Test SNR -1.0 with ber  0.4243900179862976 with bler 1.0
Test SNR -0.5 with ber  0.4213999807834625 with bler 1.0
Test SNR 0.0 with ber  0.4172600209712982 with bler 1.0
Test SNR 0.5 with ber  0.414359986782074 with bler 1.0
Test SNR 1.0 with ber  0.41276997327804565 with bler 1.0
Test SNR 1.5 with ber  0.4112599790096283 with bler 1.0
Test SNR 2.0 with ber  0.40421000123023987 with bler 1.0
Test SNR 2.5 with ber  0.4002700448036194 with bler 1.0
Test SNR 3.0 with ber  0.39807993173599243 with bler 1.0
Test SNR 3.5 with ber  0.3936399817466736 with bler 1.0
Test SNR 4.0 with ber  0.3904699683189392 with bler 1.0
final results on SNRs  [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
BER [0.42579999566078186, 0.4243900179862976, 0.4213999807834625, 0.4172600209712982, 0.414359986782074, 0.41276997327804565, 0.4112599790096283, 0.40421000123023987, 0.4002700448036194, 0.39807993173599243, 0.3936399817466736, 0.3904699683189392]
BLER [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
encoder power is 1.0
adjusted SNR should be [-1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358]
