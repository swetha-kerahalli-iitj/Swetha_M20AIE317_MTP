Namespace(channel='awgn', vv=5, radar_prob=0.05, radar_power=5.0, train_enc_channel_low=0.0, train_enc_channel_high=1.0, train_dec_channel_low=-1.5, train_dec_channel_high=2.0, init_nw_weight='default', code_rate_k=1, code_rate_n=2, enc_rnn='gru', dec_rnn='gru', enc_num_layer=3, dec_num_layer=3, dec_num_unit=100, enc_num_unit=25, enc_act='elu', dec_act='linear', num_train_dec=5, num_train_enc=1, dropout=0.0, snr_test_start=-1.5, snr_test_end=4.0, snr_points=12, batch_size=100, num_epoch=5, test_ratio=1, block_len=100, block_len_low=10, block_len_high=200, is_variable_block_len=False, num_block=1000, test_channel_mode='block_norm', train_channel_mode='block_norm', enc_truncate_limit=0, no_code_norm=False, enc_quantize_level=2, enc_value_limit=1.0, enc_grad_limit=0.01, enc_clipping='both', optimizer='adam', dec_lr=0.01, enc_lr=0.01, no_cuda=False, rec_quantize=False, print_pos_ber=False, print_pos_power=False, print_test_traj=False, precompute_norm_stats=False, Simulate='Rician', D=1, BASE_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading', LOG_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\logs_faded', DATA_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\data_faded', MODEL_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\model_faded', PLOT_PATH='C:\\WorkSpace\\FadingChannels\\Swetha_M20AIE317_MTP\\Fading\\plots_faded')
use_cuda:  False
Channel_AE(
  (enc): ENC(
    (enc_rnn): GRU(1, 25, num_layers=3, batch_first=True)
    (enc_linear): Linear(in_features=25, out_features=2, bias=True)
  )
  (dec): DEC(
    (dropout): Dropout(p=0.0, inplace=False)
    (attention): Attention(
      (attn): Linear(in_features=200, out_features=1, bias=False)
    )
    (fc): Linear(in_features=200, out_features=100, bias=True)
    (dec1_rnns): GRU(2, 100, num_layers=3, batch_first=True)
    (dec2_rnns): GRU(2, 100, num_layers=3, batch_first=True)
    (dec_outputs): Linear(in_features=200, out_features=1, bias=True)
  )
)
====> Epoch: 1 Average loss: 0.69320188  running time 96.30502462387085
====> Epoch: 1 Average loss: 0.63506310  running time 94.79240870475769
====> Epoch: 1 Average loss: 0.43515971  running time 95.6559853553772
====> Epoch: 1 Average loss: 0.39280327  running time 95.1304121017456
====> Epoch: 1 Average loss: 0.38188063  running time 93.71123123168945
====> Epoch: 1 Average loss: 0.37445081  running time 94.77736377716064
====> Test set BCE loss 0.3740555942058563 Custom Loss 0.3740555942058563 with ber  0.16670000553131104 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_1_awgn_lr_0.01_D1_1000_20230316-113053.pt
each epoch training time: 576.2440800666809s
====> Epoch: 2 Average loss: 0.35130394  running time 94.10961127281189
====> Epoch: 2 Average loss: 0.31110796  running time 95.8393828868866
====> Epoch: 2 Average loss: 0.30380850  running time 93.15997290611267
====> Epoch: 2 Average loss: 0.30114539  running time 95.12755036354065
====> Epoch: 2 Average loss: 0.29892093  running time 96.50728130340576
====> Epoch: 2 Average loss: 0.29257305  running time 93.2644910812378
====> Test set BCE loss 0.2929365336894989 Custom Loss 0.2929365336894989 with ber  0.12428001314401627 with bler  1.0
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_2_awgn_lr_0.01_D1_1000_20230316-113053.pt
each epoch training time: 573.8364818096161s
====> Epoch: 3 Average loss: 0.26037582  running time 93.62455224990845
====> Epoch: 3 Average loss: 0.22154756  running time 92.79205799102783
====> Epoch: 3 Average loss: 0.21030325  running time 92.96863412857056
====> Epoch: 3 Average loss: 0.20938247  running time 93.18811202049255
====> Epoch: 3 Average loss: 0.20771504  running time 92.9749231338501
====> Epoch: 3 Average loss: 0.20955210  running time 92.90240788459778
====> Test set BCE loss 0.2033189833164215 Custom Loss 0.2033189833164215 with ber  0.07699000090360641 with bler  0.999
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_3_awgn_lr_0.01_D1_1000_20230316-113053.pt
each epoch training time: 564.1960077285767s
====> Epoch: 4 Average loss: 0.20020053  running time 93.06860184669495
====> Epoch: 4 Average loss: 0.18536534  running time 93.26911306381226
====> Epoch: 4 Average loss: 0.17611098  running time 93.05177569389343
====> Epoch: 4 Average loss: 0.17854207  running time 93.4818868637085
====> Epoch: 4 Average loss: 0.17882508  running time 93.58185410499573
====> Epoch: 4 Average loss: 0.17473076  running time 93.26319289207458
====> Test set BCE loss 0.17784671485424042 Custom Loss 0.17784671485424042 with ber  0.06321000307798386 with bler  0.9960000000000001
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_4_awgn_lr_0.01_D1_1000_20230316-113053.pt
each epoch training time: 565.6224176883698s
====> Epoch: 5 Average loss: 0.17286421  running time 93.42649412155151
====> Epoch: 5 Average loss: 0.17825005  running time 93.5118317604065
====> Epoch: 5 Average loss: 0.17249016  running time 93.52230334281921
====> Epoch: 5 Average loss: 0.17463553  running time 93.44231414794922
====> Epoch: 5 Average loss: 0.17392049  running time 93.8687515258789
====> Epoch: 5 Average loss: 0.17563958  running time 93.50460028648376
====> Test set BCE loss 0.17554859817028046 Custom Loss 0.17554859817028046 with ber  0.06016000360250473 with bler  0.9960000000000001
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_5_awgn_lr_0.01_D1_1000_20230316-113053.pt
each epoch training time: 566.9787421226501s
saved model C:\WorkSpace\FadingChannels\Swetha_M20AIE317_MTP\Fading\model_faded\attention_model_awgn_lr_0.01_D1_1000.pt
SNRS [-2.   0.2  2.4  4.6  6.8  9.  11.2 13.4 15.6 17.8 20. ]
Test SNR -2.0 with ber  0.07977999746799469 ber with awgn  0.7509549999999999 ber with rayleigh  0.95755 ber with rician  0.9120199999999998 with bler 1.0
Test SNR 0.20000000000000018 with ber  0.05909999459981918 ber with awgn  0.5484349999999999 ber with rayleigh  0.7759350000000002 ber with rician  0.7246849999999999 with bler 0.998
Test SNR 2.4000000000000004 with ber  0.04089999943971634 ber with awgn  0.358685 ber with rayleigh  0.59741 ber with rician  0.5429649999999999 with bler 0.983
Test SNR 4.6000000000000005 with ber  0.0269399993121624 ber with awgn  0.19171 ber with rayleigh  0.43721000000000004 ber with rician  0.38222500000000004 with bler 0.923
Test SNR 6.800000000000001 with ber  0.016710001975297928 ber with awgn  0.07552 ber with rayleigh  0.307975 ber with rician  0.25616000000000005 with bler 0.8059999999999998
Test SNR 9.0 with ber  0.011029998771846294 ber with awgn  0.01779 ber with rayleigh  0.20488499999999998 ber with rician  0.16202000000000003 with bler 0.653
Test SNR 11.200000000000001 with ber  0.007040000054985285 ber with awgn  0.00169 ber with rayleigh  0.134025 ber with rician  0.099015 with bler 0.5120000000000001
Test SNR 13.400000000000002 with ber  0.0038499999791383743 ber with awgn  2e-05 ber with rayleigh  0.08410499999999999 ber with rician  0.05945 with bler 0.323
Test SNR 15.600000000000001 with ber  0.002589999930933118 ber with awgn  0.0 ber with rayleigh  0.05145500000000001 ber with rician  0.034879999999999994 with bler 0.22200000000000003
Test SNR 17.8 with ber  0.0013299999991431832 ber with awgn  0.0 ber with rayleigh  0.032139999999999995 ber with rician  0.021235 with bler 0.121
Test SNR 20.0 with ber  0.0008699999889358878 ber with awgn  0.0 ber with rayleigh  0.019615 ber with rician  0.012680000000000002 with bler 0.084
final results on SNRs  [-2.   0.2  2.4  4.6  6.8  9.  11.2 13.4 15.6 17.8 20. ]
BER [0.07977999746799469, 0.05909999459981918, 0.04089999943971634, 0.0269399993121624, 0.016710001975297928, 0.011029998771846294, 0.007040000054985285, 0.0038499999791383743, 0.002589999930933118, 0.0013299999991431832, 0.0008699999889358878]
BLER [1.0, 0.998, 0.983, 0.923, 0.8059999999999998, 0.653, 0.5120000000000001, 0.323, 0.22200000000000003, 0.121, 0.084]
AWGN [0.7509549999999999, 0.5484349999999999, 0.358685, 0.19171, 0.07552, 0.01779, 0.00169, 2e-05, 0.0, 0.0, 0.0]
rayleigh [0.95755, 0.7759350000000002, 0.59741, 0.43721000000000004, 0.307975, 0.20488499999999998, 0.134025, 0.08410499999999999, 0.05145500000000001, 0.032139999999999995, 0.019615]
rician [0.9120199999999998, 0.7246849999999999, 0.5429649999999999, 0.38222500000000004, 0.25616000000000005, 0.16202000000000003, 0.099015, 0.05945, 0.034879999999999994, 0.021235, 0.012680000000000002]
encoder power is 1.0
adjusted SNR should be [-2.000000180303801, 0.19999996779759982, 2.399999883308927, 4.60000017244041, 6.799999760125526, 8.99999981157327, 11.199999975432803, 13.399999824531744, 15.600000161235467, 17.80000039812418, 19.999999870570157]
